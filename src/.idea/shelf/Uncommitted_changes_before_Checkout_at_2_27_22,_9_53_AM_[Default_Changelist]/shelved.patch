Index: cmd/compile/internal/gc/ssa.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright 2015 The Go Authors. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\npackage gc\n\nimport (\n\t\"encoding/binary\"\n\t\"fmt\"\n\t\"html\"\n\t\"os\"\n\t\"sort\"\n\n\t\"bufio\"\n\t\"bytes\"\n\t\"cmd/compile/internal/ssa\"\n\t\"cmd/compile/internal/types\"\n\t\"cmd/internal/obj\"\n\t\"cmd/internal/obj/x86\"\n\t\"cmd/internal/objabi\"\n\t\"cmd/internal/src\"\n\t\"cmd/internal/sys\"\n)\n\nvar ssaConfig *ssa.Config\nvar ssaCaches []ssa.Cache\n\nvar ssaDump string     // early copy of $GOSSAFUNC; the func name to dump output for （os.Getenv(\"GOSSAFUNC\")）\nvar ssaDumpStdout bool // whether to dump to stdout   当GOSSAFUNC环境变量的值由+结尾时为true\nvar ssaDumpCFG string  // generate CFGs for these phases\tGOSSAFUNC环境变量:后面的内容\nconst ssaDumpFile = \"ssa.html\"\n\n// The max number of defers in a function using open-coded defers. We enforce this\n// limit because the deferBits bitmask is currently a single byte (to minimize code size)\nconst maxOpenDefers = 8\n\n// ssaDumpInlined holds all inlined functions when ssaDump contains a function name.\nvar ssaDumpInlined []*Node\n\nfunc initssaconfig() {\n\ttypes_ := ssa.NewTypes()\n\n\tif thearch.SoftFloat {\n\t\tsoftfloatInit()\n\t}\n\n\t// Generate a few pointer types that are uncommon in the frontend but common in the backend.\n\t// Caching is disabled in the backend, so generating these here avoids allocations.\n\t_ = types.NewPtr(types.Types[TINTER])                             // *interface{}\n\t_ = types.NewPtr(types.NewPtr(types.Types[TSTRING]))              // **string\n\t_ = types.NewPtr(types.NewPtr(types.Idealstring))                 // **string\n\t_ = types.NewPtr(types.NewSlice(types.Types[TINTER]))             // *[]interface{}\n\t_ = types.NewPtr(types.NewPtr(types.Bytetype))                    // **byte\n\t_ = types.NewPtr(types.NewSlice(types.Bytetype))                  // *[]byte\n\t_ = types.NewPtr(types.NewSlice(types.Types[TSTRING]))            // *[]string\n\t_ = types.NewPtr(types.NewSlice(types.Idealstring))               // *[]string\n\t_ = types.NewPtr(types.NewPtr(types.NewPtr(types.Types[TUINT8]))) // ***uint8\n\t_ = types.NewPtr(types.Types[TINT16])                             // *int16\n\t_ = types.NewPtr(types.Types[TINT64])                             // *int64\n\t_ = types.NewPtr(types.Errortype)                                 // *error\n\ttypes.NewPtrCacheEnabled = false\n\tssaConfig = ssa.NewConfig(thearch.LinkArch.Name, *types_, Ctxt, Debug['N'] == 0)\n\tif thearch.LinkArch.Name == \"386\" {\n\t\tssaConfig.Set387(thearch.Use387)\n\t}\n\tssaConfig.SoftFloat = thearch.SoftFloat\n\tssaConfig.Race = flag_race\n\tssaCaches = make([]ssa.Cache, nBackendWorkers)\n\n\t// Set up some runtime functions we'll need to call.\n\tassertE2I = sysfunc(\"assertE2I\")\n\tassertE2I2 = sysfunc(\"assertE2I2\")\n\tassertI2I = sysfunc(\"assertI2I\")\n\tassertI2I2 = sysfunc(\"assertI2I2\")\n\tdeferproc = sysfunc(\"deferproc\")\n\tdeferprocStack = sysfunc(\"deferprocStack\")\n\tDeferreturn = sysfunc(\"deferreturn\")\n\tDuffcopy = sysvar(\"duffcopy\")             // asm func with special ABI\n\tDuffzero = sysvar(\"duffzero\")             // asm func with special ABI\n\tgcWriteBarrier = sysvar(\"gcWriteBarrier\") // asm func with special ABI\n\tgoschedguarded = sysfunc(\"goschedguarded\")\n\tgrowslice = sysfunc(\"growslice\")\n\tcutslice = sysfunc(\"cutslice\")\n\tmsanread = sysfunc(\"msanread\")\n\tmsanwrite = sysfunc(\"msanwrite\")\n\tnewobject = sysfunc(\"newobject\")\n\tnewproc = sysfunc(\"newproc\")\n\tpanicdivide = sysfunc(\"panicdivide\")\n\tpanicdottypeE = sysfunc(\"panicdottypeE\")\n\tpanicdottypeI = sysfunc(\"panicdottypeI\")\n\tpanicnildottype = sysfunc(\"panicnildottype\")\n\tpanicoverflow = sysfunc(\"panicoverflow\")\n\tpanicshift = sysfunc(\"panicshift\")\n\traceread = sysfunc(\"raceread\")\n\tracereadrange = sysfunc(\"racereadrange\")\n\tracewrite = sysfunc(\"racewrite\")\n\tracewriterange = sysfunc(\"racewriterange\")\n\tx86HasPOPCNT = sysvar(\"x86HasPOPCNT\")       // bool\n\tx86HasSSE41 = sysvar(\"x86HasSSE41\")         // bool\n\tx86HasFMA = sysvar(\"x86HasFMA\")             // bool\n\tarmHasVFPv4 = sysvar(\"armHasVFPv4\")         // bool\n\tarm64HasATOMICS = sysvar(\"arm64HasATOMICS\") // bool\n\ttypedmemclr = sysfunc(\"typedmemclr\")\n\ttypedmemmove = sysfunc(\"typedmemmove\")\n\tUdiv = sysvar(\"udiv\")                 // asm func with special ABI\n\twriteBarrier = sysvar(\"writeBarrier\") // struct { bool; ... }\n\tzerobaseSym = sysvar(\"zerobase\")\n\n\t// asm funcs with special ABI\n\tif thearch.LinkArch.Name == \"amd64\" {\n\t\tGCWriteBarrierReg = map[int16]*obj.LSym{\n\t\t\tx86.REG_AX: sysvar(\"gcWriteBarrier\"),\n\t\t\tx86.REG_CX: sysvar(\"gcWriteBarrierCX\"),\n\t\t\tx86.REG_DX: sysvar(\"gcWriteBarrierDX\"),\n\t\t\tx86.REG_BX: sysvar(\"gcWriteBarrierBX\"),\n\t\t\tx86.REG_BP: sysvar(\"gcWriteBarrierBP\"),\n\t\t\tx86.REG_SI: sysvar(\"gcWriteBarrierSI\"),\n\t\t\tx86.REG_R8: sysvar(\"gcWriteBarrierR8\"),\n\t\t\tx86.REG_R9: sysvar(\"gcWriteBarrierR9\"),\n\t\t}\n\t}\n\n\tif thearch.LinkArch.Family == sys.Wasm {\n\t\tBoundsCheckFunc[ssa.BoundsIndex] = sysvar(\"goPanicIndex\")\n\t\tBoundsCheckFunc[ssa.BoundsIndexU] = sysvar(\"goPanicIndexU\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceAlen] = sysvar(\"goPanicSliceAlen\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceAlenU] = sysvar(\"goPanicSliceAlenU\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceAcap] = sysvar(\"goPanicSliceAcap\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceAcapU] = sysvar(\"goPanicSliceAcapU\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceB] = sysvar(\"goPanicSliceB\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceBU] = sysvar(\"goPanicSliceBU\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3Alen] = sysvar(\"goPanicSlice3Alen\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3AlenU] = sysvar(\"goPanicSlice3AlenU\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3Acap] = sysvar(\"goPanicSlice3Acap\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3AcapU] = sysvar(\"goPanicSlice3AcapU\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3B] = sysvar(\"goPanicSlice3B\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3BU] = sysvar(\"goPanicSlice3BU\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3C] = sysvar(\"goPanicSlice3C\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3CU] = sysvar(\"goPanicSlice3CU\")\n\t} else {\n\t\tBoundsCheckFunc[ssa.BoundsIndex] = sysvar(\"panicIndex\")\n\t\tBoundsCheckFunc[ssa.BoundsIndexU] = sysvar(\"panicIndexU\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceAlen] = sysvar(\"panicSliceAlen\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceAlenU] = sysvar(\"panicSliceAlenU\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceAcap] = sysvar(\"panicSliceAcap\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceAcapU] = sysvar(\"panicSliceAcapU\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceB] = sysvar(\"panicSliceB\")\n\t\tBoundsCheckFunc[ssa.BoundsSliceBU] = sysvar(\"panicSliceBU\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3Alen] = sysvar(\"panicSlice3Alen\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3AlenU] = sysvar(\"panicSlice3AlenU\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3Acap] = sysvar(\"panicSlice3Acap\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3AcapU] = sysvar(\"panicSlice3AcapU\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3B] = sysvar(\"panicSlice3B\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3BU] = sysvar(\"panicSlice3BU\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3C] = sysvar(\"panicSlice3C\")\n\t\tBoundsCheckFunc[ssa.BoundsSlice3CU] = sysvar(\"panicSlice3CU\")\n\t}\n\tif thearch.LinkArch.PtrSize == 4 {\n\t\tExtendCheckFunc[ssa.BoundsIndex] = sysvar(\"panicExtendIndex\")\n\t\tExtendCheckFunc[ssa.BoundsIndexU] = sysvar(\"panicExtendIndexU\")\n\t\tExtendCheckFunc[ssa.BoundsSliceAlen] = sysvar(\"panicExtendSliceAlen\")\n\t\tExtendCheckFunc[ssa.BoundsSliceAlenU] = sysvar(\"panicExtendSliceAlenU\")\n\t\tExtendCheckFunc[ssa.BoundsSliceAcap] = sysvar(\"panicExtendSliceAcap\")\n\t\tExtendCheckFunc[ssa.BoundsSliceAcapU] = sysvar(\"panicExtendSliceAcapU\")\n\t\tExtendCheckFunc[ssa.BoundsSliceB] = sysvar(\"panicExtendSliceB\")\n\t\tExtendCheckFunc[ssa.BoundsSliceBU] = sysvar(\"panicExtendSliceBU\")\n\t\tExtendCheckFunc[ssa.BoundsSlice3Alen] = sysvar(\"panicExtendSlice3Alen\")\n\t\tExtendCheckFunc[ssa.BoundsSlice3AlenU] = sysvar(\"panicExtendSlice3AlenU\")\n\t\tExtendCheckFunc[ssa.BoundsSlice3Acap] = sysvar(\"panicExtendSlice3Acap\")\n\t\tExtendCheckFunc[ssa.BoundsSlice3AcapU] = sysvar(\"panicExtendSlice3AcapU\")\n\t\tExtendCheckFunc[ssa.BoundsSlice3B] = sysvar(\"panicExtendSlice3B\")\n\t\tExtendCheckFunc[ssa.BoundsSlice3BU] = sysvar(\"panicExtendSlice3BU\")\n\t\tExtendCheckFunc[ssa.BoundsSlice3C] = sysvar(\"panicExtendSlice3C\")\n\t\tExtendCheckFunc[ssa.BoundsSlice3CU] = sysvar(\"panicExtendSlice3CU\")\n\t}\n\n\t// GO386=387 runtime definitions\n\tControlWord64trunc = sysvar(\"controlWord64trunc\") // uint16\n\tControlWord32 = sysvar(\"controlWord32\")           // uint16\n\n\t// Wasm (all asm funcs with special ABIs)\n\tWasmMove = sysvar(\"wasmMove\")\n\tWasmZero = sysvar(\"wasmZero\")\n\tWasmDiv = sysvar(\"wasmDiv\")\n\tWasmTruncS = sysvar(\"wasmTruncS\")\n\tWasmTruncU = sysvar(\"wasmTruncU\")\n\tSigPanic = sysfunc(\"sigpanic\")\n}\n\n// getParam returns the Field of ith param of node n (which is a\n// function/method/interface call), where the receiver of a method call is\n// considered as the 0th parameter. This does not include the receiver of an\n// interface call.\nfunc getParam(n *Node, i int) *types.Field {\n\tt := n.Left.Type\n\tif n.Op == OCALLMETH {\n\t\tif i == 0 {\n\t\t\treturn t.Recv()\n\t\t}\n\t\treturn t.Params().Field(i - 1)\n\t}\n\treturn t.Params().Field(i)\n}\n\n// dvarint writes a varint v to the funcdata in symbol x and returns the new offset\nfunc dvarint(x *obj.LSym, off int, v int64) int {\n\tif v < 0 || v > 1e9 {\n\t\tpanic(fmt.Sprintf(\"dvarint: bad offset for funcdata - %v\", v))\n\t}\n\tif v < 1<<7 {\n\t\treturn duint8(x, off, uint8(v))\n\t}\n\toff = duint8(x, off, uint8((v&127)|128))\n\tif v < 1<<14 {\n\t\treturn duint8(x, off, uint8(v>>7))\n\t}\n\toff = duint8(x, off, uint8(((v>>7)&127)|128))\n\tif v < 1<<21 {\n\t\treturn duint8(x, off, uint8(v>>14))\n\t}\n\toff = duint8(x, off, uint8(((v>>14)&127)|128))\n\tif v < 1<<28 {\n\t\treturn duint8(x, off, uint8(v>>21))\n\t}\n\toff = duint8(x, off, uint8(((v>>21)&127)|128))\n\treturn duint8(x, off, uint8(v>>28))\n}\n\n// emitOpenDeferInfo emits FUNCDATA information about the defers in a function\n// that is using open-coded defers.  This funcdata is used to determine the active\n// defers in a function and execute those defers during panic processing.\n//\n// The funcdata is all encoded in varints (since values will almost always be less than\n// 128, but stack offsets could potentially be up to 2Gbyte). All \"locations\" (offsets)\n// for stack variables are specified as the number of bytes below varp (pointer to the\n// top of the local variables) for their starting address. The format is:\n//\n//  - Max total argument size among all the defers\n//  - Offset of the deferBits variable\n//  - Number of defers in the function\n//  - Information about each defer call, in reverse order of appearance in the function:\n//    - Total argument size of the call\n//    - Offset of the closure value to call\n//    - Number of arguments (including interface receiver or method receiver as first arg)\n//    - Information about each argument\n//      - Offset of the stored defer argument in this function's frame\n//      - Size of the argument\n//      - Offset of where argument should be placed in the args frame when making call\nfunc (s *state) emitOpenDeferInfo() {\n\tx := Ctxt.Lookup(s.curfn.Func.lsym.Name + \".opendefer\")\n\ts.curfn.Func.lsym.Func.OpenCodedDeferInfo = x\n\toff := 0\n\n\t// Compute maxargsize (max size of arguments for all defers)\n\t// first, so we can output it first to the funcdata\n\tvar maxargsize int64\n\tfor i := len(s.openDefers) - 1; i >= 0; i-- {\n\t\tr := s.openDefers[i]\n\t\targsize := r.n.Left.Type.ArgWidth()\n\t\tif argsize > maxargsize {\n\t\t\tmaxargsize = argsize\n\t\t}\n\t}\n\toff = dvarint(x, off, maxargsize)\n\toff = dvarint(x, off, -s.deferBitsTemp.Xoffset)\n\toff = dvarint(x, off, int64(len(s.openDefers)))\n\n\t// Write in reverse-order, for ease of running in that order at runtime\n\tfor i := len(s.openDefers) - 1; i >= 0; i-- {\n\t\tr := s.openDefers[i]\n\t\toff = dvarint(x, off, r.n.Left.Type.ArgWidth())\n\t\toff = dvarint(x, off, -r.closureNode.Xoffset)\n\t\tnumArgs := len(r.argNodes)\n\t\tif r.rcvrNode != nil {\n\t\t\t// If there's an interface receiver, treat/place it as the first\n\t\t\t// arg. (If there is a method receiver, it's already included as\n\t\t\t// first arg in r.argNodes.)\n\t\t\tnumArgs++\n\t\t}\n\t\toff = dvarint(x, off, int64(numArgs))\n\t\tif r.rcvrNode != nil {\n\t\t\toff = dvarint(x, off, -r.rcvrNode.Xoffset)\n\t\t\toff = dvarint(x, off, s.config.PtrSize)\n\t\t\toff = dvarint(x, off, 0)\n\t\t}\n\t\tfor j, arg := range r.argNodes {\n\t\t\tf := getParam(r.n, j)\n\t\t\toff = dvarint(x, off, -arg.Xoffset)\n\t\t\toff = dvarint(x, off, f.Type.Size())\n\t\t\toff = dvarint(x, off, f.Offset)\n\t\t}\n\t}\n}\n\n// buildssa builds an SSA function for fn.\n// worker indicates which of the backend workers is doing the processing.\nfunc buildssa(fn *Node, worker int) *ssa.Func {\n\tname := fn.funcname() // 被编译的函数名\n\tprintssa := name == ssaDump\n\tvar astBuf *bytes.Buffer\n\tif printssa {\n\t\tastBuf = &bytes.Buffer{}\n\t\tfdumplist(astBuf, \"buildssa-enter\", fn.Func.Enter)\n\t\tfdumplist(astBuf, \"buildssa-body\", fn.Nbody)\n\t\tfdumplist(astBuf, \"buildssa-exit\", fn.Func.Exit)\n\t\tif ssaDumpStdout {\n\t\t\tfmt.Println(\"generating SSA for\", name)\n\t\t\tfmt.Print(astBuf.String())\n\t\t}\n\t}\n\n\tvar s state\n\ts.pushLine(fn.Pos)\n\tdefer s.popLine()\n\n\ts.hasdefer = fn.Func.HasDefer()\n\tif fn.Func.Pragma&CgoUnsafeArgs != 0 {\n\t\ts.cgoUnsafeArgs = true\n\t}\n\n\tfe := ssafn{\n\t\tcurfn: fn,\n\t\tlog:   printssa && ssaDumpStdout,\n\t}\n\ts.curfn = fn\n\n\ts.f = ssa.NewFunc(&fe)\n\ts.config = ssaConfig\n\ts.f.Type = fn.Type\n\ts.f.Config = ssaConfig\n\ts.f.Cache = &ssaCaches[worker]\n\ts.f.Cache.Reset()\n\ts.f.DebugTest = s.f.DebugHashMatch(\"GOSSAHASH\", name)\n\ts.f.Name = name\n\ts.f.PrintOrHtmlSSA = printssa\n\tif fn.Func.Pragma&Nosplit != 0 {\n\t\ts.f.NoSplit = true\n\t}\n\ts.panics = map[funcLine]*ssa.Block{}\n\ts.softFloat = s.config.SoftFloat\n\n\tif printssa {\n\t\ts.f.HTMLWriter = ssa.NewHTMLWriter(ssaDumpFile, s.f, ssaDumpCFG)\n\t\t// TODO: generate and print a mapping from nodes to values and blocks\n\t\tdumpSourcesColumn(s.f.HTMLWriter, fn)\n\t\ts.f.HTMLWriter.WriteAST(\"AST\", astBuf)\n\t}\n\n\t// Allocate starting block\n\ts.f.Entry = s.f.NewBlock(ssa.BlockPlain)\n\n\t// Allocate starting values\n\ts.labels = map[string]*ssaLabel{}\n\ts.labeledNodes = map[*Node]*ssaLabel{}\n\ts.fwdVars = map[*Node]*ssa.Value{}\n\ts.startmem = s.entryNewValue0(ssa.OpInitMem, types.TypeMem)\n\n\ts.hasOpenDefers = Debug['N'] == 0 && s.hasdefer && !s.curfn.Func.OpenCodedDeferDisallowed()\n\tswitch {\n\tcase s.hasOpenDefers && (Ctxt.Flag_shared || Ctxt.Flag_dynlink) && thearch.LinkArch.Name == \"386\":\n\t\t// Don't support open-coded defers for 386 ONLY when using shared\n\t\t// libraries, because there is Extra code (added by rewriteToUseGot())\n\t\t// preceding the deferreturn/ret code that is generated by gencallret()\n\t\t// that we don't track correctly.\n\t\ts.hasOpenDefers = false\n\t}\n\tif s.hasOpenDefers && s.curfn.Func.Exit.Len() > 0 {\n\t\t// Skip doing open defers if there is any Extra exit code (likely\n\t\t// copying heap-allocated return values or race detection), since\n\t\t// we will not generate that code in the case of the Extra\n\t\t// deferreturn/ret segment.\n\t\ts.hasOpenDefers = false\n\t}\n\tif s.hasOpenDefers &&\n\t\ts.curfn.Func.numReturns*s.curfn.Func.numDefers > 15 {\n\t\t// Since we are generating defer calls at every exit for\n\t\t// open-coded defers, skip doing open-coded defers if there are\n\t\t// too many returns (especially if there are multiple defers).\n\t\t// Open-coded defers are most important for improving performance\n\t\t// for smaller functions (which don't have many returns).\n\t\ts.hasOpenDefers = false\n\t}\n\n\ts.sp = s.entryNewValue0(ssa.OpSP, types.Types[TUINTPTR]) // TODO: use generic pointer type (unsafe.Pointer?) instead\n\ts.sb = s.entryNewValue0(ssa.OpSB, types.Types[TUINTPTR])\n\n\ts.startBlock(s.f.Entry)\n\ts.vars[&memVar] = s.startmem\n\tif s.hasOpenDefers {\n\t\t// Create the deferBits variable and stack slot.  deferBits is a\n\t\t// bitmask showing which of the open-coded defers in this function\n\t\t// have been activated.\n\t\tdeferBitsTemp := tempAt(src.NoXPos, s.curfn, types.Types[TUINT8])\n\t\ts.deferBitsTemp = deferBitsTemp\n\t\t// For this value, AuxInt is initialized to zero by default\n\t\tstartDeferBits := s.entryNewValue0(ssa.OpConst8, types.Types[TUINT8]) // 1字节的常量,最初为0\n\t\ts.vars[&deferBitsVar] = startDeferBits\n\t\ts.deferBitsAddr = s.addr(deferBitsTemp)\n\t\ts.store(types.Types[TUINT8], s.deferBitsAddr, startDeferBits)\n\t\t// Make sure that the deferBits stack slot is kept alive (for use\n\t\t// by panics) and stores to deferBits are not eliminated, even if\n\t\t// all checking code on deferBits in the function exit can be\n\t\t// eliminated, because the defer statements were all\n\t\t// unconditional.\n\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarLive, types.TypeMem, deferBitsTemp, s.mem(), false)\n\t}\n\n\t// Generate addresses of local declarations\n\ts.decladdrs = map[*Node]*ssa.Value{}\n\tfor _, n := range fn.Func.Dcl {\n\t\tswitch n.Class() {\n\t\tcase PPARAM, PPARAMOUT:\n\t\t\ts.decladdrs[n] = s.entryNewValue2A(ssa.OpLocalAddr, types.NewPtr(n.Type), n, s.sp, s.startmem)\n\t\t\tif n.Class() == PPARAMOUT && s.canSSA(n) {\n\t\t\t\t// Save ssa-able PPARAMOUT variables so we can\n\t\t\t\t// store them back to the stack at the end of\n\t\t\t\t// the function.\n\t\t\t\ts.returns = append(s.returns, n)\n\t\t\t}\n\t\tcase PAUTO:\n\t\t\t// processed at each use, to prevent Addr coming\n\t\t\t// before the decl.\n\t\tcase PAUTOHEAP:\n\t\t\t// moved to heap - already handled by frontend\n\t\tcase PFUNC:\n\t\t\t// local function - already handled by frontend\n\t\tdefault:\n\t\t\ts.Fatalf(\"local variable with class %v unimplemented\", n.Class())\n\t\t}\n\t}\n\n\t// Populate SSAable arguments.\n\tfor _, n := range fn.Func.Dcl {\n\t\tif n.Class() == PPARAM && s.canSSA(n) {\n\t\t\tv := s.newValue0A(ssa.OpArg, n.Type, n)\n\t\t\ts.vars[n] = v         // 记录在vars中,相当于入参被声明了\n\t\t\ts.addNamedValue(n, v) // This helps with debugging information, not needed for compilation itself.\n\t\t}\n\t}\n\n\t// Convert the AST-based IR to the SSA-based IR\n\ts.stmtList(fn.Func.Enter)\n\ts.stmtList(fn.Nbody)\n\n\t// fallthrough to exit\n\tif s.curBlock != nil {\n\t\ts.pushLine(fn.Func.Endlineno)\n\t\ts.exit()\n\t\ts.popLine()\n\t}\n\n\tfor _, b := range s.f.Blocks { // 设置每个块的前驱块到自己的第一行的位置,用于调试时分支流程的跳转\n\t\tif b.Pos != src.NoXPos {\n\t\t\ts.updateUnsetPredPos(b)\n\t\t}\n\t}\n\n\ts.insertPhis()\n\n\t// Main call to ssa package to compile function\n\tssa.Compile(s.f)\n\n\tif s.hasOpenDefers {\n\t\ts.emitOpenDeferInfo()\n\t}\n\n\treturn s.f\n}\n\nfunc dumpSourcesColumn(writer *ssa.HTMLWriter, fn *Node) {\n\t// Read sources of target function fn.\n\tfname := Ctxt.PosTable.Pos(fn.Pos).Filename()\n\ttargetFn, err := readFuncLines(fname, fn.Pos.Line(), fn.Func.Endlineno.Line())\n\tif err != nil {\n\t\twriter.Logf(\"cannot read sources for function %v: %v\", fn, err)\n\t}\n\n\t// Read sources of inlined functions.\n\tvar inlFns []*ssa.FuncLines\n\tfor _, fi := range ssaDumpInlined {\n\t\tvar elno src.XPos\n\t\tif fi.Name.Defn == nil {\n\t\t\t// Endlineno is filled from exported data.\n\t\t\telno = fi.Func.Endlineno\n\t\t} else {\n\t\t\telno = fi.Name.Defn.Func.Endlineno\n\t\t}\n\t\tfname := Ctxt.PosTable.Pos(fi.Pos).Filename()\n\t\tfnLines, err := readFuncLines(fname, fi.Pos.Line(), elno.Line())\n\t\tif err != nil {\n\t\t\twriter.Logf(\"cannot read sources for inlined function %v: %v\", fi, err)\n\t\t\tcontinue\n\t\t}\n\t\tinlFns = append(inlFns, fnLines)\n\t}\n\n\tsort.Sort(ssa.ByTopo(inlFns))\n\tif targetFn != nil {\n\t\tinlFns = append([]*ssa.FuncLines{targetFn}, inlFns...)\n\t}\n\n\twriter.WriteSources(\"sources\", inlFns)\n}\n\nfunc readFuncLines(file string, start, end uint) (*ssa.FuncLines, error) {\n\tf, err := os.Open(os.ExpandEnv(file))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\tvar lines []string\n\tln := uint(1)\n\tscanner := bufio.NewScanner(f)\n\tfor scanner.Scan() && ln <= end {\n\t\tif ln >= start {\n\t\t\tlines = append(lines, scanner.Text())\n\t\t}\n\t\tln++\n\t}\n\treturn &ssa.FuncLines{Filename: file, StartLineno: start, Lines: lines}, nil\n}\n\n// updateUnsetPredPos propagates the earliest-value position information for b\n// towards all of b's predecessors that need a position, and recurs on that\n// predecessor if its position is updated. B should have a non-empty position.\nfunc (s *state) updateUnsetPredPos(b *ssa.Block) {\n\tif b.Pos == src.NoXPos {\n\t\ts.Fatalf(\"Block %s should have a position\", b)\n\t}\n\tbestPos := src.NoXPos\n\tfor _, e := range b.Preds { // 遍历块b的所有前驱\n\t\tp := e.Block() // 获取b的前驱块\n\t\tif !p.LackingPos() {\n\t\t\tcontinue\n\t\t}\n\t\tif bestPos == src.NoXPos {\n\t\t\tbestPos = b.Pos\n\t\t\tfor _, v := range b.Values {\n\t\t\t\tif v.LackingPos() {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif v.Pos != src.NoXPos {\n\t\t\t\t\t// Assume values are still in roughly textual order;\n\t\t\t\t\t// TODO: could also seek minimum position?\n\t\t\t\t\tbestPos = v.Pos // bestPos会被设置为b块的第一行有效的ssa代码的位置\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tp.Pos = bestPos         // 设置前驱块的Pos为当前块的第一行有效的ssa代码的位置\n\t\ts.updateUnsetPredPos(p) // We do not expect long chains of these, thus recursion is okay.\t递归设置前驱块对应的代码位置\n\t}\n}\n\n// Information about each open-coded defer.\ntype openDeferInfo struct {\n\t// The ODEFER node representing the function call of the defer\n\tn *Node\n\t// If defer call is closure call, the address of the argtmp where the\n\t// closure is stored.\n\tclosure *ssa.Value\n\t// The node representing the argtmp where the closure is stored - used for\n\t// function, method, or interface call, to store a closure that panic\n\t// processing can use for this defer.\n\tclosureNode *Node\n\t// If defer call is interface call, the address of the argtmp where the\n\t// receiver is stored\n\trcvr *ssa.Value\n\t// The node representing the argtmp where the receiver is stored\n\trcvrNode *Node\n\t// The addresses of the argtmps where the evaluated arguments of the defer\n\t// function call are stored.\n\targVals []*ssa.Value\n\t// The nodes representing the argtmps where the args of the defer are stored\n\targNodes []*Node\n}\n\ntype state struct {\n\t// configuration (arch) information\n\tconfig *ssa.Config\n\n\t// function we're building\n\tf *ssa.Func\n\n\t// Node for function\n\tcurfn *Node // ssa编译的函数节点\n\n\t// labels and labeled control flow nodes (OFOR, OFORUNTIL, OSWITCH, OSELECT) in f\n\tlabels       map[string]*ssaLabel // label的字符串对应的label节点转化的ssaLabel\n\tlabeledNodes map[*Node]*ssaLabel  // 声明label的节点对应的label节点转化的ssaLabel, label声明在OFOR, OFORUNTIL, OSWITCH, OSELECT这四种类型的节点上\n\n\t// unlabeled break and continue statement tracking\n\tbreakTo    *ssa.Block // current target for plain break statement\n\tcontinueTo *ssa.Block // current target for plain continue statement\n\n\t// current location where we're interpreting the AST\n\tcurBlock *ssa.Block\n\n\t// variable assignments in the current block (map from variable symbol to ssa value)\n\t// *Node is the unique identifier (an ONAME Node) for the variable.\n\t// TODO: keep a single varnum map, then make all of these maps slices instead?\n\tvars map[*Node]*ssa.Value // 这里面记录的应该是被赋值的变量,函数的入参也在此行列\n\n\t// fwdVars are variables that are used before they are defined in the current block.\n\t// This map exists just to coalesce multiple references into a single FwdRef op.\n\t// *Node is the unique identifier (an ONAME Node) for the variable.\n\tfwdVars map[*Node]*ssa.Value // 在当前块的入口处活跃的变量\n\n\t// all defined variables at the end of each block. Indexed by block ID.\n\tdefvars []map[*Node]*ssa.Value // 每个块ID对应该块中Node节点对应声明的Value\n\n\t// addresses of PPARAM and PPARAMOUT variables.\n\tdecladdrs map[*Node]*ssa.Value // s.entryNewValue2A(ssa.OpLocalAddr, types.NewPtr(n.Type), n, s.sp, s.startmem)\n\n\t// starting values. Memory, stack pointer, and globals pointer\n\tstartmem *ssa.Value\n\tsp       *ssa.Value // stack pointer,\n\tsb       *ssa.Value // globals pointer\n\t// value representing address of where deferBits autotmp is stored\n\tdeferBitsAddr *ssa.Value\n\tdeferBitsTemp *Node\n\n\t// line number stack. The current line number is top of stack\n\tline []src.XPos\n\t// the last line number processed; it may have been popped\n\tlastPos src.XPos\n\n\t// list of panic calls by function name and line number.\n\t// Used to deduplicate panic calls.\n\tpanics map[funcLine]*ssa.Block\n\n\t// list of PPARAMOUT (return) variables.\n\treturns []*Node\n\n\tcgoUnsafeArgs bool // fn.Func.Pragma&CgoUnsafeArgs != 0\n\thasdefer      bool // whether the function contains a defer statement\n\tsoftFloat     bool // s.config.SoftFloat\n\thasOpenDefers bool // whether we are doing open-coded defers\t\t Debug['N'] == 0 && s.hasdefer && !s.curfn.Func.OpenCodedDeferDisallowed()\n\n\t// If doing open-coded defers, list of info about the defer calls in\n\t// scanning order. Hence, at exit we should run these defers in reverse\n\t// order of this list\n\topenDefers []*openDeferInfo\n\t// For open-coded defers, this is the beginning and end blocks of the last\n\t// defer exit code that we have generated so far. We use these to share\n\t// code between exits if the shareDeferExits option (disabled by default)\n\t// is on.\n\tlastDeferExit       *ssa.Block // Entry block of last defer exit code we generated\n\tlastDeferFinalBlock *ssa.Block // Final block of last defer exit code we generated\n\tlastDeferCount      int        // Number of defers encountered at that point\n}\n\ntype funcLine struct {\n\tf    *obj.LSym\n\tbase *src.PosBase\n\tline uint\n}\n\ntype ssaLabel struct {\n\ttarget         *ssa.Block // block identified by this label\t\tlabel所标记的块\n\tbreakTarget    *ssa.Block // block to break to in control flow node identified by this label\t// 循环结束时的代码块\n\tcontinueTarget *ssa.Block // block to continue to in control flow node identified by this label\t\t循环中的迭代语句\n}\n\n// label returns the label associated with sym, creating it if necessary.\nfunc (s *state) label(sym *types.Sym) *ssaLabel {\n\tlab := s.labels[sym.Name]\n\tif lab == nil {\n\t\tlab = new(ssaLabel)\n\t\ts.labels[sym.Name] = lab\n\t}\n\treturn lab\n}\n\nfunc (s *state) Logf(msg string, args ...interface{}) { s.f.Logf(msg, args...) }\nfunc (s *state) Log() bool                            { return s.f.Log() }\nfunc (s *state) Fatalf(msg string, args ...interface{}) {\n\ts.f.Frontend().Fatalf(s.peekPos(), msg, args...)\n}\nfunc (s *state) Warnl(pos src.XPos, msg string, args ...interface{}) { s.f.Warnl(pos, msg, args...) }\nfunc (s *state) Debug_checknil() bool                                { return s.f.Frontend().Debug_checknil() }\n\nvar (\n\t// dummy node for the memory variable\n\tmemVar = Node{Op: ONAME, Sym: &types.Sym{Name: \"mem\"}}\n\n\t// dummy nodes for temporary variables\n\tptrVar       = Node{Op: ONAME, Sym: &types.Sym{Name: \"ptr\"}}\n\tlenVar       = Node{Op: ONAME, Sym: &types.Sym{Name: \"len\"}}\n\tnewlenVar    = Node{Op: ONAME, Sym: &types.Sym{Name: \"newlen\"}}\n\tcapVar       = Node{Op: ONAME, Sym: &types.Sym{Name: \"cap\"}}\n\ttypVar       = Node{Op: ONAME, Sym: &types.Sym{Name: \"typ\"}}\n\tokVar        = Node{Op: ONAME, Sym: &types.Sym{Name: \"ok\"}}\n\tdeferBitsVar = Node{Op: ONAME, Sym: &types.Sym{Name: \"deferBits\"}}\n\tminVar       = Node{Op: ONAME, Sym: &types.Sym{Name: \"min\"}}\n\tmaxVar       = Node{Op: ONAME, Sym: &types.Sym{Name: \"max\"}}\n)\n\n// startBlock sets the current block we're generating code in to b.\nfunc (s *state) startBlock(b *ssa.Block) {\n\tif s.curBlock != nil {\n\t\ts.Fatalf(\"starting block %v when block %v has not ended\", b, s.curBlock)\n\t}\n\ts.curBlock = b\n\ts.vars = map[*Node]*ssa.Value{} // 清空s.var\n\tfor n := range s.fwdVars {      // 清空s.fwdVars\n\t\tdelete(s.fwdVars, n)\n\t}\n}\n\n// endBlock marks the end of generating code for the current block.\n// Returns the (former) current block. Returns nil if there is no current\n// block, i.e. if no code flows to the current execution point.\nfunc (s *state) endBlock() *ssa.Block {\n\tb := s.curBlock // 获取当前的block\n\tif b == nil {\n\t\treturn nil\n\t}\n\tfor len(s.defvars) <= int(b.ID) {\n\t\ts.defvars = append(s.defvars, nil)\n\t}\n\ts.defvars[b.ID] = s.vars // 记录所有被赋值的变量\n\ts.curBlock = nil\n\ts.vars = nil\n\tif b.LackingPos() {\n\t\t// Empty plain blocks get the line of their successor (handled after all blocks created),\n\t\t// except for increment blocks in For statements (handled in ssa conversion of OFOR),\n\t\t// and for blocks ending in GOTO/BREAK/CONTINUE.\n\t\tb.Pos = src.NoXPos\n\t} else {\n\t\tb.Pos = s.lastPos\n\t}\n\treturn b\n}\n\n// pushLine pushes a line number on the line number stack.\nfunc (s *state) pushLine(line src.XPos) {\n\tif !line.IsKnown() {\n\t\t// the frontend may emit node with line number missing,\n\t\t// use the parent line number in this case.\n\t\tline = s.peekPos()\n\t\tif Debug['K'] != 0 {\n\t\t\tWarn(\"buildssa: unknown position (line 0)\")\n\t\t}\n\t} else {\n\t\ts.lastPos = line\n\t}\n\n\ts.line = append(s.line, line)\n}\n\n// popLine pops the top of the line number stack.\nfunc (s *state) popLine() {\n\ts.line = s.line[:len(s.line)-1]\n}\n\n// peekPos peeks the top of the line number stack.\nfunc (s *state) peekPos() src.XPos {\n\treturn s.line[len(s.line)-1]\n}\n\n// newValue0 adds a new value with no arguments to the current block.\nfunc (s *state) newValue0(op ssa.Op, t *types.Type) *ssa.Value {\n\treturn s.curBlock.NewValue0(s.peekPos(), op, t)\n}\n\n// newValue0A adds a new value with no arguments and an aux value to the current block.\nfunc (s *state) newValue0A(op ssa.Op, t *types.Type, aux interface{}) *ssa.Value {\n\treturn s.curBlock.NewValue0A(s.peekPos(), op, t, aux)\n}\n\n// newValue0I adds a new value with no arguments and an auxint value to the current block.\nfunc (s *state) newValue0I(op ssa.Op, t *types.Type, auxint int64) *ssa.Value {\n\treturn s.curBlock.NewValue0I(s.peekPos(), op, t, auxint)\n}\n\n// newValue1 adds a new value with one argument to the current block.\nfunc (s *state) newValue1(op ssa.Op, t *types.Type, arg *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue1(s.peekPos(), op, t, arg)\n}\n\n// newValue1A adds a new value with one argument and an aux value to the current block.\nfunc (s *state) newValue1A(op ssa.Op, t *types.Type, aux interface{}, arg *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue1A(s.peekPos(), op, t, aux, arg)\n}\n\n// newValue1Apos adds a new value with one argument and an aux value to the current block.\n// isStmt determines whether the created values may be a statement or not\n// (i.e., false means never, yes means maybe).\nfunc (s *state) newValue1Apos(op ssa.Op, t *types.Type, aux interface{}, arg *ssa.Value, isStmt bool) *ssa.Value {\n\tif isStmt {\n\t\treturn s.curBlock.NewValue1A(s.peekPos(), op, t, aux, arg)\n\t}\n\treturn s.curBlock.NewValue1A(s.peekPos().WithNotStmt(), op, t, aux, arg)\n}\n\n// newValue1I adds a new value with one argument and an auxint value to the current block.\nfunc (s *state) newValue1I(op ssa.Op, t *types.Type, aux int64, arg *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue1I(s.peekPos(), op, t, aux, arg)\n}\n\n// newValue2 adds a new value with two arguments to the current block.\nfunc (s *state) newValue2(op ssa.Op, t *types.Type, arg0, arg1 *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue2(s.peekPos(), op, t, arg0, arg1)\n}\n\n// newValue2Apos adds a new value with two arguments and an aux value to the current block.\n// isStmt determines whether the created values may be a statement or not\n// (i.e., false means never, yes means maybe).\nfunc (s *state) newValue2Apos(op ssa.Op, t *types.Type, aux interface{}, arg0, arg1 *ssa.Value, isStmt bool) *ssa.Value {\n\tif isStmt {\n\t\treturn s.curBlock.NewValue2A(s.peekPos(), op, t, aux, arg0, arg1)\n\t}\n\treturn s.curBlock.NewValue2A(s.peekPos().WithNotStmt(), op, t, aux, arg0, arg1)\n}\n\n// newValue2I adds a new value with two arguments and an auxint value to the current block.\nfunc (s *state) newValue2I(op ssa.Op, t *types.Type, aux int64, arg0, arg1 *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue2I(s.peekPos(), op, t, aux, arg0, arg1)\n}\n\n// newValue3 adds a new value with three arguments to the current block.\nfunc (s *state) newValue3(op ssa.Op, t *types.Type, arg0, arg1, arg2 *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue3(s.peekPos(), op, t, arg0, arg1, arg2)\n}\n\n// newValue3I adds a new value with three arguments and an auxint value to the current block.\nfunc (s *state) newValue3I(op ssa.Op, t *types.Type, aux int64, arg0, arg1, arg2 *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue3I(s.peekPos(), op, t, aux, arg0, arg1, arg2)\n}\n\n// newValue3A adds a new value with three arguments and an aux value to the current block.\nfunc (s *state) newValue3A(op ssa.Op, t *types.Type, aux interface{}, arg0, arg1, arg2 *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue3A(s.peekPos(), op, t, aux, arg0, arg1, arg2)\n}\n\n// newValue3Apos adds a new value with three arguments and an aux value to the current block.\n// isStmt determines whether the created values may be a statement or not\n// (i.e., false means never, yes means maybe).\nfunc (s *state) newValue3Apos(op ssa.Op, t *types.Type, aux interface{}, arg0, arg1, arg2 *ssa.Value, isStmt bool) *ssa.Value {\n\tif isStmt {\n\t\treturn s.curBlock.NewValue3A(s.peekPos(), op, t, aux, arg0, arg1, arg2)\n\t}\n\treturn s.curBlock.NewValue3A(s.peekPos().WithNotStmt(), op, t, aux, arg0, arg1, arg2)\n}\n\n// newValue4 adds a new value with four arguments to the current block.\nfunc (s *state) newValue4(op ssa.Op, t *types.Type, arg0, arg1, arg2, arg3 *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue4(s.peekPos(), op, t, arg0, arg1, arg2, arg3)\n}\n\n// newValue4 adds a new value with four arguments and an auxint value to the current block.\nfunc (s *state) newValue4I(op ssa.Op, t *types.Type, aux int64, arg0, arg1, arg2, arg3 *ssa.Value) *ssa.Value {\n\treturn s.curBlock.NewValue4I(s.peekPos(), op, t, aux, arg0, arg1, arg2, arg3)\n}\n\n// entryNewValue0 adds a new value with no arguments to the entry block.\nfunc (s *state) entryNewValue0(op ssa.Op, t *types.Type) *ssa.Value {\n\treturn s.f.Entry.NewValue0(src.NoXPos, op, t)\n}\n\n// entryNewValue0A adds a new value with no arguments and an aux value to the entry block.\nfunc (s *state) entryNewValue0A(op ssa.Op, t *types.Type, aux interface{}) *ssa.Value {\n\treturn s.f.Entry.NewValue0A(src.NoXPos, op, t, aux)\n}\n\n// entryNewValue1 adds a new value with one argument to the entry block.\nfunc (s *state) entryNewValue1(op ssa.Op, t *types.Type, arg *ssa.Value) *ssa.Value {\n\treturn s.f.Entry.NewValue1(src.NoXPos, op, t, arg)\n}\n\n// entryNewValue1 adds a new value with one argument and an auxint value to the entry block.\nfunc (s *state) entryNewValue1I(op ssa.Op, t *types.Type, auxint int64, arg *ssa.Value) *ssa.Value {\n\treturn s.f.Entry.NewValue1I(src.NoXPos, op, t, auxint, arg)\n}\n\n// entryNewValue1A adds a new value with one argument and an aux value to the entry block.\nfunc (s *state) entryNewValue1A(op ssa.Op, t *types.Type, aux interface{}, arg *ssa.Value) *ssa.Value {\n\treturn s.f.Entry.NewValue1A(src.NoXPos, op, t, aux, arg)\n}\n\n// entryNewValue2 adds a new value with two arguments to the entry block.\nfunc (s *state) entryNewValue2(op ssa.Op, t *types.Type, arg0, arg1 *ssa.Value) *ssa.Value {\n\treturn s.f.Entry.NewValue2(src.NoXPos, op, t, arg0, arg1)\n}\n\n// entryNewValue2A adds a new value with two arguments and an aux value to the entry block.\nfunc (s *state) entryNewValue2A(op ssa.Op, t *types.Type, aux interface{}, arg0, arg1 *ssa.Value) *ssa.Value {\n\treturn s.f.Entry.NewValue2A(src.NoXPos, op, t, aux, arg0, arg1)\n}\n\n// const* routines add a new const value to the entry block.\nfunc (s *state) constSlice(t *types.Type) *ssa.Value {\n\treturn s.f.ConstSlice(t)\n}\nfunc (s *state) constInterface(t *types.Type) *ssa.Value {\n\treturn s.f.ConstInterface(t)\n}\nfunc (s *state) constNil(t *types.Type) *ssa.Value { return s.f.ConstNil(t) }\nfunc (s *state) constEmptyString(t *types.Type) *ssa.Value {\n\treturn s.f.ConstEmptyString(t)\n}\nfunc (s *state) constBool(c bool) *ssa.Value {\n\treturn s.f.ConstBool(types.Types[TBOOL], c)\n}\nfunc (s *state) constInt8(t *types.Type, c int8) *ssa.Value {\n\treturn s.f.ConstInt8(t, c)\n}\nfunc (s *state) constInt16(t *types.Type, c int16) *ssa.Value {\n\treturn s.f.ConstInt16(t, c)\n}\nfunc (s *state) constInt32(t *types.Type, c int32) *ssa.Value {\n\treturn s.f.ConstInt32(t, c)\n}\nfunc (s *state) constInt64(t *types.Type, c int64) *ssa.Value {\n\treturn s.f.ConstInt64(t, c)\n}\nfunc (s *state) constFloat32(t *types.Type, c float64) *ssa.Value {\n\treturn s.f.ConstFloat32(t, c)\n}\nfunc (s *state) constFloat64(t *types.Type, c float64) *ssa.Value {\n\treturn s.f.ConstFloat64(t, c)\n}\nfunc (s *state) constInt(t *types.Type, c int64) *ssa.Value {\n\tif s.config.PtrSize == 8 {\n\t\treturn s.constInt64(t, c)\n\t}\n\tif int64(int32(c)) != c {\n\t\ts.Fatalf(\"integer constant too big %d\", c)\n\t}\n\treturn s.constInt32(t, int32(c))\n}\nfunc (s *state) constOffPtrSP(t *types.Type, c int64) *ssa.Value {\n\treturn s.f.ConstOffPtrSP(t, c, s.sp)\n}\n\n// newValueOrSfCall* are wrappers around newValue*, which may create a call to a\n// soft-float runtime function instead (when emitting soft-float code).\nfunc (s *state) newValueOrSfCall1(op ssa.Op, t *types.Type, arg *ssa.Value) *ssa.Value {\n\tif s.softFloat {\n\t\tif c, ok := s.sfcall(op, arg); ok {\n\t\t\treturn c\n\t\t}\n\t}\n\treturn s.newValue1(op, t, arg)\n}\nfunc (s *state) newValueOrSfCall2(op ssa.Op, t *types.Type, arg0, arg1 *ssa.Value) *ssa.Value {\n\tif s.softFloat {\n\t\tif c, ok := s.sfcall(op, arg0, arg1); ok {\n\t\t\treturn c\n\t\t}\n\t}\n\treturn s.newValue2(op, t, arg0, arg1)\n}\n\nfunc (s *state) instrument(t *types.Type, addr *ssa.Value, wr bool) {\n\tif !s.curfn.Func.InstrumentBody() {\n\t\treturn\n\t}\n\n\tw := t.Size()\n\tif w == 0 {\n\t\treturn // can't race on zero-sized things\n\t}\n\n\tif ssa.IsSanitizerSafeAddr(addr) {\n\t\treturn\n\t}\n\n\tvar fn *obj.LSym\n\tneedWidth := false\n\n\tif flag_msan {\n\t\tfn = msanread\n\t\tif wr {\n\t\t\tfn = msanwrite\n\t\t}\n\t\tneedWidth = true\n\t} else if flag_race && t.NumComponents(types.CountBlankFields) > 1 {\n\t\t// for composite objects we have to write every address\n\t\t// because a write might happen to any subobject.\n\t\t// composites with only one element don't have subobjects, though.\n\t\tfn = racereadrange\n\t\tif wr {\n\t\t\tfn = racewriterange\n\t\t}\n\t\tneedWidth = true\n\t} else if flag_race {\n\t\t// for non-composite objects we can write just the start\n\t\t// address, as any write must write the first byte.\n\t\tfn = raceread\n\t\tif wr {\n\t\t\tfn = racewrite\n\t\t}\n\t} else {\n\t\tpanic(\"unreachable\")\n\t}\n\n\targs := []*ssa.Value{addr}\n\tif needWidth {\n\t\targs = append(args, s.constInt(types.Types[TUINTPTR], w))\n\t}\n\ts.rtcall(fn, true, nil, args...)\n}\n\nfunc (s *state) load(t *types.Type, src *ssa.Value) *ssa.Value {\n\ts.instrument(t, src, false)\n\treturn s.rawLoad(t, src)\n}\n\nfunc (s *state) rawLoad(t *types.Type, src *ssa.Value) *ssa.Value {\n\treturn s.newValue2(ssa.OpLoad, t, src, s.mem())\n}\n\n// t是参数类型, dst是存储的地址,val为存储的内容(参数)\nfunc (s *state) store(t *types.Type, dst, val *ssa.Value) {\n\ts.vars[&memVar] = s.newValue3A(ssa.OpStore, types.TypeMem, t, dst, val, s.mem())\n}\n\nfunc (s *state) zero(t *types.Type, dst *ssa.Value) {\n\ts.instrument(t, dst, true)\n\tstore := s.newValue2I(ssa.OpZero, types.TypeMem, t.Size(), dst, s.mem())\n\tstore.Aux = t\n\ts.vars[&memVar] = store\n}\n\nfunc (s *state) move(t *types.Type, dst, src *ssa.Value) {\n\ts.instrument(t, src, false)\n\ts.instrument(t, dst, true)\n\tstore := s.newValue3I(ssa.OpMove, types.TypeMem, t.Size(), dst, src, s.mem())\n\tstore.Aux = t\n\ts.vars[&memVar] = store\n}\n\n// stmtList converts the statement list n to SSA and adds it to s.\nfunc (s *state) stmtList(l Nodes) {\n\tfor _, n := range l.Slice() {\n\t\ts.stmt(n)\n\t}\n}\n\n// stmt converts the statement n to SSA and adds it to s.\nfunc (s *state) stmt(n *Node) {\n\tif !(n.Op == OVARKILL || n.Op == OVARLIVE || n.Op == OVARDEF) {\n\t\t// OVARKILL, OVARLIVE, and OVARDEF are invisible to the programmer, so we don't use their line numbers to avoid confusion in debugging.\n\t\ts.pushLine(n.Pos)\n\t\tdefer s.popLine()\n\t}\n\n\t// If s.curBlock is nil, and n isn't a label (which might have an associated goto somewhere),\n\t// then this code is dead. Stop here.\n\tif s.curBlock == nil && n.Op != OLABEL {\n\t\treturn\n\t}\n\n\ts.stmtList(n.Ninit)\n\tswitch n.Op {\n\n\tcase OBLOCK:\n\t\ts.stmtList(n.List)\n\n\t// No-ops\n\tcase OEMPTY, ODCLCONST, ODCLTYPE, OFALL:\n\n\t// Expression statements\n\tcase OCALLFUNC:\n\t\tif isIntrinsicCall(n) { // 处理内部的函数调用比如sync/atomic或者math等\n\t\t\ts.intrinsicCall(n)\n\t\t\treturn\n\t\t}\n\t\tfallthrough\n\n\tcase OCALLMETH, OCALLINTER: // Left(List/Rlist) (direct method call x.Method(args)), Left(List/Rlist) (interface method call x.Method(args))\n\t\ts.call(n, callNormal)\n\t\tif n.Op == OCALLFUNC && n.Left.Op == ONAME && n.Left.Class() == PFUNC { // 是一个函数调用\n\t\t\tif fn := n.Left.Sym.Name; compiling_runtime && fn == \"throw\" ||\n\t\t\t\tn.Left.Sym.Pkg == Runtimepkg && (fn == \"throwinit\" || fn == \"gopanic\" || fn == \"panicwrap\" || fn == \"block\" || fn == \"panicmakeslicelen\" || fn == \"panicmakeslicecap\") {\n\t\t\t\tm := s.mem()\n\t\t\t\tb := s.endBlock()\n\t\t\t\tb.Kind = ssa.BlockExit\n\t\t\t\tb.SetControl(m)\n\t\t\t\t// TODO: never rewrite OPANIC to OCALLFUNC in the\n\t\t\t\t// first place. Need to wait until all backends\n\t\t\t\t// go through SSA.\n\t\t\t}\n\t\t}\n\tcase ODEFER: // defer Left (Left must be call)\n\t\tif Debug_defer > 0 {\n\t\t\tvar defertype string\n\t\t\tif s.hasOpenDefers {\n\t\t\t\tdefertype = \"open-coded\"\n\t\t\t} else if n.Esc == EscNever {\n\t\t\t\tdefertype = \"stack-allocated\"\n\t\t\t} else {\n\t\t\t\tdefertype = \"heap-allocated\"\n\t\t\t}\n\t\t\tWarnl(n.Pos, \"%s defer\", defertype)\n\t\t}\n\t\tif s.hasOpenDefers {\n\t\t\ts.openDeferRecord(n.Left)\n\t\t} else {\n\t\t\td := callDefer\n\t\t\tif n.Esc == EscNever { // 当前节点未逃逸\n\t\t\t\td = callDeferStack\n\t\t\t}\n\t\t\ts.call(n.Left, d)\n\t\t}\n\tcase OGO: // go Left (Left must be call)\n\t\ts.call(n.Left, callGo)\n\n\tcase OAS2DOTTYPE: // List = Right (x, ok = I.(int))\n\t\tres, resok := s.dottype(n.Right, true)\n\t\tderef := false\n\t\tif !canSSAType(n.Right.Type) {\n\t\t\tif res.Op != ssa.OpLoad {\n\t\t\t\ts.Fatalf(\"dottype of non-load\")\n\t\t\t}\n\t\t\tmem := s.mem()\n\t\t\tif mem.Op == ssa.OpVarKill {\n\t\t\t\tmem = mem.Args[0]\n\t\t\t}\n\t\t\tif res.Args[1] != mem {\n\t\t\t\ts.Fatalf(\"memory no longer live from 2-result dottype load\")\n\t\t\t}\n\t\t\tderef = true\n\t\t\tres = res.Args[0]\n\t\t}\n\t\ts.assign(n.List.First(), res, deref, 0)\n\t\ts.assign(n.List.Second(), resok, false, 0)\n\t\treturn\n\n\tcase OAS2FUNC: // List = Right (x, y = f())\n\t\t// We come here only when it is an intrinsic call returning two values.\n\t\tif !isIntrinsicCall(n.Right) {\n\t\t\ts.Fatalf(\"non-intrinsic AS2FUNC not expanded %v\", n.Right)\n\t\t}\n\t\tv := s.intrinsicCall(n.Right)\n\t\tv1 := s.newValue1(ssa.OpSelect0, n.List.First().Type, v)\n\t\tv2 := s.newValue1(ssa.OpSelect1, n.List.Second().Type, v)\n\t\ts.assign(n.List.First(), v1, false, 0)\n\t\ts.assign(n.List.Second(), v2, false, 0)\n\t\treturn\n\n\tcase ODCL: // var Left (declares Left of type Left.Type)\n\t\tif n.Left.Class() == PAUTOHEAP {\n\t\t\ts.Fatalf(\"DCL %v\", n)\n\t\t}\n\n\tcase OLABEL:\n\t\tsym := n.Sym\n\t\tlab := s.label(sym)\n\n\t\t// Associate label with its control flow node, if any\n\t\tif ctl := n.labeledControl(); ctl != nil {\n\t\t\ts.labeledNodes[ctl] = lab // 标记控制节点上声明的label\n\t\t}\n\n\t\t// The label might already have a target block via a goto.\n\t\tif lab.target == nil {\n\t\t\tlab.target = s.f.NewBlock(ssa.BlockPlain) // 设置label所标记的块\n\t\t}\n\n\t\t// Go to that label.\n\t\t// (We pretend \"label:\" is preceded by \"goto label\", unless the predecessor is unreachable.)\n\t\tif s.curBlock != nil { // 当这里判断为false时,应该是在entry block里的第一行有效代码就是一个label\n\t\t\tb := s.endBlock()       // 结束当前块\n\t\t\tb.AddEdgeTo(lab.target) // 设置当前块的后继为label处\n\t\t}\n\t\ts.startBlock(lab.target) // 开始处理label所标记的块\n\n\tcase OGOTO: // goto Sym\n\t\tsym := n.Sym // 获取跳转到的符号(label)\n\n\t\tlab := s.label(sym)    // 通过label符号获取对应的label\n\t\tif lab.target == nil { // 出现这种情况应该是goto label出现在那个label的前面,导致还没有处理这个label\n\t\t\tlab.target = s.f.NewBlock(ssa.BlockPlain)\n\t\t}\n\n\t\tb := s.endBlock()\n\t\tb.Pos = s.lastPos.WithIsStmt() // Do this even if b is an empty block.\n\t\tb.AddEdgeTo(lab.target)        // goto 所在块可以到label标记的块\n\n\tcase OAS: // Left = Right or (if Colas=true) Left := Right\n\t\tif n.Left == n.Right && n.Left.Op == ONAME {\n\t\t\t// An x=x assignment. No point in doing anything\n\t\t\t// here. In addition, skipping this assignment\n\t\t\t// prevents generating:\n\t\t\t//   VARDEF x\n\t\t\t//   COPY x -> x\n\t\t\t// which is bad because x is incorrectly considered\n\t\t\t// dead before the vardef. See issue #14904.\n\t\t\treturn\n\t\t}\n\n\t\t// Evaluate RHS.\n\t\trhs := n.Right\n\t\tif rhs != nil {\n\t\t\tswitch rhs.Op {\n\t\t\tcase OSTRUCTLIT, OARRAYLIT, OSLICELIT:\n\t\t\t\t// All literals with nonzero fields have already been\n\t\t\t\t// rewritten during walk. Any that remain are just T{}\n\t\t\t\t// or equivalents. Use the zero value.\n\t\t\t\tif !isZero(rhs) {\n\t\t\t\t\ts.Fatalf(\"literal with nonzero value in SSA: %v\", rhs)\n\t\t\t\t}\n\t\t\t\trhs = nil\n\t\t\tcase OAPPEND: // append(List); after walk, Left may contain elem type descriptor\n\t\t\t\t// Check whether we're writing the result of an append back to the same slice.\n\t\t\t\t// If so, we handle it specially to avoid write barriers on the fast\n\t\t\t\t// (non-growth) path.\n\t\t\t\tif !samesafeexpr(n.Left, rhs.List.First()) || Debug['N'] != 0 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\t// If the slice can be SSA'd, it'll be on the stack,\n\t\t\t\t// so there will be no write barriers,\n\t\t\t\t// so there's no need to attempt to prevent them.\n\t\t\t\tif s.canSSA(n.Left) {\n\t\t\t\t\tif Debug_append > 0 { // replicating old diagnostic message\n\t\t\t\t\t\tWarnl(n.Pos, \"append: len-only update (in local slice)\")\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif Debug_append > 0 {\n\t\t\t\t\tWarnl(n.Pos, \"append: len-only update\")\n\t\t\t\t}\n\t\t\t\ts.append(rhs, true)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tif n.Left.isBlank() {\n\t\t\t// _ = rhs\n\t\t\t// Just evaluate rhs for side-effects.\n\t\t\tif rhs != nil {\n\t\t\t\ts.expr(rhs)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tvar t *types.Type\n\t\tif n.Right != nil {\n\t\t\tt = n.Right.Type\n\t\t} else {\n\t\t\tt = n.Left.Type\n\t\t}\n\n\t\tvar r *ssa.Value\n\t\tderef := !canSSAType(t)\n\t\tif deref {\n\t\t\tif rhs == nil {\n\t\t\t\tr = nil // Signal assign to use OpZero.\n\t\t\t} else {\n\t\t\t\tr = s.addr(rhs)\n\t\t\t}\n\t\t} else {\n\t\t\tif rhs == nil {\n\t\t\t\tr = s.zeroVal(t)\n\t\t\t} else {\n\t\t\t\tr = s.expr(rhs)\n\t\t\t}\n\t\t}\n\n\t\tvar skip skipMask\n\t\tif rhs != nil && (rhs.Op == OSLICE || rhs.Op == OSLICE3 || rhs.Op == OSLICESTR) && samesafeexpr(rhs.Left, n.Left) {\n\t\t\t// We're assigning a slicing operation back to its source.\n\t\t\t// Don't write back fields we aren't changing. See issue #14855.\n\t\t\ti, j, k := rhs.SliceBounds()\n\t\t\tif i != nil && (i.Op == OLITERAL && i.Val().Ctype() == CTINT && i.Int64() == 0) {\n\t\t\t\t// [0:...] is the same as [:...]\n\t\t\t\ti = nil\n\t\t\t}\n\t\t\t// TODO: detect defaults for len/cap also.\n\t\t\t// Currently doesn't really work because (*p)[:len(*p)] appears here as:\n\t\t\t//    tmp = len(*p)\n\t\t\t//    (*p)[:tmp]\n\t\t\t//if j != nil && (j.Op == OLEN && samesafeexpr(j.Left, n.Left)) {\n\t\t\t//      j = nil\n\t\t\t//}\n\t\t\t//if k != nil && (k.Op == OCAP && samesafeexpr(k.Left, n.Left)) {\n\t\t\t//      k = nil\n\t\t\t//}\n\t\t\tif i == nil {\n\t\t\t\tskip |= skipPtr\n\t\t\t\tif j == nil {\n\t\t\t\t\tskip |= skipLen\n\t\t\t\t}\n\t\t\t\tif k == nil {\n\t\t\t\t\tskip |= skipCap\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\ts.assign(n.Left, r, deref, skip)\n\n\tcase OIF: // if Ninit; Left { Nbody } else { Rlist }\n\t\tif Isconst(n.Left, CTBOOL) { // 判断语句是一个布尔常量\n\t\t\ts.stmtList(n.Left.Ninit)\n\t\t\tif n.Left.Bool() { // 根据布尔常量只编译一个分支\n\t\t\t\ts.stmtList(n.Nbody)\n\t\t\t} else {\n\t\t\t\ts.stmtList(n.Rlist)\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\t\tvar likely int8\n\t\tif n.Likely() {\n\t\t\tlikely = 1\n\t\t}\n\t\tvar bThen *ssa.Block\n\t\tif n.Nbody.Len() != 0 {\n\t\t\tbThen = s.f.NewBlock(ssa.BlockPlain)\n\t\t} else { // if的then块中没有语句就跳过\n\t\t\tbThen = bEnd\n\t\t}\n\t\tvar bElse *ssa.Block\n\t\tif n.Rlist.Len() != 0 {\n\t\t\tbElse = s.f.NewBlock(ssa.BlockPlain)\n\t\t} else {\n\t\t\tbElse = bEnd\n\t\t}\n\t\ts.condBranch(n.Left, bThen, bElse, likely)\n\n\t\tif n.Nbody.Len() != 0 {\n\t\t\ts.startBlock(bThen)\n\t\t\ts.stmtList(n.Nbody)\n\t\t\tif b := s.endBlock(); b != nil {\n\t\t\t\tb.AddEdgeTo(bEnd)\n\t\t\t}\n\t\t}\n\t\tif n.Rlist.Len() != 0 {\n\t\t\ts.startBlock(bElse)\n\t\t\ts.stmtList(n.Rlist)\n\t\t\tif b := s.endBlock(); b != nil {\n\t\t\t\tb.AddEdgeTo(bEnd)\n\t\t\t}\n\t\t}\n\t\ts.startBlock(bEnd)\n\n\tcase ORETURN: // return List\n\t\ts.stmtList(n.List)\n\t\tb := s.exit()\n\t\tb.Pos = s.lastPos.WithIsStmt()\n\n\tcase ORETJMP: // return to other function\n\t\ts.stmtList(n.List)\n\t\tb := s.exit()\n\t\tb.Kind = ssa.BlockRetJmp // override BlockRet\n\t\tb.Aux = n.Sym.Linksym()\n\n\tcase OCONTINUE, OBREAK: // continue [Sym], break [Sym]\n\t\tvar to *ssa.Block\n\t\tif n.Sym == nil {\n\t\t\t// plain break/continue\n\t\t\tswitch n.Op {\n\t\t\tcase OCONTINUE:\n\t\t\t\tto = s.continueTo\n\t\t\tcase OBREAK:\n\t\t\t\tto = s.breakTo\n\t\t\t}\n\t\t} else {\n\t\t\t// labeled break/continue; look up the target\n\t\t\tsym := n.Sym\n\t\t\tlab := s.label(sym)\n\t\t\tswitch n.Op {\n\t\t\tcase OCONTINUE:\n\t\t\t\tto = lab.continueTarget\n\t\t\tcase OBREAK:\n\t\t\t\tto = lab.breakTarget\n\t\t\t}\n\t\t}\n\n\t\tb := s.endBlock()\n\t\tb.Pos = s.lastPos.WithIsStmt() // Do this even if b is an empty block.\n\t\tb.AddEdgeTo(to)\n\n\tcase OFOR, OFORUNTIL: // for Ninit; Left; Right { Nbody }\n\t\t// OFOR: for Ninit; Left; Right { Nbody }\n\t\t// cond (Left); body (Nbody); incr (Right)\n\t\t//\n\t\t// OFORUNTIL: for Ninit; Left; Right; List { Nbody }\n\t\t// => body: { Nbody }; incr: Right; if Left { lateincr: List; goto body }; end:\n\t\tbCond := s.f.NewBlock(ssa.BlockPlain)\n\t\tbBody := s.f.NewBlock(ssa.BlockPlain)\n\t\tbIncr := s.f.NewBlock(ssa.BlockPlain)\n\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\n\t\t// ensure empty for loops have correct position; issue #30167\n\t\tbBody.Pos = n.Pos\n\n\t\t// first, jump to condition test (OFOR) or body (OFORUNTIL)\n\t\tb := s.endBlock()\n\t\tif n.Op == OFOR {\n\t\t\tb.AddEdgeTo(bCond)\n\t\t\t// generate code to test condition\n\t\t\ts.startBlock(bCond)\n\t\t\tif n.Left != nil {\n\t\t\t\ts.condBranch(n.Left, bBody, bEnd, 1)\n\t\t\t} else { // for循环中没有条件判断就直接到for循环中的代码块,这就相当于死循环\n\t\t\t\tb := s.endBlock()\n\t\t\t\tb.Kind = ssa.BlockPlain\n\t\t\t\tb.AddEdgeTo(bBody)\n\t\t\t}\n\n\t\t} else { // OFORUNTIL\n\t\t\tb.AddEdgeTo(bBody) // 先进入body块执行\n\t\t}\n\n\t\t// set up for continue/break in body\n\t\tprevContinue := s.continueTo\n\t\tprevBreak := s.breakTo\n\t\ts.continueTo = bIncr     // for循环中的迭代语句\n\t\ts.breakTo = bEnd         // for循环结束时的代码块\n\t\tlab := s.labeledNodes[n] // 获取在该循环上声明的label\n\t\tif lab != nil {\n\t\t\t// labeled for loop\n\t\t\tlab.continueTarget = bIncr\n\t\t\tlab.breakTarget = bEnd\n\t\t}\n\n\t\t// generate body\n\t\ts.startBlock(bBody)\n\t\ts.stmtList(n.Nbody)\n\n\t\t// tear down continue/break\n\t\ts.continueTo = prevContinue\n\t\ts.breakTo = prevBreak\n\t\tif lab != nil {\n\t\t\tlab.continueTarget = nil\n\t\t\tlab.breakTarget = nil\n\t\t}\n\n\t\t// done with body, goto incr\n\t\tif b := s.endBlock(); b != nil {\n\t\t\tb.AddEdgeTo(bIncr)\n\t\t}\n\n\t\t// generate incr (and, for OFORUNTIL, condition)\n\t\ts.startBlock(bIncr)\n\t\tif n.Right != nil {\n\t\t\ts.stmt(n.Right)\n\t\t}\n\t\tif n.Op == OFOR {\n\t\t\tif b := s.endBlock(); b != nil {\n\t\t\t\tb.AddEdgeTo(bCond)\n\t\t\t\t// It can happen that bIncr ends in a block containing only VARKILL,\n\t\t\t\t// and that muddles the debugging experience.\n\t\t\t\tif n.Op != OFORUNTIL && b.Pos == src.NoXPos {\n\t\t\t\t\tb.Pos = bCond.Pos\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// bCond is unused in OFORUNTIL, so repurpose it.\n\t\t\tbLateIncr := bCond\n\t\t\t// test condition\n\t\t\ts.condBranch(n.Left, bLateIncr, bEnd, 1)\n\t\t\t// generate late increment\n\t\t\ts.startBlock(bLateIncr)\n\t\t\ts.stmtList(n.List)\n\t\t\ts.endBlock().AddEdgeTo(bBody)\n\t\t}\n\n\t\ts.startBlock(bEnd)\n\n\tcase OSWITCH, OSELECT: // switch Ninit; Left { List } (List is a list of OCASE), select { List } (List is list of OCASE)\n\t\t// These have been mostly rewritten by the front end into their Nbody fields.\n\t\t// Our main task is to correctly hook up any break statements.\n\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\n\t\tprevBreak := s.breakTo\n\t\ts.breakTo = bEnd\n\t\tlab := s.labeledNodes[n]\n\t\tif lab != nil {\n\t\t\t// labeled\n\t\t\tlab.breakTarget = bEnd\n\t\t}\n\n\t\t// generate body code\n\t\ts.stmtList(n.Nbody)\n\n\t\ts.breakTo = prevBreak\n\t\tif lab != nil {\n\t\t\tlab.breakTarget = nil\n\t\t}\n\n\t\t// walk adds explicit OBREAK nodes to the end of all reachable code paths.\n\t\t// If we still have a current block here, then mark it unreachable.\n\t\tif s.curBlock != nil {\n\t\t\tm := s.mem()\n\t\t\tb := s.endBlock()\n\t\t\tb.Kind = ssa.BlockExit\n\t\t\tb.SetControl(m)\n\t\t}\n\t\ts.startBlock(bEnd)\n\n\tcase OVARDEF:\n\t\tif !s.canSSA(n.Left) {\n\t\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarDef, types.TypeMem, n.Left, s.mem(), false)\n\t\t}\n\tcase OVARKILL:\n\t\t// Insert a varkill op to record that a variable is no longer live.\n\t\t// We only care about liveness info at call sites, so putting the\n\t\t// varkill in the store chain is enough to keep it correctly ordered\n\t\t// with respect to call ops.\n\t\tif !s.canSSA(n.Left) {\n\t\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarKill, types.TypeMem, n.Left, s.mem(), false)\n\t\t}\n\n\tcase OVARLIVE:\n\t\t// Insert a varlive op to record that a variable is still live.\n\t\tif !n.Left.Name.Addrtaken() {\n\t\t\ts.Fatalf(\"VARLIVE variable %v must have Addrtaken set\", n.Left)\n\t\t}\n\t\tswitch n.Left.Class() {\n\t\tcase PAUTO, PPARAM, PPARAMOUT:\n\t\tdefault:\n\t\t\ts.Fatalf(\"VARLIVE variable %v must be Auto or Arg\", n.Left)\n\t\t}\n\t\ts.vars[&memVar] = s.newValue1A(ssa.OpVarLive, types.TypeMem, n.Left, s.mem())\n\n\tcase OCHECKNIL:\n\t\tp := s.expr(n.Left)\n\t\ts.nilCheck(p)\n\n\tcase OINLMARK:\n\t\ts.newValue1I(ssa.OpInlMark, types.TypeVoid, n.Xoffset, s.mem())\n\n\tdefault:\n\t\ts.Fatalf(\"unhandled stmt %v\", n.Op)\n\t}\n}\n\n// If true, share as many open-coded defer exits as possible (with the downside of\n// worse line-number information)\nconst shareDeferExits = false\n\n// exit processes any code that needs to be generated just before returning.\n// It returns a BlockRet block that ends the control flow. Its control value\n// will be set to the final memory state.\nfunc (s *state) exit() *ssa.Block {\n\tif s.hasdefer {\n\t\tif s.hasOpenDefers {\n\t\t\tif shareDeferExits && s.lastDeferExit != nil && len(s.openDefers) == s.lastDeferCount {\n\t\t\t\tif s.curBlock.Kind != ssa.BlockPlain {\n\t\t\t\t\tpanic(\"Block for an exit should be BlockPlain\")\n\t\t\t\t}\n\t\t\t\ts.curBlock.AddEdgeTo(s.lastDeferExit)\n\t\t\t\ts.endBlock()\n\t\t\t\treturn s.lastDeferFinalBlock\n\t\t\t}\n\t\t\ts.openDeferExit()\n\t\t} else {\n\t\t\ts.rtcall(Deferreturn, true, nil)\n\t\t}\n\t}\n\n\t// Run exit code. Typically, this code copies heap-allocated PPARAMOUT\n\t// variables back to the stack.\n\ts.stmtList(s.curfn.Func.Exit)\n\n\t// Store SSAable PPARAMOUT variables back to stack locations.\n\tfor _, n := range s.returns {\n\t\taddr := s.decladdrs[n]       // 获取保存返回值的地址\n\t\tval := s.variable(n, n.Type) // 获取返回值变量\n\t\ts.vars[&memVar] = s.newValue1A(ssa.OpVarDef, types.TypeMem, n, s.mem())\n\t\ts.store(n.Type, addr, val) // 将返回值保存到栈上的地址\n\t\t// TODO: if val is ever spilled, we'd like to use the\n\t\t// PPARAMOUT slot for spilling it. That won't happen\n\t\t// currently.\n\t}\n\n\t// Do actual return.\n\tm := s.mem()\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockRet\n\tb.SetControl(m)\n\tif s.hasdefer && s.hasOpenDefers {\n\t\ts.lastDeferFinalBlock = b\n\t}\n\treturn b\n}\n\ntype opAndType struct {\n\top    Op\n\tetype types.EType\n}\n\nvar opToSSA = map[opAndType]ssa.Op{\n\topAndType{OADD, TINT8}:    ssa.OpAdd8,\n\topAndType{OADD, TUINT8}:   ssa.OpAdd8,\n\topAndType{OADD, TINT16}:   ssa.OpAdd16,\n\topAndType{OADD, TUINT16}:  ssa.OpAdd16,\n\topAndType{OADD, TINT32}:   ssa.OpAdd32,\n\topAndType{OADD, TUINT32}:  ssa.OpAdd32,\n\topAndType{OADD, TINT64}:   ssa.OpAdd64,\n\topAndType{OADD, TUINT64}:  ssa.OpAdd64,\n\topAndType{OADD, TFLOAT32}: ssa.OpAdd32F,\n\topAndType{OADD, TFLOAT64}: ssa.OpAdd64F,\n\n\topAndType{OSUB, TINT8}:    ssa.OpSub8,\n\topAndType{OSUB, TUINT8}:   ssa.OpSub8,\n\topAndType{OSUB, TINT16}:   ssa.OpSub16,\n\topAndType{OSUB, TUINT16}:  ssa.OpSub16,\n\topAndType{OSUB, TINT32}:   ssa.OpSub32,\n\topAndType{OSUB, TUINT32}:  ssa.OpSub32,\n\topAndType{OSUB, TINT64}:   ssa.OpSub64,\n\topAndType{OSUB, TUINT64}:  ssa.OpSub64,\n\topAndType{OSUB, TFLOAT32}: ssa.OpSub32F,\n\topAndType{OSUB, TFLOAT64}: ssa.OpSub64F,\n\n\topAndType{ONOT, TBOOL}: ssa.OpNot,\n\n\topAndType{ONEG, TINT8}:    ssa.OpNeg8,\n\topAndType{ONEG, TUINT8}:   ssa.OpNeg8,\n\topAndType{ONEG, TINT16}:   ssa.OpNeg16,\n\topAndType{ONEG, TUINT16}:  ssa.OpNeg16,\n\topAndType{ONEG, TINT32}:   ssa.OpNeg32,\n\topAndType{ONEG, TUINT32}:  ssa.OpNeg32,\n\topAndType{ONEG, TINT64}:   ssa.OpNeg64,\n\topAndType{ONEG, TUINT64}:  ssa.OpNeg64,\n\topAndType{ONEG, TFLOAT32}: ssa.OpNeg32F,\n\topAndType{ONEG, TFLOAT64}: ssa.OpNeg64F,\n\n\topAndType{OBITNOT, TINT8}:   ssa.OpCom8,\n\topAndType{OBITNOT, TUINT8}:  ssa.OpCom8,\n\topAndType{OBITNOT, TINT16}:  ssa.OpCom16,\n\topAndType{OBITNOT, TUINT16}: ssa.OpCom16,\n\topAndType{OBITNOT, TINT32}:  ssa.OpCom32,\n\topAndType{OBITNOT, TUINT32}: ssa.OpCom32,\n\topAndType{OBITNOT, TINT64}:  ssa.OpCom64,\n\topAndType{OBITNOT, TUINT64}: ssa.OpCom64,\n\n\topAndType{OIMAG, TCOMPLEX64}:  ssa.OpComplexImag,\n\topAndType{OIMAG, TCOMPLEX128}: ssa.OpComplexImag,\n\topAndType{OREAL, TCOMPLEX64}:  ssa.OpComplexReal,\n\topAndType{OREAL, TCOMPLEX128}: ssa.OpComplexReal,\n\n\topAndType{OMUL, TINT8}:    ssa.OpMul8,\n\topAndType{OMUL, TUINT8}:   ssa.OpMul8,\n\topAndType{OMUL, TINT16}:   ssa.OpMul16,\n\topAndType{OMUL, TUINT16}:  ssa.OpMul16,\n\topAndType{OMUL, TINT32}:   ssa.OpMul32,\n\topAndType{OMUL, TUINT32}:  ssa.OpMul32,\n\topAndType{OMUL, TINT64}:   ssa.OpMul64,\n\topAndType{OMUL, TUINT64}:  ssa.OpMul64,\n\topAndType{OMUL, TFLOAT32}: ssa.OpMul32F,\n\topAndType{OMUL, TFLOAT64}: ssa.OpMul64F,\n\n\topAndType{ODIV, TFLOAT32}: ssa.OpDiv32F,\n\topAndType{ODIV, TFLOAT64}: ssa.OpDiv64F,\n\n\topAndType{ODIV, TINT8}:   ssa.OpDiv8,\n\topAndType{ODIV, TUINT8}:  ssa.OpDiv8u,\n\topAndType{ODIV, TINT16}:  ssa.OpDiv16,\n\topAndType{ODIV, TUINT16}: ssa.OpDiv16u,\n\topAndType{ODIV, TINT32}:  ssa.OpDiv32,\n\topAndType{ODIV, TUINT32}: ssa.OpDiv32u,\n\topAndType{ODIV, TINT64}:  ssa.OpDiv64,\n\topAndType{ODIV, TUINT64}: ssa.OpDiv64u,\n\n\topAndType{OMOD, TINT8}:   ssa.OpMod8,\n\topAndType{OMOD, TUINT8}:  ssa.OpMod8u,\n\topAndType{OMOD, TINT16}:  ssa.OpMod16,\n\topAndType{OMOD, TUINT16}: ssa.OpMod16u,\n\topAndType{OMOD, TINT32}:  ssa.OpMod32,\n\topAndType{OMOD, TUINT32}: ssa.OpMod32u,\n\topAndType{OMOD, TINT64}:  ssa.OpMod64,\n\topAndType{OMOD, TUINT64}: ssa.OpMod64u,\n\n\topAndType{OAND, TINT8}:   ssa.OpAnd8,\n\topAndType{OAND, TUINT8}:  ssa.OpAnd8,\n\topAndType{OAND, TINT16}:  ssa.OpAnd16,\n\topAndType{OAND, TUINT16}: ssa.OpAnd16,\n\topAndType{OAND, TINT32}:  ssa.OpAnd32,\n\topAndType{OAND, TUINT32}: ssa.OpAnd32,\n\topAndType{OAND, TINT64}:  ssa.OpAnd64,\n\topAndType{OAND, TUINT64}: ssa.OpAnd64,\n\n\topAndType{OOR, TINT8}:   ssa.OpOr8,\n\topAndType{OOR, TUINT8}:  ssa.OpOr8,\n\topAndType{OOR, TINT16}:  ssa.OpOr16,\n\topAndType{OOR, TUINT16}: ssa.OpOr16,\n\topAndType{OOR, TINT32}:  ssa.OpOr32,\n\topAndType{OOR, TUINT32}: ssa.OpOr32,\n\topAndType{OOR, TINT64}:  ssa.OpOr64,\n\topAndType{OOR, TUINT64}: ssa.OpOr64,\n\n\topAndType{OXOR, TINT8}:   ssa.OpXor8,\n\topAndType{OXOR, TUINT8}:  ssa.OpXor8,\n\topAndType{OXOR, TINT16}:  ssa.OpXor16,\n\topAndType{OXOR, TUINT16}: ssa.OpXor16,\n\topAndType{OXOR, TINT32}:  ssa.OpXor32,\n\topAndType{OXOR, TUINT32}: ssa.OpXor32,\n\topAndType{OXOR, TINT64}:  ssa.OpXor64,\n\topAndType{OXOR, TUINT64}: ssa.OpXor64,\n\n\topAndType{OEQ, TBOOL}:      ssa.OpEqB,\n\topAndType{OEQ, TINT8}:      ssa.OpEq8,\n\topAndType{OEQ, TUINT8}:     ssa.OpEq8,\n\topAndType{OEQ, TINT16}:     ssa.OpEq16,\n\topAndType{OEQ, TUINT16}:    ssa.OpEq16,\n\topAndType{OEQ, TINT32}:     ssa.OpEq32,\n\topAndType{OEQ, TUINT32}:    ssa.OpEq32,\n\topAndType{OEQ, TINT64}:     ssa.OpEq64,\n\topAndType{OEQ, TUINT64}:    ssa.OpEq64,\n\topAndType{OEQ, TINTER}:     ssa.OpEqInter,\n\topAndType{OEQ, TSLICE}:     ssa.OpEqSlice,\n\topAndType{OEQ, TFUNC}:      ssa.OpEqPtr,\n\topAndType{OEQ, TMAP}:       ssa.OpEqPtr,\n\topAndType{OEQ, TCHAN}:      ssa.OpEqPtr,\n\topAndType{OEQ, TPTR}:       ssa.OpEqPtr,\n\topAndType{OEQ, TUINTPTR}:   ssa.OpEqPtr,\n\topAndType{OEQ, TUNSAFEPTR}: ssa.OpEqPtr,\n\topAndType{OEQ, TFLOAT64}:   ssa.OpEq64F,\n\topAndType{OEQ, TFLOAT32}:   ssa.OpEq32F,\n\n\topAndType{ONE, TBOOL}:      ssa.OpNeqB,\n\topAndType{ONE, TINT8}:      ssa.OpNeq8,\n\topAndType{ONE, TUINT8}:     ssa.OpNeq8,\n\topAndType{ONE, TINT16}:     ssa.OpNeq16,\n\topAndType{ONE, TUINT16}:    ssa.OpNeq16,\n\topAndType{ONE, TINT32}:     ssa.OpNeq32,\n\topAndType{ONE, TUINT32}:    ssa.OpNeq32,\n\topAndType{ONE, TINT64}:     ssa.OpNeq64,\n\topAndType{ONE, TUINT64}:    ssa.OpNeq64,\n\topAndType{ONE, TINTER}:     ssa.OpNeqInter,\n\topAndType{ONE, TSLICE}:     ssa.OpNeqSlice,\n\topAndType{ONE, TFUNC}:      ssa.OpNeqPtr,\n\topAndType{ONE, TMAP}:       ssa.OpNeqPtr,\n\topAndType{ONE, TCHAN}:      ssa.OpNeqPtr,\n\topAndType{ONE, TPTR}:       ssa.OpNeqPtr,\n\topAndType{ONE, TUINTPTR}:   ssa.OpNeqPtr,\n\topAndType{ONE, TUNSAFEPTR}: ssa.OpNeqPtr,\n\topAndType{ONE, TFLOAT64}:   ssa.OpNeq64F,\n\topAndType{ONE, TFLOAT32}:   ssa.OpNeq32F,\n\n\topAndType{OLT, TINT8}:    ssa.OpLess8,\n\topAndType{OLT, TUINT8}:   ssa.OpLess8U,\n\topAndType{OLT, TINT16}:   ssa.OpLess16,\n\topAndType{OLT, TUINT16}:  ssa.OpLess16U,\n\topAndType{OLT, TINT32}:   ssa.OpLess32,\n\topAndType{OLT, TUINT32}:  ssa.OpLess32U,\n\topAndType{OLT, TINT64}:   ssa.OpLess64,\n\topAndType{OLT, TUINT64}:  ssa.OpLess64U,\n\topAndType{OLT, TFLOAT64}: ssa.OpLess64F,\n\topAndType{OLT, TFLOAT32}: ssa.OpLess32F,\n\n\topAndType{OLE, TINT8}:    ssa.OpLeq8,\n\topAndType{OLE, TUINT8}:   ssa.OpLeq8U,\n\topAndType{OLE, TINT16}:   ssa.OpLeq16,\n\topAndType{OLE, TUINT16}:  ssa.OpLeq16U,\n\topAndType{OLE, TINT32}:   ssa.OpLeq32,\n\topAndType{OLE, TUINT32}:  ssa.OpLeq32U,\n\topAndType{OLE, TINT64}:   ssa.OpLeq64,\n\topAndType{OLE, TUINT64}:  ssa.OpLeq64U,\n\topAndType{OLE, TFLOAT64}: ssa.OpLeq64F,\n\topAndType{OLE, TFLOAT32}: ssa.OpLeq32F,\n}\n\n// 返回int,uint以及uintptr的确切的类型(TINT32/TINT64/TUINT32/TUINT64)\nfunc (s *state) concreteEtype(t *types.Type) types.EType {\n\te := t.Etype\n\tswitch e {\n\tdefault:\n\t\treturn e\n\tcase TINT:\n\t\tif s.config.PtrSize == 8 {\n\t\t\treturn TINT64\n\t\t}\n\t\treturn TINT32\n\tcase TUINT:\n\t\tif s.config.PtrSize == 8 {\n\t\t\treturn TUINT64\n\t\t}\n\t\treturn TUINT32\n\tcase TUINTPTR:\n\t\tif s.config.PtrSize == 8 {\n\t\t\treturn TUINT64\n\t\t}\n\t\treturn TUINT32\n\t}\n}\n\n// 根据操作以及对应的类型获取ssa的操作码\nfunc (s *state) ssaOp(op Op, t *types.Type) ssa.Op {\n\tetype := s.concreteEtype(t)\n\tx, ok := opToSSA[opAndType{op, etype}]\n\tif !ok {\n\t\ts.Fatalf(\"unhandled binary op %v %s\", op, etype)\n\t}\n\treturn x\n}\n\nfunc floatForComplex(t *types.Type) *types.Type {\n\tswitch t.Etype {\n\tcase TCOMPLEX64:\n\t\treturn types.Types[TFLOAT32]\n\tcase TCOMPLEX128:\n\t\treturn types.Types[TFLOAT64]\n\t}\n\tFatalf(\"unexpected type: %v\", t)\n\treturn nil\n}\n\nfunc complexForFloat(t *types.Type) *types.Type {\n\tswitch t.Etype {\n\tcase TFLOAT32:\n\t\treturn types.Types[TCOMPLEX64]\n\tcase TFLOAT64:\n\t\treturn types.Types[TCOMPLEX128]\n\t}\n\tFatalf(\"unexpected type: %v\", t)\n\treturn nil\n}\n\ntype opAndTwoTypes struct {\n\top     Op\n\tetype1 types.EType\n\tetype2 types.EType\n}\n\ntype twoTypes struct {\n\tetype1 types.EType\n\tetype2 types.EType\n}\n\ntype twoOpsAndType struct {\n\top1              ssa.Op\n\top2              ssa.Op\n\tintermediateType types.EType // 两种操作的中间类型\n}\n\nvar fpConvOpToSSA = map[twoTypes]twoOpsAndType{\n\n\ttwoTypes{TINT8, TFLOAT32}:  twoOpsAndType{ssa.OpSignExt8to32, ssa.OpCvt32to32F, TINT32},\n\ttwoTypes{TINT16, TFLOAT32}: twoOpsAndType{ssa.OpSignExt16to32, ssa.OpCvt32to32F, TINT32},\n\ttwoTypes{TINT32, TFLOAT32}: twoOpsAndType{ssa.OpCopy, ssa.OpCvt32to32F, TINT32},\n\ttwoTypes{TINT64, TFLOAT32}: twoOpsAndType{ssa.OpCopy, ssa.OpCvt64to32F, TINT64},\n\n\ttwoTypes{TINT8, TFLOAT64}:  twoOpsAndType{ssa.OpSignExt8to32, ssa.OpCvt32to64F, TINT32},\n\ttwoTypes{TINT16, TFLOAT64}: twoOpsAndType{ssa.OpSignExt16to32, ssa.OpCvt32to64F, TINT32},\n\ttwoTypes{TINT32, TFLOAT64}: twoOpsAndType{ssa.OpCopy, ssa.OpCvt32to64F, TINT32},\n\ttwoTypes{TINT64, TFLOAT64}: twoOpsAndType{ssa.OpCopy, ssa.OpCvt64to64F, TINT64},\n\n\ttwoTypes{TFLOAT32, TINT8}:  twoOpsAndType{ssa.OpCvt32Fto32, ssa.OpTrunc32to8, TINT32},\n\ttwoTypes{TFLOAT32, TINT16}: twoOpsAndType{ssa.OpCvt32Fto32, ssa.OpTrunc32to16, TINT32},\n\ttwoTypes{TFLOAT32, TINT32}: twoOpsAndType{ssa.OpCvt32Fto32, ssa.OpCopy, TINT32},\n\ttwoTypes{TFLOAT32, TINT64}: twoOpsAndType{ssa.OpCvt32Fto64, ssa.OpCopy, TINT64},\n\n\ttwoTypes{TFLOAT64, TINT8}:  twoOpsAndType{ssa.OpCvt64Fto32, ssa.OpTrunc32to8, TINT32},\n\ttwoTypes{TFLOAT64, TINT16}: twoOpsAndType{ssa.OpCvt64Fto32, ssa.OpTrunc32to16, TINT32},\n\ttwoTypes{TFLOAT64, TINT32}: twoOpsAndType{ssa.OpCvt64Fto32, ssa.OpCopy, TINT32},\n\ttwoTypes{TFLOAT64, TINT64}: twoOpsAndType{ssa.OpCvt64Fto64, ssa.OpCopy, TINT64},\n\t// unsigned\n\ttwoTypes{TUINT8, TFLOAT32}:  twoOpsAndType{ssa.OpZeroExt8to32, ssa.OpCvt32to32F, TINT32},\n\ttwoTypes{TUINT16, TFLOAT32}: twoOpsAndType{ssa.OpZeroExt16to32, ssa.OpCvt32to32F, TINT32},\n\ttwoTypes{TUINT32, TFLOAT32}: twoOpsAndType{ssa.OpZeroExt32to64, ssa.OpCvt64to32F, TINT64}, // go wide to dodge unsigned\n\ttwoTypes{TUINT64, TFLOAT32}: twoOpsAndType{ssa.OpCopy, ssa.OpInvalid, TUINT64},            // Cvt64Uto32F, branchy code expansion instead\n\n\ttwoTypes{TUINT8, TFLOAT64}:  twoOpsAndType{ssa.OpZeroExt8to32, ssa.OpCvt32to64F, TINT32},\n\ttwoTypes{TUINT16, TFLOAT64}: twoOpsAndType{ssa.OpZeroExt16to32, ssa.OpCvt32to64F, TINT32},\n\ttwoTypes{TUINT32, TFLOAT64}: twoOpsAndType{ssa.OpZeroExt32to64, ssa.OpCvt64to64F, TINT64}, // go wide to dodge unsigned\n\ttwoTypes{TUINT64, TFLOAT64}: twoOpsAndType{ssa.OpCopy, ssa.OpInvalid, TUINT64},            // Cvt64Uto64F, branchy code expansion instead\n\n\ttwoTypes{TFLOAT32, TUINT8}:  twoOpsAndType{ssa.OpCvt32Fto32, ssa.OpTrunc32to8, TINT32},\n\ttwoTypes{TFLOAT32, TUINT16}: twoOpsAndType{ssa.OpCvt32Fto32, ssa.OpTrunc32to16, TINT32},\n\ttwoTypes{TFLOAT32, TUINT32}: twoOpsAndType{ssa.OpCvt32Fto64, ssa.OpTrunc64to32, TINT64}, // go wide to dodge unsigned\n\ttwoTypes{TFLOAT32, TUINT64}: twoOpsAndType{ssa.OpInvalid, ssa.OpCopy, TUINT64},          // Cvt32Fto64U, branchy code expansion instead\n\n\ttwoTypes{TFLOAT64, TUINT8}:  twoOpsAndType{ssa.OpCvt64Fto32, ssa.OpTrunc32to8, TINT32},\n\ttwoTypes{TFLOAT64, TUINT16}: twoOpsAndType{ssa.OpCvt64Fto32, ssa.OpTrunc32to16, TINT32},\n\ttwoTypes{TFLOAT64, TUINT32}: twoOpsAndType{ssa.OpCvt64Fto64, ssa.OpTrunc64to32, TINT64}, // go wide to dodge unsigned\n\ttwoTypes{TFLOAT64, TUINT64}: twoOpsAndType{ssa.OpInvalid, ssa.OpCopy, TUINT64},          // Cvt64Fto64U, branchy code expansion instead\n\n\t// float\n\ttwoTypes{TFLOAT64, TFLOAT32}: twoOpsAndType{ssa.OpCvt64Fto32F, ssa.OpCopy, TFLOAT32},\n\ttwoTypes{TFLOAT64, TFLOAT64}: twoOpsAndType{ssa.OpRound64F, ssa.OpCopy, TFLOAT64},\n\ttwoTypes{TFLOAT32, TFLOAT32}: twoOpsAndType{ssa.OpRound32F, ssa.OpCopy, TFLOAT32},\n\ttwoTypes{TFLOAT32, TFLOAT64}: twoOpsAndType{ssa.OpCvt32Fto64F, ssa.OpCopy, TFLOAT64},\n}\n\n// this map is used only for 32-bit arch, and only includes the difference\n// on 32-bit arch, don't use int64<->float conversion for uint32\nvar fpConvOpToSSA32 = map[twoTypes]twoOpsAndType{\n\ttwoTypes{TUINT32, TFLOAT32}: twoOpsAndType{ssa.OpCopy, ssa.OpCvt32Uto32F, TUINT32},\n\ttwoTypes{TUINT32, TFLOAT64}: twoOpsAndType{ssa.OpCopy, ssa.OpCvt32Uto64F, TUINT32},\n\ttwoTypes{TFLOAT32, TUINT32}: twoOpsAndType{ssa.OpCvt32Fto32U, ssa.OpCopy, TUINT32},\n\ttwoTypes{TFLOAT64, TUINT32}: twoOpsAndType{ssa.OpCvt64Fto32U, ssa.OpCopy, TUINT32},\n}\n\n// uint64<->float conversions, only on machines that have instructions for that\nvar uint64fpConvOpToSSA = map[twoTypes]twoOpsAndType{\n\ttwoTypes{TUINT64, TFLOAT32}: twoOpsAndType{ssa.OpCopy, ssa.OpCvt64Uto32F, TUINT64},\n\ttwoTypes{TUINT64, TFLOAT64}: twoOpsAndType{ssa.OpCopy, ssa.OpCvt64Uto64F, TUINT64},\n\ttwoTypes{TFLOAT32, TUINT64}: twoOpsAndType{ssa.OpCvt32Fto64U, ssa.OpCopy, TUINT64},\n\ttwoTypes{TFLOAT64, TUINT64}: twoOpsAndType{ssa.OpCvt64Fto64U, ssa.OpCopy, TUINT64},\n}\n\nvar shiftOpToSSA = map[opAndTwoTypes]ssa.Op{\n\topAndTwoTypes{OLSH, TINT8, TUINT8}:   ssa.OpLsh8x8,\n\topAndTwoTypes{OLSH, TUINT8, TUINT8}:  ssa.OpLsh8x8,\n\topAndTwoTypes{OLSH, TINT8, TUINT16}:  ssa.OpLsh8x16,\n\topAndTwoTypes{OLSH, TUINT8, TUINT16}: ssa.OpLsh8x16,\n\topAndTwoTypes{OLSH, TINT8, TUINT32}:  ssa.OpLsh8x32,\n\topAndTwoTypes{OLSH, TUINT8, TUINT32}: ssa.OpLsh8x32,\n\topAndTwoTypes{OLSH, TINT8, TUINT64}:  ssa.OpLsh8x64,\n\topAndTwoTypes{OLSH, TUINT8, TUINT64}: ssa.OpLsh8x64,\n\n\topAndTwoTypes{OLSH, TINT16, TUINT8}:   ssa.OpLsh16x8,\n\topAndTwoTypes{OLSH, TUINT16, TUINT8}:  ssa.OpLsh16x8,\n\topAndTwoTypes{OLSH, TINT16, TUINT16}:  ssa.OpLsh16x16,\n\topAndTwoTypes{OLSH, TUINT16, TUINT16}: ssa.OpLsh16x16,\n\topAndTwoTypes{OLSH, TINT16, TUINT32}:  ssa.OpLsh16x32,\n\topAndTwoTypes{OLSH, TUINT16, TUINT32}: ssa.OpLsh16x32,\n\topAndTwoTypes{OLSH, TINT16, TUINT64}:  ssa.OpLsh16x64,\n\topAndTwoTypes{OLSH, TUINT16, TUINT64}: ssa.OpLsh16x64,\n\n\topAndTwoTypes{OLSH, TINT32, TUINT8}:   ssa.OpLsh32x8,\n\topAndTwoTypes{OLSH, TUINT32, TUINT8}:  ssa.OpLsh32x8,\n\topAndTwoTypes{OLSH, TINT32, TUINT16}:  ssa.OpLsh32x16,\n\topAndTwoTypes{OLSH, TUINT32, TUINT16}: ssa.OpLsh32x16,\n\topAndTwoTypes{OLSH, TINT32, TUINT32}:  ssa.OpLsh32x32,\n\topAndTwoTypes{OLSH, TUINT32, TUINT32}: ssa.OpLsh32x32,\n\topAndTwoTypes{OLSH, TINT32, TUINT64}:  ssa.OpLsh32x64,\n\topAndTwoTypes{OLSH, TUINT32, TUINT64}: ssa.OpLsh32x64,\n\n\topAndTwoTypes{OLSH, TINT64, TUINT8}:   ssa.OpLsh64x8,\n\topAndTwoTypes{OLSH, TUINT64, TUINT8}:  ssa.OpLsh64x8,\n\topAndTwoTypes{OLSH, TINT64, TUINT16}:  ssa.OpLsh64x16,\n\topAndTwoTypes{OLSH, TUINT64, TUINT16}: ssa.OpLsh64x16,\n\topAndTwoTypes{OLSH, TINT64, TUINT32}:  ssa.OpLsh64x32,\n\topAndTwoTypes{OLSH, TUINT64, TUINT32}: ssa.OpLsh64x32,\n\topAndTwoTypes{OLSH, TINT64, TUINT64}:  ssa.OpLsh64x64,\n\topAndTwoTypes{OLSH, TUINT64, TUINT64}: ssa.OpLsh64x64,\n\n\topAndTwoTypes{ORSH, TINT8, TUINT8}:   ssa.OpRsh8x8,\n\topAndTwoTypes{ORSH, TUINT8, TUINT8}:  ssa.OpRsh8Ux8,\n\topAndTwoTypes{ORSH, TINT8, TUINT16}:  ssa.OpRsh8x16,\n\topAndTwoTypes{ORSH, TUINT8, TUINT16}: ssa.OpRsh8Ux16,\n\topAndTwoTypes{ORSH, TINT8, TUINT32}:  ssa.OpRsh8x32,\n\topAndTwoTypes{ORSH, TUINT8, TUINT32}: ssa.OpRsh8Ux32,\n\topAndTwoTypes{ORSH, TINT8, TUINT64}:  ssa.OpRsh8x64,\n\topAndTwoTypes{ORSH, TUINT8, TUINT64}: ssa.OpRsh8Ux64,\n\n\topAndTwoTypes{ORSH, TINT16, TUINT8}:   ssa.OpRsh16x8,\n\topAndTwoTypes{ORSH, TUINT16, TUINT8}:  ssa.OpRsh16Ux8,\n\topAndTwoTypes{ORSH, TINT16, TUINT16}:  ssa.OpRsh16x16,\n\topAndTwoTypes{ORSH, TUINT16, TUINT16}: ssa.OpRsh16Ux16,\n\topAndTwoTypes{ORSH, TINT16, TUINT32}:  ssa.OpRsh16x32,\n\topAndTwoTypes{ORSH, TUINT16, TUINT32}: ssa.OpRsh16Ux32,\n\topAndTwoTypes{ORSH, TINT16, TUINT64}:  ssa.OpRsh16x64,\n\topAndTwoTypes{ORSH, TUINT16, TUINT64}: ssa.OpRsh16Ux64,\n\n\topAndTwoTypes{ORSH, TINT32, TUINT8}:   ssa.OpRsh32x8,\n\topAndTwoTypes{ORSH, TUINT32, TUINT8}:  ssa.OpRsh32Ux8,\n\topAndTwoTypes{ORSH, TINT32, TUINT16}:  ssa.OpRsh32x16,\n\topAndTwoTypes{ORSH, TUINT32, TUINT16}: ssa.OpRsh32Ux16,\n\topAndTwoTypes{ORSH, TINT32, TUINT32}:  ssa.OpRsh32x32,\n\topAndTwoTypes{ORSH, TUINT32, TUINT32}: ssa.OpRsh32Ux32,\n\topAndTwoTypes{ORSH, TINT32, TUINT64}:  ssa.OpRsh32x64,\n\topAndTwoTypes{ORSH, TUINT32, TUINT64}: ssa.OpRsh32Ux64,\n\n\topAndTwoTypes{ORSH, TINT64, TUINT8}:   ssa.OpRsh64x8,\n\topAndTwoTypes{ORSH, TUINT64, TUINT8}:  ssa.OpRsh64Ux8,\n\topAndTwoTypes{ORSH, TINT64, TUINT16}:  ssa.OpRsh64x16,\n\topAndTwoTypes{ORSH, TUINT64, TUINT16}: ssa.OpRsh64Ux16,\n\topAndTwoTypes{ORSH, TINT64, TUINT32}:  ssa.OpRsh64x32,\n\topAndTwoTypes{ORSH, TUINT64, TUINT32}: ssa.OpRsh64Ux32,\n\topAndTwoTypes{ORSH, TINT64, TUINT64}:  ssa.OpRsh64x64,\n\topAndTwoTypes{ORSH, TUINT64, TUINT64}: ssa.OpRsh64Ux64,\n}\n\nfunc (s *state) ssaShiftOp(op Op, t *types.Type, u *types.Type) ssa.Op {\n\tetype1 := s.concreteEtype(t)\n\tetype2 := s.concreteEtype(u)\n\tx, ok := shiftOpToSSA[opAndTwoTypes{op, etype1, etype2}]\n\tif !ok {\n\t\ts.Fatalf(\"unhandled shift op %v etype=%s/%s\", op, etype1, etype2)\n\t}\n\treturn x\n}\n\n// expr converts the expression n to ssa, adds it to s and returns the ssa result.\nfunc (s *state) expr(n *Node) *ssa.Value {\n\tif !(n.Op == ONAME || n.Op == OLITERAL && n.Sym != nil) {\n\t\t// ONAMEs and named OLITERALs have the line number\n\t\t// of the decl, not the use. See issue 14742.\n\t\ts.pushLine(n.Pos)\n\t\tdefer s.popLine()\n\t}\n\n\ts.stmtList(n.Ninit)\n\tswitch n.Op {\n\tcase OBYTES2STRTMP: // Type(Left) (Type is string, Left is a []byte, ephemeral)\n\t\tslice := s.expr(n.Left) // 解析左节点，左节点的类型应该为[]byte\n\t\tptr := s.newValue1(ssa.OpSlicePtr, s.f.Config.Types.BytePtr, slice)\n\t\tlen := s.newValue1(ssa.OpSliceLen, types.Types[TINT], slice)\n\t\treturn s.newValue2(ssa.OpStringMake, n.Type, ptr, len)\n\tcase OSTR2BYTESTMP: // Type(Left) (Type is []byte, Left is a string, ephemeral)\n\t\tstr := s.expr(n.Left)\n\t\tptr := s.newValue1(ssa.OpStringPtr, s.f.Config.Types.BytePtr, str)\n\t\tlen := s.newValue1(ssa.OpStringLen, types.Types[TINT], str)\n\t\treturn s.newValue3(ssa.OpSliceMake, n.Type, ptr, len, len)\n\tcase OCFUNC:\n\t\taux := n.Left.Sym.Linksym()\n\t\treturn s.entryNewValue1A(ssa.OpAddr, n.Type, aux, s.sb)\n\tcase ONAME:\n\t\tif n.Class() == PFUNC { // global function\n\t\t\t// \"value\" of a function is the address of the function's closure\n\t\t\tsym := funcsym(n.Sym).Linksym()\n\t\t\treturn s.entryNewValue1A(ssa.OpAddr, types.NewPtr(n.Type), sym, s.sb)\n\t\t}\n\t\tif s.canSSA(n) {\n\t\t\treturn s.variable(n, n.Type)\n\t\t}\n\t\taddr := s.addr(n)\n\t\treturn s.load(n.Type, addr)\n\tcase OCLOSUREVAR:\n\t\taddr := s.addr(n)\n\t\treturn s.load(n.Type, addr)\n\tcase OLITERAL:\n\t\tswitch u := n.Val().U.(type) {\n\t\tcase *Mpint:\n\t\t\ti := u.Int64()\n\t\t\tswitch n.Type.Size() {\n\t\t\tcase 1:\n\t\t\t\treturn s.constInt8(n.Type, int8(i))\n\t\t\tcase 2:\n\t\t\t\treturn s.constInt16(n.Type, int16(i))\n\t\t\tcase 4:\n\t\t\t\treturn s.constInt32(n.Type, int32(i))\n\t\t\tcase 8:\n\t\t\t\treturn s.constInt64(n.Type, i)\n\t\t\tdefault:\n\t\t\t\ts.Fatalf(\"bad integer size %d\", n.Type.Size())\n\t\t\t\treturn nil\n\t\t\t}\n\t\tcase string:\n\t\t\tif u == \"\" {\n\t\t\t\treturn s.constEmptyString(n.Type)\n\t\t\t}\n\t\t\treturn s.entryNewValue0A(ssa.OpConstString, n.Type, u)\n\t\tcase bool:\n\t\t\treturn s.constBool(u)\n\t\tcase *NilVal:\n\t\t\tt := n.Type\n\t\t\tswitch {\n\t\t\tcase t.IsSlice():\n\t\t\t\treturn s.constSlice(t)\n\t\t\tcase t.IsInterface():\n\t\t\t\treturn s.constInterface(t)\n\t\t\tdefault:\n\t\t\t\treturn s.constNil(t)\n\t\t\t}\n\t\tcase *Mpflt:\n\t\t\tswitch n.Type.Size() {\n\t\t\tcase 4:\n\t\t\t\treturn s.constFloat32(n.Type, u.Float32())\n\t\t\tcase 8:\n\t\t\t\treturn s.constFloat64(n.Type, u.Float64())\n\t\t\tdefault:\n\t\t\t\ts.Fatalf(\"bad float size %d\", n.Type.Size())\n\t\t\t\treturn nil\n\t\t\t}\n\t\tcase *Mpcplx:\n\t\t\tr := &u.Real\n\t\t\ti := &u.Imag\n\t\t\tswitch n.Type.Size() {\n\t\t\tcase 8:\n\t\t\t\tpt := types.Types[TFLOAT32]\n\t\t\t\treturn s.newValue2(ssa.OpComplexMake, n.Type,\n\t\t\t\t\ts.constFloat32(pt, r.Float32()),\n\t\t\t\t\ts.constFloat32(pt, i.Float32()))\n\t\t\tcase 16:\n\t\t\t\tpt := types.Types[TFLOAT64]\n\t\t\t\treturn s.newValue2(ssa.OpComplexMake, n.Type,\n\t\t\t\t\ts.constFloat64(pt, r.Float64()),\n\t\t\t\t\ts.constFloat64(pt, i.Float64()))\n\t\t\tdefault:\n\t\t\t\ts.Fatalf(\"bad float size %d\", n.Type.Size())\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\tdefault:\n\t\t\ts.Fatalf(\"unhandled OLITERAL %v\", n.Val().Ctype())\n\t\t\treturn nil\n\t\t}\n\tcase OCONVNOP:\n\t\tto := n.Type        // 将left转换的目标类型\n\t\tfrom := n.Left.Type // 原类型\n\n\t\t// Assume everything will work out, so set up our return value.\n\t\t// Anything interesting that happens from here is a fatal.\n\t\tx := s.expr(n.Left)\n\n\t\t// Special case for not confusing GC and liveness.\n\t\t// We don't want pointers accidentally classified\n\t\t// as not-pointers or vice-versa because of copy\n\t\t// elision.\n\t\tif to.IsPtrShaped() != from.IsPtrShaped() { // 一个是指针另一个不是\n\t\t\treturn s.newValue2(ssa.OpConvert, to, x, s.mem())\n\t\t}\n\n\t\tv := s.newValue1(ssa.OpCopy, to, x) // ensure that v has the right type\n\n\t\t// CONVNOP closure\n\t\tif to.Etype == TFUNC && from.IsPtrShaped() {\n\t\t\treturn v\n\t\t}\n\n\t\t// named <--> unnamed type or typed <--> untyped const\n\t\tif from.Etype == to.Etype {\n\t\t\treturn v\n\t\t}\n\n\t\t// unsafe.Pointer <--> *T\n\t\tif to.Etype == TUNSAFEPTR && from.IsPtrShaped() || from.Etype == TUNSAFEPTR && to.IsPtrShaped() {\n\t\t\treturn v\n\t\t}\n\n\t\t// map <--> *hmap\n\t\tif to.Etype == TMAP && from.IsPtr() &&\n\t\t\tto.MapType().Hmap == from.Elem() {\n\t\t\treturn v\n\t\t}\n\n\t\tdowidth(from)\n\t\tdowidth(to)\n\t\tif from.Width != to.Width { // 校验类型宽度是否相同\n\t\t\ts.Fatalf(\"CONVNOP width mismatch %v (%d) -> %v (%d)\\n\", from, from.Width, to, to.Width)\n\t\t\treturn nil\n\t\t}\n\t\tif etypesign(from.Etype) != etypesign(to.Etype) { // 判断Etype的正负符号是否相同\n\t\t\ts.Fatalf(\"CONVNOP sign mismatch %v (%s) -> %v (%s)\\n\", from, from.Etype, to, to.Etype)\n\t\t\treturn nil\n\t\t}\n\n\t\tif instrumenting {\n\t\t\t// These appear to be fine, but they fail the\n\t\t\t// integer constraint below, so okay them here.\n\t\t\t// Sample non-integer conversion: map[string]string -> *uint8\n\t\t\treturn v\n\t\t}\n\n\t\tif etypesign(from.Etype) == 0 { // 不是整型\n\t\t\ts.Fatalf(\"CONVNOP unrecognized non-integer %v -> %v\\n\", from, to)\n\t\t\treturn nil\n\t\t}\n\n\t\t// integer, same width, same sign\n\t\treturn v\n\n\tcase OCONV: // Type(Left) (type conversion)\n\t\tx := s.expr(n.Left)\n\t\tft := n.Left.Type // from type\n\t\ttt := n.Type      // to type\n\t\tif ft.IsBoolean() && tt.IsKind(TUINT8) {\n\t\t\t// Bool -> uint8 is generated internally when indexing into runtime.staticbyte.\n\t\t\treturn s.newValue1(ssa.OpCopy, n.Type, x)\n\t\t}\n\t\tif ft.IsInteger() && tt.IsInteger() { // 整型强转为整型\n\t\t\tvar op ssa.Op\n\t\t\tif tt.Size() == ft.Size() { // 两种类型的宽度一致\n\t\t\t\top = ssa.OpCopy\n\t\t\t} else if tt.Size() < ft.Size() {\n\t\t\t\t// truncation\n\t\t\t\tswitch 10*ft.Size() + tt.Size() {\n\t\t\t\tcase 21: // ft类型的宽度为2,tt类型的宽度为1\n\t\t\t\t\top = ssa.OpTrunc16to8\n\t\t\t\tcase 41: // ft类型的宽度为4,tt类型的宽度为1\n\t\t\t\t\top = ssa.OpTrunc32to8\n\t\t\t\tcase 42: // ft类型的宽度为4,tt类型的宽度为2\n\t\t\t\t\top = ssa.OpTrunc32to16\n\t\t\t\tcase 81: // ft类型的宽度为8,tt类型的宽度为1\n\t\t\t\t\top = ssa.OpTrunc64to8\n\t\t\t\tcase 82: // ft类型的宽度为8,tt类型的宽度为2\n\t\t\t\t\top = ssa.OpTrunc64to16\n\t\t\t\tcase 84: // ft类型的宽度为8,tt类型的宽度为4\n\t\t\t\t\top = ssa.OpTrunc64to32\n\t\t\t\tdefault:\n\t\t\t\t\ts.Fatalf(\"weird integer truncation %v -> %v\", ft, tt)\n\t\t\t\t}\n\t\t\t} else if ft.IsSigned() { // ft为有符号整型类型且tt.Size() > ft.Size()\n\t\t\t\t// sign extension\n\t\t\t\tswitch 10*ft.Size() + tt.Size() {\n\t\t\t\tcase 12: // ft类型的宽度为1,tt类型的宽度为2\n\t\t\t\t\top = ssa.OpSignExt8to16\n\t\t\t\tcase 14: // ft类型的宽度为1,tt类型的宽度为4\n\t\t\t\t\top = ssa.OpSignExt8to32\n\t\t\t\tcase 18: // ft类型的宽度为1,tt类型的宽度为8\n\t\t\t\t\top = ssa.OpSignExt8to64\n\t\t\t\tcase 24: // ft类型的宽度为2,tt类型的宽度为4\n\t\t\t\t\top = ssa.OpSignExt16to32\n\t\t\t\tcase 28: // ft类型的宽度为2,tt类型的宽度为8\n\t\t\t\t\top = ssa.OpSignExt16to64\n\t\t\t\tcase 48: // ft类型的宽度为4,tt类型的宽度为8\n\t\t\t\t\top = ssa.OpSignExt32to64\n\t\t\t\tdefault:\n\t\t\t\t\ts.Fatalf(\"bad integer sign extension %v -> %v\", ft, tt)\n\t\t\t\t}\n\t\t\t} else { // ft为无符号整型类型且tt.Size() > ft.Size()\n\t\t\t\t// zero extension\n\t\t\t\tswitch 10*ft.Size() + tt.Size() {\n\t\t\t\tcase 12:\n\t\t\t\t\top = ssa.OpZeroExt8to16\n\t\t\t\tcase 14:\n\t\t\t\t\top = ssa.OpZeroExt8to32\n\t\t\t\tcase 18:\n\t\t\t\t\top = ssa.OpZeroExt8to64\n\t\t\t\tcase 24:\n\t\t\t\t\top = ssa.OpZeroExt16to32\n\t\t\t\tcase 28:\n\t\t\t\t\top = ssa.OpZeroExt16to64\n\t\t\t\tcase 48:\n\t\t\t\t\top = ssa.OpZeroExt32to64\n\t\t\t\tdefault:\n\t\t\t\t\ts.Fatalf(\"weird integer sign extension %v -> %v\", ft, tt)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn s.newValue1(op, n.Type, x)\n\t\t}\n\n\t\tif ft.IsFloat() || tt.IsFloat() { // 表示该类型强转中有一个类型为float\n\t\t\tconv, ok := fpConvOpToSSA[twoTypes{s.concreteEtype(ft), s.concreteEtype(tt)}]\n\t\t\tif s.config.RegSize == 4 && thearch.LinkArch.Family != sys.MIPS && !s.softFloat {\n\t\t\t\tif conv1, ok1 := fpConvOpToSSA32[twoTypes{s.concreteEtype(ft), s.concreteEtype(tt)}]; ok1 {\n\t\t\t\t\tconv = conv1\n\t\t\t\t}\n\t\t\t}\n\t\t\tif thearch.LinkArch.Family == sys.ARM64 || thearch.LinkArch.Family == sys.Wasm || thearch.LinkArch.Family == sys.S390X || s.softFloat {\n\t\t\t\tif conv1, ok1 := uint64fpConvOpToSSA[twoTypes{s.concreteEtype(ft), s.concreteEtype(tt)}]; ok1 {\n\t\t\t\t\tconv = conv1\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif thearch.LinkArch.Family == sys.MIPS && !s.softFloat {\n\t\t\t\tif ft.Size() == 4 && ft.IsInteger() && !ft.IsSigned() { // ft是uint32\n\t\t\t\t\t// tt is float32 or float64, and ft is also unsigned\n\t\t\t\t\tif tt.Size() == 4 {\n\t\t\t\t\t\treturn s.uint32Tofloat32(n, x, ft, tt)\n\t\t\t\t\t}\n\t\t\t\t\tif tt.Size() == 8 {\n\t\t\t\t\t\treturn s.uint32Tofloat64(n, x, ft, tt)\n\t\t\t\t\t}\n\t\t\t\t} else if tt.Size() == 4 && tt.IsInteger() && !tt.IsSigned() { // 强转为32位无符号整型\n\t\t\t\t\t// ft is float32 or float64, and tt is unsigned integer\n\t\t\t\t\tif ft.Size() == 4 {\n\t\t\t\t\t\treturn s.float32ToUint32(n, x, ft, tt)\n\t\t\t\t\t}\n\t\t\t\t\tif ft.Size() == 8 {\n\t\t\t\t\t\treturn s.float64ToUint32(n, x, ft, tt)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !ok {\n\t\t\t\ts.Fatalf(\"weird float conversion %v -> %v\", ft, tt)\n\t\t\t}\n\t\t\top1, op2, it := conv.op1, conv.op2, conv.intermediateType\n\n\t\t\tif op1 != ssa.OpInvalid && op2 != ssa.OpInvalid {\n\t\t\t\t// normal case, not tripping over unsigned 64\n\t\t\t\tif op1 == ssa.OpCopy {\n\t\t\t\t\tif op2 == ssa.OpCopy {\n\t\t\t\t\t\treturn x\n\t\t\t\t\t}\n\t\t\t\t\treturn s.newValueOrSfCall1(op2, n.Type, x)\n\t\t\t\t}\n\t\t\t\tif op2 == ssa.OpCopy {\n\t\t\t\t\treturn s.newValueOrSfCall1(op1, n.Type, x)\n\t\t\t\t}\n\t\t\t\treturn s.newValueOrSfCall1(op2, n.Type, s.newValueOrSfCall1(op1, types.Types[it], x))\n\t\t\t}\n\t\t\t// Tricky 64-bit unsigned cases.\n\t\t\tif ft.IsInteger() {\n\t\t\t\t// tt is float32 or float64, and ft is also unsigned\n\t\t\t\tif tt.Size() == 4 {\n\t\t\t\t\treturn s.uint64Tofloat32(n, x, ft, tt)\n\t\t\t\t}\n\t\t\t\tif tt.Size() == 8 {\n\t\t\t\t\treturn s.uint64Tofloat64(n, x, ft, tt)\n\t\t\t\t}\n\t\t\t\ts.Fatalf(\"weird unsigned integer to float conversion %v -> %v\", ft, tt)\n\t\t\t}\n\t\t\t// ft is float32 or float64, and tt is unsigned integer\n\t\t\tif ft.Size() == 4 {\n\t\t\t\treturn s.float32ToUint64(n, x, ft, tt)\n\t\t\t}\n\t\t\tif ft.Size() == 8 {\n\t\t\t\treturn s.float64ToUint64(n, x, ft, tt)\n\t\t\t}\n\t\t\ts.Fatalf(\"weird float to unsigned integer conversion %v -> %v\", ft, tt)\n\t\t\treturn nil\n\t\t}\n\n\t\tif ft.IsComplex() && tt.IsComplex() { // 都是复数类型\n\t\t\tvar op ssa.Op\n\t\t\tif ft.Size() == tt.Size() { // 拥有相同的宽度\n\t\t\t\tswitch ft.Size() {\n\t\t\t\tcase 8:\n\t\t\t\t\top = ssa.OpRound32F\n\t\t\t\tcase 16:\n\t\t\t\t\top = ssa.OpRound64F\n\t\t\t\tdefault:\n\t\t\t\t\ts.Fatalf(\"weird complex conversion %v -> %v\", ft, tt)\n\t\t\t\t}\n\t\t\t} else if ft.Size() == 8 && tt.Size() == 16 {\n\t\t\t\top = ssa.OpCvt32Fto64F\n\t\t\t} else if ft.Size() == 16 && tt.Size() == 8 {\n\t\t\t\top = ssa.OpCvt64Fto32F\n\t\t\t} else {\n\t\t\t\ts.Fatalf(\"weird complex conversion %v -> %v\", ft, tt)\n\t\t\t}\n\t\t\tftp := floatForComplex(ft)\n\t\t\tttp := floatForComplex(tt)\n\t\t\treturn s.newValue2(ssa.OpComplexMake, tt,\n\t\t\t\ts.newValueOrSfCall1(op, ttp, s.newValue1(ssa.OpComplexReal, ftp, x)),\n\t\t\t\ts.newValueOrSfCall1(op, ttp, s.newValue1(ssa.OpComplexImag, ftp, x)))\n\t\t}\n\n\t\ts.Fatalf(\"unhandled OCONV %s -> %s\", n.Left.Type.Etype, n.Type.Etype)\n\t\treturn nil\n\n\tcase ODOTTYPE: // Left.Right or Left.Type \t\tLeft必须为interface类型\n\t\tres, _ := s.dottype(n, false)\n\t\treturn res\n\n\t// binary ops\n\tcase OLT, OEQ, ONE, OLE, OGE, OGT:\n\t\ta := s.expr(n.Left)\n\t\tb := s.expr(n.Right)\n\t\tif n.Left.Type.IsComplex() { // Left是复数\n\t\t\tpt := floatForComplex(n.Left.Type) // 获取用于存储复数的float类型\n\t\t\top := s.ssaOp(OEQ, pt)\n\t\t\tr := s.newValueOrSfCall2(op, types.Types[TBOOL], s.newValue1(ssa.OpComplexReal, pt, a), s.newValue1(ssa.OpComplexReal, pt, b)) // 分别比较两个复数的实部和虚部\n\t\t\ti := s.newValueOrSfCall2(op, types.Types[TBOOL], s.newValue1(ssa.OpComplexImag, pt, a), s.newValue1(ssa.OpComplexImag, pt, b))\n\t\t\tc := s.newValue2(ssa.OpAndB, types.Types[TBOOL], r, i)\n\t\t\tswitch n.Op {\n\t\t\tcase OEQ:\n\t\t\t\treturn c\n\t\t\tcase ONE:\n\t\t\t\treturn s.newValue1(ssa.OpNot, types.Types[TBOOL], c)\n\t\t\tdefault:\n\t\t\t\ts.Fatalf(\"ordered complex compare %v\", n.Op)\n\t\t\t}\n\t\t}\n\n\t\t// Convert OGE and OGT into OLE and OLT.\n\t\top := n.Op\n\t\tswitch op {\n\t\tcase OGE: // 左边大于等于右边改为右边小于等于左边\n\t\t\top, a, b = OLE, b, a\n\t\tcase OGT: // Left > Right改为Right < Left\n\t\t\top, a, b = OLT, b, a\n\t\t}\n\t\tif n.Left.Type.IsFloat() { // 左部为浮点类型\n\t\t\t// float comparison\n\t\t\treturn s.newValueOrSfCall2(s.ssaOp(op, n.Left.Type), types.Types[TBOOL], a, b)\n\t\t}\n\t\t// integer comparison\n\t\treturn s.newValue2(s.ssaOp(op, n.Left.Type), types.Types[TBOOL], a, b)\n\tcase OMUL: // Left * Right\n\t\ta := s.expr(n.Left)\n\t\tb := s.expr(n.Right)\n\t\tif n.Type.IsComplex() { // 复数乘法\n\t\t\tmulop := ssa.OpMul64F\n\t\t\taddop := ssa.OpAdd64F\n\t\t\tsubop := ssa.OpSub64F\n\t\t\tpt := floatForComplex(n.Type) // Could be Float32 or Float64\n\t\t\twt := types.Types[TFLOAT64]   // Compute in Float64 to minimize cancellation error\n\t\t\t// 获取两个复数的实部与虚部\n\t\t\tareal := s.newValue1(ssa.OpComplexReal, pt, a)\n\t\t\tbreal := s.newValue1(ssa.OpComplexReal, pt, b)\n\t\t\taimag := s.newValue1(ssa.OpComplexImag, pt, a)\n\t\t\tbimag := s.newValue1(ssa.OpComplexImag, pt, b)\n\n\t\t\tif pt != wt { // Widen for calculation\t\tpt为float32\n\t\t\t\tareal = s.newValueOrSfCall1(ssa.OpCvt32Fto64F, wt, areal)\n\t\t\t\tbreal = s.newValueOrSfCall1(ssa.OpCvt32Fto64F, wt, breal)\n\t\t\t\taimag = s.newValueOrSfCall1(ssa.OpCvt32Fto64F, wt, aimag)\n\t\t\t\tbimag = s.newValueOrSfCall1(ssa.OpCvt32Fto64F, wt, bimag)\n\t\t\t}\n\n\t\t\txreal := s.newValueOrSfCall2(subop, wt, s.newValueOrSfCall2(mulop, wt, areal, breal), s.newValueOrSfCall2(mulop, wt, aimag, bimag))\n\t\t\tximag := s.newValueOrSfCall2(addop, wt, s.newValueOrSfCall2(mulop, wt, areal, bimag), s.newValueOrSfCall2(mulop, wt, aimag, breal))\n\n\t\t\tif pt != wt { // Narrow to store back\t\tpt为float32\n\t\t\t\txreal = s.newValueOrSfCall1(ssa.OpCvt64Fto32F, pt, xreal)\n\t\t\t\tximag = s.newValueOrSfCall1(ssa.OpCvt64Fto32F, pt, ximag)\n\t\t\t}\n\n\t\t\treturn s.newValue2(ssa.OpComplexMake, n.Type, xreal, ximag)\n\t\t}\n\n\t\tif n.Type.IsFloat() { // 浮点数相乘\n\t\t\treturn s.newValueOrSfCall2(s.ssaOp(n.Op, n.Type), a.Type, a, b)\n\t\t}\n\t\t// 整数相乘\n\t\treturn s.newValue2(s.ssaOp(n.Op, n.Type), a.Type, a, b)\n\n\tcase ODIV: // Left / Right\n\t\ta := s.expr(n.Left)\n\t\tb := s.expr(n.Right)\n\t\tif n.Type.IsComplex() { // 复数相除\n\t\t\t// TODO this is not executed because the front-end substitutes a runtime call.\n\t\t\t// That probably ought to change; with modest optimization the widen/narrow\n\t\t\t// conversions could all be elided in larger expression trees.\n\t\t\tmulop := ssa.OpMul64F\n\t\t\taddop := ssa.OpAdd64F\n\t\t\tsubop := ssa.OpSub64F\n\t\t\tdivop := ssa.OpDiv64F\n\t\t\tpt := floatForComplex(n.Type) // Could be Float32 or Float64\n\t\t\twt := types.Types[TFLOAT64]   // Compute in Float64 to minimize cancellation error\n\n\t\t\tareal := s.newValue1(ssa.OpComplexReal, pt, a)\n\t\t\tbreal := s.newValue1(ssa.OpComplexReal, pt, b)\n\t\t\taimag := s.newValue1(ssa.OpComplexImag, pt, a)\n\t\t\tbimag := s.newValue1(ssa.OpComplexImag, pt, b)\n\n\t\t\tif pt != wt { // Widen for calculation\n\t\t\t\tareal = s.newValueOrSfCall1(ssa.OpCvt32Fto64F, wt, areal)\n\t\t\t\tbreal = s.newValueOrSfCall1(ssa.OpCvt32Fto64F, wt, breal)\n\t\t\t\taimag = s.newValueOrSfCall1(ssa.OpCvt32Fto64F, wt, aimag)\n\t\t\t\tbimag = s.newValueOrSfCall1(ssa.OpCvt32Fto64F, wt, bimag)\n\t\t\t}\n\n\t\t\tdenom := s.newValueOrSfCall2(addop, wt, s.newValueOrSfCall2(mulop, wt, breal, breal), s.newValueOrSfCall2(mulop, wt, bimag, bimag))\n\t\t\txreal := s.newValueOrSfCall2(addop, wt, s.newValueOrSfCall2(mulop, wt, areal, breal), s.newValueOrSfCall2(mulop, wt, aimag, bimag))\n\t\t\tximag := s.newValueOrSfCall2(subop, wt, s.newValueOrSfCall2(mulop, wt, aimag, breal), s.newValueOrSfCall2(mulop, wt, areal, bimag))\n\n\t\t\t// TODO not sure if this is best done in wide precision or narrow\n\t\t\t// Double-rounding might be an issue.\n\t\t\t// Note that the pre-SSA implementation does the entire calculation\n\t\t\t// in wide format, so wide is compatible.\n\t\t\txreal = s.newValueOrSfCall2(divop, wt, xreal, denom)\n\t\t\tximag = s.newValueOrSfCall2(divop, wt, ximag, denom)\n\n\t\t\tif pt != wt { // Narrow to store back\n\t\t\t\txreal = s.newValueOrSfCall1(ssa.OpCvt64Fto32F, pt, xreal)\n\t\t\t\tximag = s.newValueOrSfCall1(ssa.OpCvt64Fto32F, pt, ximag)\n\t\t\t}\n\t\t\treturn s.newValue2(ssa.OpComplexMake, n.Type, xreal, ximag)\n\t\t}\n\t\tif n.Type.IsFloat() {\n\t\t\treturn s.newValueOrSfCall2(s.ssaOp(n.Op, n.Type), a.Type, a, b)\n\t\t}\n\t\treturn s.intDivide(n, a, b)\n\tcase OMOD: // Left % Right\n\t\ta := s.expr(n.Left)\n\t\tb := s.expr(n.Right)\n\t\treturn s.intDivide(n, a, b)\n\tcase OADD, OSUB: // Left + Right, Left - Right\n\t\ta := s.expr(n.Left)\n\t\tb := s.expr(n.Right)\n\t\tif n.Type.IsComplex() {\n\t\t\tpt := floatForComplex(n.Type)\n\t\t\top := s.ssaOp(n.Op, pt)\n\t\t\treturn s.newValue2(ssa.OpComplexMake, n.Type,\n\t\t\t\ts.newValueOrSfCall2(op, pt, s.newValue1(ssa.OpComplexReal, pt, a), s.newValue1(ssa.OpComplexReal, pt, b)),\n\t\t\t\ts.newValueOrSfCall2(op, pt, s.newValue1(ssa.OpComplexImag, pt, a), s.newValue1(ssa.OpComplexImag, pt, b)))\n\t\t}\n\t\tif n.Type.IsFloat() {\n\t\t\treturn s.newValueOrSfCall2(s.ssaOp(n.Op, n.Type), a.Type, a, b)\n\t\t}\n\t\treturn s.newValue2(s.ssaOp(n.Op, n.Type), a.Type, a, b)\n\tcase OAND, OOR, OXOR:\n\t\ta := s.expr(n.Left)\n\t\tb := s.expr(n.Right)\n\t\treturn s.newValue2(s.ssaOp(n.Op, n.Type), a.Type, a, b)\n\tcase OLSH, ORSH: // Left << Right, Left >> Right\n\t\ta := s.expr(n.Left)\n\t\tb := s.expr(n.Right)\n\t\tbt := b.Type       // 右部的类型\n\t\tif bt.IsSigned() { // 右部是有符号数\n\t\t\tcmp := s.newValue2(s.ssaOp(OLE, bt), types.Types[TBOOL], s.zeroVal(bt), b) // 判断b是否大于等于0\n\t\t\ts.check(cmp, panicshift)\n\t\t\tbt = bt.ToUnsigned() // 将bt的类型从有符号转为对应的无符号类型\n\t\t}\n\t\treturn s.newValue2(s.ssaShiftOp(n.Op, n.Type, bt), a.Type, a, b)\n\tcase OANDAND, OOROR: // Left && Right, Left || Right\n\t\t// To implement OANDAND (and OOROR), we introduce a\n\t\t// new temporary variable to hold the result. The\n\t\t// variable is associated with the OANDAND node in the\n\t\t// s.vars table (normally variables are only\n\t\t// associated with ONAME nodes). We convert\n\t\t//     A && B\n\t\t// to\n\t\t//     var = A\n\t\t//     if var {\n\t\t//         var = B\n\t\t//     }\n\t\t// Using var in the subsequent block introduces the\n\t\t// necessary phi variable.\n\t\tel := s.expr(n.Left)\n\t\ts.vars[n] = el // 一个布尔变量接收了Left的值\n\n\t\tb := s.endBlock()\n\t\tb.Kind = ssa.BlockIf\n\t\tb.SetControl(el)\n\t\t// In theory, we should set b.Likely here based on context.\n\t\t// However, gc only gives us likeliness hints\n\t\t// in a single place, for plain OIF statements,\n\t\t// and passing around context is finnicky, so don't bother for now.\n\n\t\tbRight := s.f.NewBlock(ssa.BlockPlain)\n\t\tbResult := s.f.NewBlock(ssa.BlockPlain)\n\t\tif n.Op == OANDAND {\n\t\t\tb.AddEdgeTo(bRight)\n\t\t\tb.AddEdgeTo(bResult)\n\t\t} else if n.Op == OOROR {\n\t\t\tb.AddEdgeTo(bResult)\n\t\t\tb.AddEdgeTo(bRight)\n\t\t}\n\n\t\ts.startBlock(bRight)\n\t\ter := s.expr(n.Right)\n\t\ts.vars[n] = er\n\n\t\tb = s.endBlock()\n\t\tb.AddEdgeTo(bResult)\n\n\t\ts.startBlock(bResult)\n\t\treturn s.variable(n, types.Types[TBOOL])\n\tcase OCOMPLEX: // complex(Left, Right) or complex(List[0]) where List[0] is a 2-result function call\t     complex(1, 2) // 1+2i\n\t\tr := s.expr(n.Left)\n\t\ti := s.expr(n.Right)\n\t\treturn s.newValue2(ssa.OpComplexMake, n.Type, r, i)\n\n\t// unary ops\n\tcase ONEG: // -Left\n\t\ta := s.expr(n.Left)\n\t\tif n.Type.IsComplex() { // Left是一个复数\n\t\t\ttp := floatForComplex(n.Type)\n\t\t\tnegop := s.ssaOp(n.Op, tp)\n\t\t\treturn s.newValue2(ssa.OpComplexMake, n.Type,\n\t\t\t\ts.newValue1(negop, tp, s.newValue1(ssa.OpComplexReal, tp, a)),\n\t\t\t\ts.newValue1(negop, tp, s.newValue1(ssa.OpComplexImag, tp, a)))\n\t\t}\n\t\treturn s.newValue1(s.ssaOp(n.Op, n.Type), a.Type, a)\n\tcase ONOT, OBITNOT: // !Left, // ^Left\n\t\ta := s.expr(n.Left)\n\t\treturn s.newValue1(s.ssaOp(n.Op, n.Type), a.Type, a)\n\tcase OIMAG, OREAL: // imag(Left), real(Left)\n\t\ta := s.expr(n.Left)\n\t\treturn s.newValue1(s.ssaOp(n.Op, n.Left.Type), n.Type, a)\n\tcase OPLUS: // +Left\n\t\treturn s.expr(n.Left)\n\n\tcase OADDR: // &Left\n\t\treturn s.addr(n.Left)\n\n\tcase ORESULT: // result of a function call; Xoffset is stack offset\n\t\taddr := s.constOffPtrSP(types.NewPtr(n.Type), n.Xoffset)\n\t\treturn s.load(n.Type, addr)\n\n\tcase ODEREF: // *Left\n\t\tp := s.exprPtr(n.Left, n.Bounded(), n.Pos)\n\t\treturn s.load(n.Type, p)\n\n\tcase ODOT: // Left.Sym (Left is of struct type)\n\t\tif n.Left.Op == OSTRUCTLIT {\n\t\t\t// All literals with nonzero fields have already been\n\t\t\t// rewritten during walk. Any that remain are just T{}\n\t\t\t// or equivalents. Use the zero value.\n\t\t\tif !isZero(n.Left) {\n\t\t\t\ts.Fatalf(\"literal with nonzero value in SSA: %v\", n.Left)\n\t\t\t}\n\t\t\treturn s.zeroVal(n.Type)\n\t\t}\n\t\t// If n is addressable and can't be represented in\n\t\t// SSA, then load just the selected field. This\n\t\t// prevents false memory dependencies in race/msan\n\t\t// instrumentation.\n\t\tif islvalue(n) && !s.canSSA(n) {\n\t\t\tp := s.addr(n)\n\t\t\treturn s.load(n.Type, p)\n\t\t}\n\t\tv := s.expr(n.Left)\n\t\treturn s.newValue1I(ssa.OpStructSelect, n.Type, int64(fieldIdx(n)), v)\n\n\tcase ODOTPTR: // Left.Sym (Left is of pointer to struct type)\n\t\tp := s.exprPtr(n.Left, n.Bounded(), n.Pos)\n\t\tp = s.newValue1I(ssa.OpOffPtr, types.NewPtr(n.Type), n.Xoffset, p)\n\t\treturn s.load(n.Type, p)\n\n\tcase OINDEX: // Left[Right] (index of array or slice)\n\t\tswitch {\n\t\tcase n.Left.Type.IsString():\n\t\t\tif n.Bounded() && Isconst(n.Left, CTSTR) && Isconst(n.Right, CTINT) {\n\t\t\t\t// Replace \"abc\"[1] with 'b'.\n\t\t\t\t// Delayed until now because \"abc\"[1] is not an ideal constant.\n\t\t\t\t// See test/fixedbugs/issue11370.go.\n\t\t\t\treturn s.newValue0I(ssa.OpConst8, types.Types[TUINT8], int64(int8(strlit(n.Left)[n.Right.Int64()])))\n\t\t\t}\n\t\t\ta := s.expr(n.Left)\n\t\t\ti := s.expr(n.Right)\n\t\t\tlen := s.newValue1(ssa.OpStringLen, types.Types[TINT], a)\n\t\t\ti = s.boundsCheck(i, len, ssa.BoundsIndex, n.Bounded())\n\t\t\tptrtyp := s.f.Config.Types.BytePtr\n\t\t\tptr := s.newValue1(ssa.OpStringPtr, ptrtyp, a)\n\t\t\tif Isconst(n.Right, CTINT) {\n\t\t\t\tptr = s.newValue1I(ssa.OpOffPtr, ptrtyp, n.Right.Int64(), ptr)\n\t\t\t} else {\n\t\t\t\tptr = s.newValue2(ssa.OpAddPtr, ptrtyp, ptr, i)\n\t\t\t}\n\t\t\treturn s.load(types.Types[TUINT8], ptr)\n\t\tcase n.Left.Type.IsSlice():\n\t\t\tp := s.addr(n)\n\t\t\treturn s.load(n.Left.Type.Elem(), p)\n\t\tcase n.Left.Type.IsArray():\n\t\t\tif canSSAType(n.Left.Type) {\n\t\t\t\t// SSA can handle arrays of length at most 1.\n\t\t\t\tbound := n.Left.Type.NumElem()\n\t\t\t\ta := s.expr(n.Left)\n\t\t\t\ti := s.expr(n.Right)\n\t\t\t\tif bound == 0 {\n\t\t\t\t\t// Bounds check will never succeed.  Might as well\n\t\t\t\t\t// use constants for the bounds check.\n\t\t\t\t\tz := s.constInt(types.Types[TINT], 0)\n\t\t\t\t\ts.boundsCheck(z, z, ssa.BoundsIndex, false)\n\t\t\t\t\t// The return value won't be live, return junk.\n\t\t\t\t\treturn s.newValue0(ssa.OpUnknown, n.Type)\n\t\t\t\t}\n\t\t\t\tlen := s.constInt(types.Types[TINT], bound)\n\t\t\t\ts.boundsCheck(i, len, ssa.BoundsIndex, n.Bounded()) // checks i == 0\n\t\t\t\treturn s.newValue1I(ssa.OpArraySelect, n.Type, 0, a)\n\t\t\t}\n\t\t\tp := s.addr(n)\n\t\t\treturn s.load(n.Left.Type.Elem(), p)\n\t\tdefault:\n\t\t\ts.Fatalf(\"bad type for index %v\", n.Left.Type)\n\t\t\treturn nil\n\t\t}\n\n\tcase OLEN, OCAP: // len(Left), cap(Left)\n\t\tswitch {\n\t\tcase n.Left.Type.IsSlice():\n\t\t\top := ssa.OpSliceLen\n\t\t\tif n.Op == OCAP {\n\t\t\t\top = ssa.OpSliceCap\n\t\t\t}\n\t\t\treturn s.newValue1(op, types.Types[TINT], s.expr(n.Left))\n\t\tcase n.Left.Type.IsString(): // string; not reachable for OCAP\n\t\t\treturn s.newValue1(ssa.OpStringLen, types.Types[TINT], s.expr(n.Left))\n\t\tcase n.Left.Type.IsMap(), n.Left.Type.IsChan():\n\t\t\treturn s.referenceTypeBuiltin(n, s.expr(n.Left))\n\t\tdefault: // array\n\t\t\treturn s.constInt(types.Types[TINT], n.Left.Type.NumElem())\n\t\t}\n\n\tcase OSPTR: // Left是一个切片, 该操作获取Left中存储元素的指针\n\t\ta := s.expr(n.Left)\n\t\tif n.Left.Type.IsSlice() {\n\t\t\treturn s.newValue1(ssa.OpSlicePtr, n.Type, a)\n\t\t} else {\n\t\t\treturn s.newValue1(ssa.OpStringPtr, n.Type, a)\n\t\t}\n\n\tcase OITAB: // Left指向一个非空接口\n\t\ta := s.expr(n.Left)\n\t\treturn s.newValue1(ssa.OpITab, n.Type, a)\n\n\tcase OIDATA:\n\t\ta := s.expr(n.Left)\n\t\treturn s.newValue1(ssa.OpIData, n.Type, a)\n\n\tcase OEFACE: // itable and data words of an empty-interface value.\n\t\ttab := s.expr(n.Left)\n\t\tdata := s.expr(n.Right)\n\t\treturn s.newValue2(ssa.OpIMake, n.Type, tab, data)\n\n\tcase OSLICEHEADER: // sliceheader{Left, List[0], List[1]} (Left is unsafe.Pointer, List[0] is length, List[1] is capacity)\n\t\tp := s.expr(n.Left)\n\t\tl := s.expr(n.List.First())\n\t\tc := s.expr(n.List.Second())\n\t\treturn s.newValue3(ssa.OpSliceMake, n.Type, p, l, c)\n\n\tcase OSLICE, OSLICEARR, OSLICE3, OSLICE3ARR:\n\t\tv := s.expr(n.Left) // 处理切片或数组\n\t\tv.Extra = n.Extra\n\t\tvar i, j, k *ssa.Value\n\t\tlow, high, max := n.SliceBounds() // 获取[low:high:max]切片操作中的三个值\n\t\tif low != nil {\n\t\t\ti = s.expr(low)\n\t\t}\n\t\tif high != nil {\n\t\t\tj = s.expr(high)\n\t\t}\n\t\tif max != nil {\n\t\t\tk = s.expr(max)\n\t\t}\n\t\tp, l, c := s.slice(v, i, j, k, n.Bounded())\n\t\treturn s.newValue3(ssa.OpSliceMake, n.Type, p, l, c)\n\n\tcase OSLICESTR: // Left[List[0] : List[1]] (Left is string)\n\t\tv := s.expr(n.Left)\n\t\tvar i, j *ssa.Value\n\t\tlow, high, _ := n.SliceBounds()\n\t\tif low != nil {\n\t\t\ti = s.expr(low)\n\t\t}\n\t\tif high != nil {\n\t\t\tj = s.expr(high)\n\t\t}\n\t\tp, l, _ := s.slice(v, i, j, nil, n.Bounded())\n\t\treturn s.newValue2(ssa.OpStringMake, n.Type, p, l)\n\n\tcase OCALLFUNC: // Left(List/Rlist) (function call f(args))\n\t\tif isIntrinsicCall(n) {\n\t\t\treturn s.intrinsicCall(n)\n\t\t}\n\t\tfallthrough\n\n\tcase OCALLINTER, OCALLMETH:\n\t\ta := s.call(n, callNormal)\n\t\treturn s.load(n.Type, a)\n\n\tcase OGETG: // runtime.getg() (read g pointer)\n\t\treturn s.newValue1(ssa.OpGetG, n.Type, s.mem())\n\n\tcase OAPPEND: // append(List); after walk, Left may contain elem type descriptor\n\t\treturn s.append(n, false)\n\n\tcase OSTRUCTLIT, OARRAYLIT:\n\t\t// All literals with nonzero fields have already been\n\t\t// rewritten during walk. Any that remain are just T{}\n\t\t// or equivalents. Use the zero value.\n\t\tif !isZero(n) {\n\t\t\ts.Fatalf(\"literal with nonzero value in SSA: %v\", n)\n\t\t}\n\t\treturn s.zeroVal(n.Type)\n\n\tcase ONEWOBJ: // runtime.newobject(n.Type); introduced by walk; Left is type descriptor\n\t\tif n.Type.Elem().Size() == 0 {\n\t\t\treturn s.newValue1A(ssa.OpAddr, n.Type, zerobaseSym, s.sb)\n\t\t}\n\t\ttyp := s.expr(n.Left)\n\t\tvv := s.rtcall(newobject, true, []*types.Type{n.Type}, typ)\n\t\treturn vv[0]\n\n\tdefault:\n\t\ts.Fatalf(\"unhandled expr %v\", n.Op)\n\t\treturn nil\n\t}\n}\n\n// append converts an OAPPEND node to SSA.\n// If inplace is false, it converts the OAPPEND expression n to an ssa.Value,\n// adds it to s, and returns the Value.\n// If inplace is true, it writes the result of the OAPPEND expression n\n// back to the slice being appended to, and returns nil.\n// inplace MUST be set to false if the slice can be SSA'd.\nfunc (s *state) append(n *Node, inplace bool) *ssa.Value {\n\t// If inplace is false, process as expression \"append(s, e1, e2, e3)\":\n\t//\n\t// ptr, len, cap := s\n\t// newlen := len + 3\n\t// if newlen > cap {\n\t//     ptr, len, cap = growslice(s, newlen)\n\t//     newlen = len + 3 // recalculate to avoid a spill\n\t// }\n\t// // with write barriers, if needed:\n\t// *(ptr+len) = e1\n\t// *(ptr+len+1) = e2\n\t// *(ptr+len+2) = e3\n\t// return makeslice(ptr, newlen, cap)\n\t//\n\t//\n\t// If inplace is true, process as statement \"s = append(s, e1, e2, e3)\":\n\t//\n\t// a := &s\n\t// ptr, len, cap := s\n\t// newlen := len + 3\n\t// if uint(newlen) > uint(cap) {\n\t//    newptr, len, newcap = growslice(ptr, len, cap, newlen)\n\t//    vardef(a)       // if necessary, advise liveness we are writing a new a\n\t//    *a.cap = newcap // write before ptr to avoid a spill\n\t//    *a.ptr = newptr // with write barrier\n\t// }\n\t// newlen = len + 3 // recalculate to avoid a spill\n\t// *a.len = newlen\n\t// // with write barriers, if needed:\n\t// *(ptr+len) = e1\n\t// *(ptr+len+1) = e2\n\t// *(ptr+len+2) = e3\n\n\tet := n.Type.Elem()    // 获取元素的类型\n\tpt := types.NewPtr(et) // 元素的指针类型\n\n\t// Evaluate slice\n\tsliceNode := n.List.First() // the slice node is the first in the list\n\n\tvar slice, addr *ssa.Value\n\tif inplace {\n\t\taddr = s.addr(sliceNode) // sliceNode相当于左边被赋值的变量,这里取它的地址\n\t\tslice = s.load(n.Type, addr)\n\t} else {\n\t\tslice = s.expr(sliceNode)\n\t}\n\n\t// Allocate new blocks\n\tgrow := s.f.NewBlock(ssa.BlockPlain)\n\tassign := s.f.NewBlock(ssa.BlockPlain)\n\n\t// Decide if we need to grow\n\tnargs := int64(n.List.Len() - 1)\n\tp := s.newValue1(ssa.OpSlicePtr, pt, slice)                                                                     // 获取切片对象\n\tl := s.newValue1(ssa.OpSliceLen, types.Types[TINT], slice)                                                      // 获取len\n\tc := s.newValue1(ssa.OpSliceCap, types.Types[TINT], slice)                                                      // 获取cap\n\tnl := s.newValue2(s.ssaOp(OADD, types.Types[TINT]), types.Types[TINT], l, s.constInt(types.Types[TINT], nargs)) // 计算len+nargs\n\n\tcmp := s.newValue2(s.ssaOp(OLT, types.Types[TUINT]), types.Types[TBOOL], c, nl) // if cap < newlen\n\ts.vars[&ptrVar] = p                                                             // 记录指针变量\n\n\tif !inplace {\n\t\ts.vars[&newlenVar] = nl\n\t\ts.vars[&capVar] = c\n\t} else {\n\t\ts.vars[&lenVar] = l\n\t}\n\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf\n\tb.Likely = ssa.BranchUnlikely\n\tb.SetControl(cmp)\n\tb.AddEdgeTo(grow) // grow是b的第一个后继块,表示cap小于newlen时扩容\n\tb.AddEdgeTo(assign)\n\n\t// Call growslice\n\ts.startBlock(grow)\n\ttaddr := s.expr(n.Left)                                                                                     // append操作左边的变量\n\tr := s.rtcall(growslice, true, []*types.Type{pt, types.Types[TINT], types.Types[TINT]}, taddr, p, l, c, nl) // 调用growslice函数\n\n\tif inplace {\n\t\tif sliceNode.Op == ONAME && sliceNode.Class() != PEXTERN { // 不是向全局变量中添加元素\n\t\t\t// Tell liveness we're about to build a new slice\n\t\t\ts.vars[&memVar] = s.newValue1A(ssa.OpVarDef, types.TypeMem, sliceNode, s.mem())\n\t\t}\n\t\tcapaddr := s.newValue1I(ssa.OpOffPtr, s.f.Config.Types.IntPtr, sliceCapOffset, addr) // 根据slice的cap偏移获取cap的地址, int*类型\n\t\ts.store(types.Types[TINT], capaddr, r[2])                                            // grow后的cap保存到cap地址中\n\t\ts.store(pt, addr, r[0])                                                              // grow后的切片保存到切片地址中\n\t\t// load the value we just stored to avoid having to spill it\n\t\ts.vars[&ptrVar] = s.load(pt, addr) // 将该地址赋给append语句的左部变量\n\t\ts.vars[&lenVar] = r[1]             // avoid a spill in the fast path\n\t} else {\n\t\ts.vars[&ptrVar] = r[0]\n\t\ts.vars[&newlenVar] = s.newValue2(s.ssaOp(OADD, types.Types[TINT]), types.Types[TINT], r[1], s.constInt(types.Types[TINT], nargs))\n\t\ts.vars[&capVar] = r[2]\n\t}\n\n\tb = s.endBlock()\n\tb.AddEdgeTo(assign)\n\n\t// assign new elements to slots\n\ts.startBlock(assign)\n\n\tif inplace {\n\t\tl = s.variable(&lenVar, types.Types[TINT])                                                                     // generates phi for len\n\t\tnl = s.newValue2(s.ssaOp(OADD, types.Types[TINT]), types.Types[TINT], l, s.constInt(types.Types[TINT], nargs)) // newlen = len+args\n\t\tlenaddr := s.newValue1I(ssa.OpOffPtr, s.f.Config.Types.IntPtr, sliceLenOffset, addr)                           // ptr.len\n\t\ts.store(types.Types[TINT], lenaddr, nl)                                                                        // *ptr.len = newlen\t赋值回去\n\t}\n\n\t// Evaluate args\n\ttype argRec struct {\n\t\t// if store is true, we're appending the value v.  If false, we're appending the\n\t\t// value at *v.\n\t\tv     *ssa.Value\n\t\tstore bool\n\t}\n\targs := make([]argRec, 0, nargs)\n\tfor _, n := range n.List.Slice()[1:] { // 遍历append节点的所有参数\n\t\tif canSSAType(n.Type) { // 参数的类型可以直接ssa编译\n\t\t\targs = append(args, argRec{v: s.expr(n), store: true})\n\t\t} else {\n\t\t\tv := s.addr(n)                    // 取参数的地址\n\t\t\targs = append(args, argRec{v: v}) // 将参数的地址添加到args中\n\t\t}\n\t}\n\n\tp = s.variable(&ptrVar, pt) // generates phi for ptr\n\tif !inplace {\n\t\tnl = s.variable(&newlenVar, types.Types[TINT]) // generates phi for nl\n\t\tc = s.variable(&capVar, types.Types[TINT])     // generates phi for cap\n\t}\n\tp2 := s.newValue2(ssa.OpPtrIndex, pt, p, l) // 获取p[l]\n\tfor i, arg := range args {\n\t\taddr := s.newValue2(ssa.OpPtrIndex, pt, p2, s.constInt(types.Types[TINT], int64(i)))\n\t\tif arg.store {\n\t\t\ts.storeType(et, addr, arg.v, 0, true)\n\t\t} else {\n\t\t\ts.move(et, addr, arg.v)\n\t\t}\n\t}\n\n\tdelete(s.vars, &ptrVar)\n\tif inplace {\n\t\tdelete(s.vars, &lenVar)\n\t\treturn nil\n\t}\n\tdelete(s.vars, &newlenVar)\n\tdelete(s.vars, &capVar)\n\t// make result\n\treturn s.newValue3(ssa.OpSliceMake, n.Type, p, nl, c)\n}\n\n// condBranch evaluates the boolean expression cond and branches to yes\n// if cond is true and no if cond is false.\n// This function is intended to handle && and || better than just calling\n// s.expr(cond) and branching on the result.\nfunc (s *state) condBranch(cond *Node, yes, no *ssa.Block, likely int8) {\n\tswitch cond.Op {\n\tcase OANDAND:\n\t\tmid := s.f.NewBlock(ssa.BlockPlain) // 这个应该是&&后面的布尔表达式\n\t\ts.stmtList(cond.Ninit)\n\t\ts.condBranch(cond.Left, mid, no, max8(likely, 0))\n\t\ts.startBlock(mid)\n\t\ts.condBranch(cond.Right, yes, no, likely)\n\t\treturn\n\t\t// Note: if likely==1, then both recursive calls pass 1.\n\t\t// If likely==-1, then we don't have enough information to decide\n\t\t// whether the first branch is likely or not. So we pass 0 for\n\t\t// the likeliness of the first branch.\n\t\t// TODO: have the frontend give us branch prediction hints for\n\t\t// OANDAND and OOROR nodes (if it ever has such info).\n\tcase OOROR:\n\t\tmid := s.f.NewBlock(ssa.BlockPlain)\n\t\ts.stmtList(cond.Ninit)\n\t\ts.condBranch(cond.Left, yes, mid, min8(likely, 0))\n\t\ts.startBlock(mid)\n\t\ts.condBranch(cond.Right, yes, no, likely)\n\t\treturn\n\t\t// Note: if likely==-1, then both recursive calls pass -1.\n\t\t// If likely==1, then we don't have enough info to decide\n\t\t// the likelihood of the first branch.\n\tcase ONOT:\n\t\ts.stmtList(cond.Ninit)\n\t\ts.condBranch(cond.Left, no, yes, -likely)\n\t\treturn\n\t}\n\tc := s.expr(cond)\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf\n\tb.SetControl(c)\n\tb.Likely = ssa.BranchPrediction(likely) // gc and ssa both use -1/0/+1 for likeliness\n\tb.AddEdgeTo(yes)\n\tb.AddEdgeTo(no)\n}\n\ntype skipMask uint8\n\nconst (\n\tskipPtr skipMask = 1 << iota // 忽略指针\n\tskipLen                      // 忽略len\n\tskipCap                      // 忽略cap\n)\n\n// assign does left = right.\n// Right has already been evaluated to ssa, left has not.\n// If deref is true, then we do left = *right instead (and right has already been nil-checked).\n// If deref is true and right == nil, just do left = 0.\n// skip indicates assignments (at the top level) that can be avoided.\nfunc (s *state) assign(left *Node, right *ssa.Value, deref bool, skip skipMask) {\n\tif left.Op == ONAME && left.isBlank() {\n\t\treturn\n\t}\n\tt := left.Type\n\tdowidth(t)\n\tif s.canSSA(left) {\n\t\tif deref {\n\t\t\ts.Fatalf(\"can SSA LHS %v but not RHS %s\", left, right)\n\t\t}\n\t\tif left.Op == ODOT {\n\t\t\t// We're assigning to a field of an ssa-able value.\n\t\t\t// We need to build a new structure with the new value for the\n\t\t\t// field we're assigning and the old values for the other fields.\n\t\t\t// For instance:\n\t\t\t//   type T struct {a, b, c int}\n\t\t\t//   var T x\n\t\t\t//   x.b = 5\n\t\t\t// For the x.b = 5 assignment we want to generate x = T{x.a, 5, x.c}\n\n\t\t\t// Grab information about the structure type.\n\t\t\tt := left.Left.Type   // 结构体类型\n\t\t\tnf := t.NumFields()   // 字段数量\n\t\t\tidx := fieldIdx(left) // 字段nf是结构体t的第几个字段\n\n\t\t\t// Grab old value of structure.\n\t\t\told := s.expr(left.Left)\n\n\t\t\t// Make new structure.\n\t\t\tnew := s.newValue0(ssa.StructMakeOp(t.NumFields()), t)\n\n\t\t\t// Add fields as args.\n\t\t\tfor i := 0; i < nf; i++ {\n\t\t\t\tif i == idx {\n\t\t\t\t\tnew.AddArg(right)\n\t\t\t\t} else {\n\t\t\t\t\tnew.AddArg(s.newValue1I(ssa.OpStructSelect, t.FieldType(i), int64(i), old))\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Recursively assign the new value we've made to the base of the dot op.\n\t\t\ts.assign(left.Left, new, false, 0)\n\t\t\t// TODO: do we need to update named values here?\n\t\t\treturn\n\t\t}\n\t\tif left.Op == OINDEX && left.Left.Type.IsArray() {\n\t\t\ts.pushLine(left.Pos)\n\t\t\tdefer s.popLine()\n\t\t\t// We're assigning to an element of an ssa-able array.\n\t\t\t// a[i] = v\n\t\t\tt := left.Left.Type\n\t\t\tn := t.NumElem() // 数组可以存储的最大容量\n\n\t\t\ti := s.expr(left.Right) // index\n\t\t\tif n == 0 {\n\t\t\t\t// The bounds check must fail.  Might as well\n\t\t\t\t// ignore the actual index and just use zeros.\n\t\t\t\tz := s.constInt(types.Types[TINT], 0)\n\t\t\t\ts.boundsCheck(z, z, ssa.BoundsIndex, false)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif n != 1 { // 因为到这一步需要canssa,其中判断数组元素长度应该为1\n\t\t\t\ts.Fatalf(\"assigning to non-1-length array\")\n\t\t\t}\n\t\t\t// Rewrite to a = [1]{v}\n\t\t\tlen := s.constInt(types.Types[TINT], 1)\n\t\t\ts.boundsCheck(i, len, ssa.BoundsIndex, false) // checks i == 0\n\t\t\tv := s.newValue1(ssa.OpArrayMake1, t, right)\n\t\t\ts.assign(left.Left, v, false, 0) // 将新创建的数组赋值给原数组\n\t\t\treturn\n\t\t}\n\t\t// Update variable assignment.\n\t\ts.vars[left] = right\n\t\ts.addNamedValue(left, right)\n\t\treturn\n\t}\n\n\t// If this assignment clobbers an entire local variable, then emit\n\t// OpVarDef so liveness analysis knows the variable is redefined.\n\tif base := clobberBase(left); base.Op == ONAME && base.Class() != PEXTERN && skip == 0 {\n\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarDef, types.TypeMem, base, s.mem(), !base.IsAutoTmp())\n\t}\n\n\t// Left is not ssa-able. Compute its address.\n\taddr := s.addr(left)\n\tif isReflectHeaderDataField(left) {\n\t\t// Package unsafe's documentation says storing pointers into\n\t\t// reflect.SliceHeader and reflect.StringHeader's Data fields\n\t\t// is valid, even though they have type uintptr (#19168).\n\t\t// Mark it pointer type to signal the writebarrier pass to\n\t\t// insert a write barrier.\n\t\tt = types.Types[TUNSAFEPTR]\n\t}\n\tif deref {\n\t\t// Treat as a mem->mem move.\n\t\tif right == nil {\n\t\t\ts.zero(t, addr)\n\t\t} else {\n\t\t\ts.move(t, addr, right)\n\t\t}\n\t\treturn\n\t}\n\t// Treat as a store.\n\ts.storeType(t, addr, right, skip, !left.IsAutoTmp())\n}\n\n// zeroVal returns the zero value for type t.\nfunc (s *state) zeroVal(t *types.Type) *ssa.Value {\n\tswitch {\n\tcase t.IsInteger():\n\t\tswitch t.Size() {\n\t\tcase 1:\n\t\t\treturn s.constInt8(t, 0)\n\t\tcase 2:\n\t\t\treturn s.constInt16(t, 0)\n\t\tcase 4:\n\t\t\treturn s.constInt32(t, 0)\n\t\tcase 8:\n\t\t\treturn s.constInt64(t, 0)\n\t\tdefault:\n\t\t\ts.Fatalf(\"bad sized integer type %v\", t)\n\t\t}\n\tcase t.IsFloat():\n\t\tswitch t.Size() {\n\t\tcase 4:\n\t\t\treturn s.constFloat32(t, 0)\n\t\tcase 8:\n\t\t\treturn s.constFloat64(t, 0)\n\t\tdefault:\n\t\t\ts.Fatalf(\"bad sized float type %v\", t)\n\t\t}\n\tcase t.IsComplex():\n\t\tswitch t.Size() {\n\t\tcase 8:\n\t\t\tz := s.constFloat32(types.Types[TFLOAT32], 0)\n\t\t\treturn s.entryNewValue2(ssa.OpComplexMake, t, z, z)\n\t\tcase 16:\n\t\t\tz := s.constFloat64(types.Types[TFLOAT64], 0)\n\t\t\treturn s.entryNewValue2(ssa.OpComplexMake, t, z, z)\n\t\tdefault:\n\t\t\ts.Fatalf(\"bad sized complex type %v\", t)\n\t\t}\n\n\tcase t.IsString():\n\t\treturn s.constEmptyString(t)\n\tcase t.IsPtrShaped():\n\t\treturn s.constNil(t)\n\tcase t.IsBoolean():\n\t\treturn s.constBool(false)\n\tcase t.IsInterface():\n\t\treturn s.constInterface(t)\n\tcase t.IsSlice():\n\t\treturn s.constSlice(t)\n\tcase t.IsStruct():\n\t\tn := t.NumFields() // 获取结构体的字段数量\n\t\tv := s.entryNewValue0(ssa.StructMakeOp(t.NumFields()), t)\n\t\tfor i := 0; i < n; i++ { // 将结构体中的所有字段的0值放到Args数组中\n\t\t\tv.AddArg(s.zeroVal(t.FieldType(i)))\n\t\t}\n\t\treturn v\n\tcase t.IsArray():\n\t\tswitch t.NumElem() { // number of elements\n\t\tcase 0:\n\t\t\treturn s.entryNewValue0(ssa.OpArrayMake0, t)\n\t\tcase 1:\n\t\t\treturn s.entryNewValue1(ssa.OpArrayMake1, t, s.zeroVal(t.Elem()))\n\t\t}\n\t}\n\ts.Fatalf(\"zero for type %v not implemented\", t)\n\treturn nil\n}\n\ntype callKind int8\n\nconst (\n\tcallNormal callKind = iota\n\tcallDefer\n\tcallDeferStack\n\tcallGo\n)\n\ntype sfRtCallDef struct {\n\trtfn  *obj.LSym\n\trtype types.EType\n}\n\nvar softFloatOps map[ssa.Op]sfRtCallDef\n\nfunc softfloatInit() {\n\t// Some of these operations get transformed by sfcall.\n\tsoftFloatOps = map[ssa.Op]sfRtCallDef{\n\t\tssa.OpAdd32F: sfRtCallDef{sysfunc(\"fadd32\"), TFLOAT32},\n\t\tssa.OpAdd64F: sfRtCallDef{sysfunc(\"fadd64\"), TFLOAT64},\n\t\tssa.OpSub32F: sfRtCallDef{sysfunc(\"fadd32\"), TFLOAT32},\n\t\tssa.OpSub64F: sfRtCallDef{sysfunc(\"fadd64\"), TFLOAT64},\n\t\tssa.OpMul32F: sfRtCallDef{sysfunc(\"fmul32\"), TFLOAT32},\n\t\tssa.OpMul64F: sfRtCallDef{sysfunc(\"fmul64\"), TFLOAT64},\n\t\tssa.OpDiv32F: sfRtCallDef{sysfunc(\"fdiv32\"), TFLOAT32},\n\t\tssa.OpDiv64F: sfRtCallDef{sysfunc(\"fdiv64\"), TFLOAT64},\n\n\t\tssa.OpEq64F:   sfRtCallDef{sysfunc(\"feq64\"), TBOOL},\n\t\tssa.OpEq32F:   sfRtCallDef{sysfunc(\"feq32\"), TBOOL},\n\t\tssa.OpNeq64F:  sfRtCallDef{sysfunc(\"feq64\"), TBOOL},\n\t\tssa.OpNeq32F:  sfRtCallDef{sysfunc(\"feq32\"), TBOOL},\n\t\tssa.OpLess64F: sfRtCallDef{sysfunc(\"fgt64\"), TBOOL},\n\t\tssa.OpLess32F: sfRtCallDef{sysfunc(\"fgt32\"), TBOOL},\n\t\tssa.OpLeq64F:  sfRtCallDef{sysfunc(\"fge64\"), TBOOL},\n\t\tssa.OpLeq32F:  sfRtCallDef{sysfunc(\"fge32\"), TBOOL},\n\n\t\tssa.OpCvt32to32F:  sfRtCallDef{sysfunc(\"fint32to32\"), TFLOAT32},\n\t\tssa.OpCvt32Fto32:  sfRtCallDef{sysfunc(\"f32toint32\"), TINT32},\n\t\tssa.OpCvt64to32F:  sfRtCallDef{sysfunc(\"fint64to32\"), TFLOAT32},\n\t\tssa.OpCvt32Fto64:  sfRtCallDef{sysfunc(\"f32toint64\"), TINT64},\n\t\tssa.OpCvt64Uto32F: sfRtCallDef{sysfunc(\"fuint64to32\"), TFLOAT32},\n\t\tssa.OpCvt32Fto64U: sfRtCallDef{sysfunc(\"f32touint64\"), TUINT64},\n\t\tssa.OpCvt32to64F:  sfRtCallDef{sysfunc(\"fint32to64\"), TFLOAT64},\n\t\tssa.OpCvt64Fto32:  sfRtCallDef{sysfunc(\"f64toint32\"), TINT32},\n\t\tssa.OpCvt64to64F:  sfRtCallDef{sysfunc(\"fint64to64\"), TFLOAT64},\n\t\tssa.OpCvt64Fto64:  sfRtCallDef{sysfunc(\"f64toint64\"), TINT64},\n\t\tssa.OpCvt64Uto64F: sfRtCallDef{sysfunc(\"fuint64to64\"), TFLOAT64},\n\t\tssa.OpCvt64Fto64U: sfRtCallDef{sysfunc(\"f64touint64\"), TUINT64},\n\t\tssa.OpCvt32Fto64F: sfRtCallDef{sysfunc(\"f32to64\"), TFLOAT64},\n\t\tssa.OpCvt64Fto32F: sfRtCallDef{sysfunc(\"f64to32\"), TFLOAT32},\n\t}\n}\n\n// TODO: do not emit sfcall if operation can be optimized to constant in later\n// opt phase\nfunc (s *state) sfcall(op ssa.Op, args ...*ssa.Value) (*ssa.Value, bool) {\n\tif callDef, ok := softFloatOps[op]; ok {\n\t\tswitch op {\n\t\tcase ssa.OpLess32F,\n\t\t\tssa.OpLess64F,\n\t\t\tssa.OpLeq32F,\n\t\t\tssa.OpLeq64F:\n\t\t\targs[0], args[1] = args[1], args[0]\n\t\tcase ssa.OpSub32F,\n\t\t\tssa.OpSub64F:\n\t\t\targs[1] = s.newValue1(s.ssaOp(ONEG, types.Types[callDef.rtype]), args[1].Type, args[1])\n\t\t}\n\n\t\tresult := s.rtcall(callDef.rtfn, true, []*types.Type{types.Types[callDef.rtype]}, args...)[0]\n\t\tif op == ssa.OpNeq32F || op == ssa.OpNeq64F {\n\t\t\tresult = s.newValue1(ssa.OpNot, result.Type, result)\n\t\t}\n\t\treturn result, true\n\t}\n\treturn nil, false\n}\n\nvar intrinsics map[intrinsicKey]intrinsicBuilder\n\n// An intrinsicBuilder converts a call node n into an ssa value that\n// implements that call as an intrinsic. args is a list of arguments to the func.\ntype intrinsicBuilder func(s *state, n *Node, args []*ssa.Value) *ssa.Value\n\ntype intrinsicKey struct {\n\tarch *sys.Arch\n\tpkg  string\n\tfn   string\n}\n\nfunc init() {\n\tintrinsics = map[intrinsicKey]intrinsicBuilder{}\n\n\tvar all []*sys.Arch       // 所有架构\n\tvar p4 []*sys.Arch        // 指针长度为4字节的架构\n\tvar p8 []*sys.Arch        // 指针长度为8字节的架构\n\tvar lwatomics []*sys.Arch // 非PPC64架构\n\tfor _, a := range &sys.Archs {\n\t\tall = append(all, a)\n\t\tif a.PtrSize == 4 {\n\t\t\tp4 = append(p4, a)\n\t\t} else {\n\t\t\tp8 = append(p8, a)\n\t\t}\n\t\tif a.Family != sys.PPC64 {\n\t\t\tlwatomics = append(lwatomics, a)\n\t\t}\n\t}\n\n\t// add adds the intrinsic b for pkg.fn for the given list of architectures.\n\tadd := func(pkg, fn string, b intrinsicBuilder, archs ...*sys.Arch) {\n\t\tfor _, a := range archs {\n\t\t\tintrinsics[intrinsicKey{a, pkg, fn}] = b\n\t\t}\n\t}\n\t// addF does the same as add but operates on architecture families.\n\taddF := func(pkg, fn string, b intrinsicBuilder, archFamilies ...sys.ArchFamily) {\n\t\tm := 0\n\t\tfor _, f := range archFamilies {\n\t\t\tif f >= 32 {\n\t\t\t\tpanic(\"too many architecture families\")\n\t\t\t}\n\t\t\tm |= 1 << uint(f)\n\t\t}\n\t\tfor _, a := range all {\n\t\t\tif m>>uint(a.Family)&1 != 0 {\n\t\t\t\tintrinsics[intrinsicKey{a, pkg, fn}] = b\n\t\t\t}\n\t\t}\n\t}\n\t// alias defines pkg.fn = pkg2.fn2 for all architectures in archs for which pkg2.fn2 exists.\n\talias := func(pkg, fn, pkg2, fn2 string, archs ...*sys.Arch) {\n\t\taliased := false\n\t\tfor _, a := range archs {\n\t\t\tif b, ok := intrinsics[intrinsicKey{a, pkg2, fn2}]; ok {\n\t\t\t\tintrinsics[intrinsicKey{a, pkg, fn}] = b\n\t\t\t\taliased = true\n\t\t\t}\n\t\t}\n\t\tif !aliased {\n\t\t\tpanic(fmt.Sprintf(\"attempted to alias undefined intrinsic: %s.%s\", pkg, fn))\n\t\t}\n\t}\n\n\t/******** runtime ********/\n\tif !instrumenting {\n\t\tadd(\"runtime\", \"slicebytetostringtmp\",\n\t\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\t\t// Compiler frontend optimizations emit OBYTES2STRTMP nodes\n\t\t\t\t// for the backend instead of slicebytetostringtmp calls\n\t\t\t\t// when not instrumenting.\n\t\t\t\treturn s.newValue2(ssa.OpStringMake, n.Type, args[0], args[1])\n\t\t\t},\n\t\t\tall...)\n\t}\n\taddF(\"runtime/internal/math\", \"MulUintptr\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tif s.config.PtrSize == 4 {\n\t\t\t\treturn s.newValue2(ssa.OpMul32uover, types.NewTuple(types.Types[TUINT], types.Types[TUINT]), args[0], args[1])\n\t\t\t}\n\t\t\treturn s.newValue2(ssa.OpMul64uover, types.NewTuple(types.Types[TUINT], types.Types[TUINT]), args[0], args[1])\n\t\t},\n\t\tsys.AMD64, sys.I386, sys.MIPS64)\n\tadd(\"runtime\", \"KeepAlive\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tdata := s.newValue1(ssa.OpIData, s.f.Config.Types.BytePtr, args[0])\n\t\t\ts.vars[&memVar] = s.newValue2(ssa.OpKeepAlive, types.TypeMem, data, s.mem())\n\t\t\treturn nil\n\t\t},\n\t\tall...)\n\tadd(\"runtime\", \"getclosureptr\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue0(ssa.OpGetClosurePtr, s.f.Config.Types.Uintptr)\n\t\t},\n\t\tall...)\n\n\tadd(\"runtime\", \"getcallerpc\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue0(ssa.OpGetCallerPC, s.f.Config.Types.Uintptr)\n\t\t},\n\t\tall...)\n\n\tadd(\"runtime\", \"getcallersp\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue0(ssa.OpGetCallerSP, s.f.Config.Types.Uintptr)\n\t\t},\n\t\tall...)\n\n\t/******** runtime/internal/sys ********/\n\taddF(\"runtime/internal/sys\", \"Ctz32\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpCtz32, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64)\n\taddF(\"runtime/internal/sys\", \"Ctz64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpCtz64, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64)\n\taddF(\"runtime/internal/sys\", \"Bswap32\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBswap32, types.Types[TUINT32], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.ARM, sys.S390X)\n\taddF(\"runtime/internal/sys\", \"Bswap64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBswap64, types.Types[TUINT64], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.ARM, sys.S390X)\n\n\t/******** runtime/internal/atomic ********/\n\taddF(\"runtime/internal/atomic\", \"Load\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue2(ssa.OpAtomicLoad32, types.NewTuple(types.Types[TUINT32], types.TypeMem), args[0], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TUINT32], v)\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Load8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue2(ssa.OpAtomicLoad8, types.NewTuple(types.Types[TUINT8], types.TypeMem), args[0], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TUINT8], v)\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Load64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue2(ssa.OpAtomicLoad64, types.NewTuple(types.Types[TUINT64], types.TypeMem), args[0], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TUINT64], v)\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"LoadAcq\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue2(ssa.OpAtomicLoadAcq32, types.NewTuple(types.Types[TUINT32], types.TypeMem), args[0], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TUINT32], v)\n\t\t},\n\t\tsys.PPC64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Loadp\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue2(ssa.OpAtomicLoadPtr, types.NewTuple(s.f.Config.Types.BytePtr, types.TypeMem), args[0], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, s.f.Config.Types.BytePtr, v)\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\n\taddF(\"runtime/internal/atomic\", \"Store\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\ts.vars[&memVar] = s.newValue3(ssa.OpAtomicStore32, types.TypeMem, args[0], args[1], s.mem())\n\t\t\treturn nil\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Store8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\ts.vars[&memVar] = s.newValue3(ssa.OpAtomicStore8, types.TypeMem, args[0], args[1], s.mem())\n\t\t\treturn nil\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Store64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\ts.vars[&memVar] = s.newValue3(ssa.OpAtomicStore64, types.TypeMem, args[0], args[1], s.mem())\n\t\t\treturn nil\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"StorepNoWB\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\ts.vars[&memVar] = s.newValue3(ssa.OpAtomicStorePtrNoWB, types.TypeMem, args[0], args[1], s.mem())\n\t\t\treturn nil\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.MIPS64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"StoreRel\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\ts.vars[&memVar] = s.newValue3(ssa.OpAtomicStoreRel32, types.TypeMem, args[0], args[1], s.mem())\n\t\t\treturn nil\n\t\t},\n\t\tsys.PPC64, sys.S390X)\n\n\taddF(\"runtime/internal/atomic\", \"Xchg\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue3(ssa.OpAtomicExchange32, types.NewTuple(types.Types[TUINT32], types.TypeMem), args[0], args[1], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TUINT32], v)\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Xchg64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue3(ssa.OpAtomicExchange64, types.NewTuple(types.Types[TUINT64], types.TypeMem), args[0], args[1], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TUINT64], v)\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\n\taddF(\"runtime/internal/atomic\", \"Xadd\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue3(ssa.OpAtomicAdd32, types.NewTuple(types.Types[TUINT32], types.TypeMem), args[0], args[1], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TUINT32], v)\n\t\t},\n\t\tsys.AMD64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Xadd64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue3(ssa.OpAtomicAdd64, types.NewTuple(types.Types[TUINT64], types.TypeMem), args[0], args[1], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TUINT64], v)\n\t\t},\n\t\tsys.AMD64, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\n\tmakeXaddARM64 := func(op0 ssa.Op, op1 ssa.Op, ty types.EType) func(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\treturn func(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\t// Target Atomic feature is identified by dynamic detection\n\t\t\taddr := s.entryNewValue1A(ssa.OpAddr, types.Types[TBOOL].PtrTo(), arm64HasATOMICS, s.sb)\n\t\t\tv := s.load(types.Types[TBOOL], addr)\n\t\t\tb := s.endBlock()\n\t\t\tb.Kind = ssa.BlockIf\n\t\t\tb.SetControl(v)\n\t\t\tbTrue := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbFalse := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tb.AddEdgeTo(bTrue)\n\t\t\tb.AddEdgeTo(bFalse)\n\t\t\tb.Likely = ssa.BranchUnlikely // most machines don't have Atomics nowadays\n\n\t\t\t// We have atomic instructions - use it directly.\n\t\t\ts.startBlock(bTrue)\n\t\t\tv0 := s.newValue3(op1, types.NewTuple(types.Types[ty], types.TypeMem), args[0], args[1], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v0)\n\t\t\ts.vars[n] = s.newValue1(ssa.OpSelect0, types.Types[ty], v0)\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Use original instruction sequence.\n\t\t\ts.startBlock(bFalse)\n\t\t\tv1 := s.newValue3(op0, types.NewTuple(types.Types[ty], types.TypeMem), args[0], args[1], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v1)\n\t\t\ts.vars[n] = s.newValue1(ssa.OpSelect0, types.Types[ty], v1)\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Merge results.\n\t\t\ts.startBlock(bEnd)\n\t\t\treturn s.variable(n, types.Types[ty])\n\t\t}\n\t}\n\n\taddF(\"runtime/internal/atomic\", \"Xadd\",\n\t\tmakeXaddARM64(ssa.OpAtomicAdd32, ssa.OpAtomicAdd32Variant, TUINT32),\n\t\tsys.ARM64)\n\taddF(\"runtime/internal/atomic\", \"Xadd64\",\n\t\tmakeXaddARM64(ssa.OpAtomicAdd64, ssa.OpAtomicAdd64Variant, TUINT64),\n\t\tsys.ARM64)\n\n\taddF(\"runtime/internal/atomic\", \"Cas\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue4(ssa.OpAtomicCompareAndSwap32, types.NewTuple(types.Types[TBOOL], types.TypeMem), args[0], args[1], args[2], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TBOOL], v)\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Cas64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue4(ssa.OpAtomicCompareAndSwap64, types.NewTuple(types.Types[TBOOL], types.TypeMem), args[0], args[1], args[2], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TBOOL], v)\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"CasRel\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.newValue4(ssa.OpAtomicCompareAndSwap32, types.NewTuple(types.Types[TBOOL], types.TypeMem), args[0], args[1], args[2], s.mem())\n\t\t\ts.vars[&memVar] = s.newValue1(ssa.OpSelect1, types.TypeMem, v)\n\t\t\treturn s.newValue1(ssa.OpSelect0, types.Types[TBOOL], v)\n\t\t},\n\t\tsys.PPC64)\n\n\taddF(\"runtime/internal/atomic\", \"And8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\ts.vars[&memVar] = s.newValue3(ssa.OpAtomicAnd8, types.TypeMem, args[0], args[1], s.mem())\n\t\t\treturn nil\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.PPC64, sys.S390X)\n\taddF(\"runtime/internal/atomic\", \"Or8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\ts.vars[&memVar] = s.newValue3(ssa.OpAtomicOr8, types.TypeMem, args[0], args[1], s.mem())\n\t\t\treturn nil\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.MIPS, sys.PPC64, sys.S390X)\n\n\talias(\"runtime/internal/atomic\", \"Loadint64\", \"runtime/internal/atomic\", \"Load64\", all...)\n\talias(\"runtime/internal/atomic\", \"Xaddint64\", \"runtime/internal/atomic\", \"Xadd64\", all...)\n\talias(\"runtime/internal/atomic\", \"Loaduint\", \"runtime/internal/atomic\", \"Load\", p4...)\n\talias(\"runtime/internal/atomic\", \"Loaduint\", \"runtime/internal/atomic\", \"Load64\", p8...)\n\talias(\"runtime/internal/atomic\", \"Loaduintptr\", \"runtime/internal/atomic\", \"Load\", p4...)\n\talias(\"runtime/internal/atomic\", \"Loaduintptr\", \"runtime/internal/atomic\", \"Load64\", p8...)\n\talias(\"runtime/internal/atomic\", \"LoadAcq\", \"runtime/internal/atomic\", \"Load\", lwatomics...)\n\talias(\"runtime/internal/atomic\", \"Storeuintptr\", \"runtime/internal/atomic\", \"Store\", p4...)\n\talias(\"runtime/internal/atomic\", \"Storeuintptr\", \"runtime/internal/atomic\", \"Store64\", p8...)\n\talias(\"runtime/internal/atomic\", \"StoreRel\", \"runtime/internal/atomic\", \"Store\", lwatomics...)\n\talias(\"runtime/internal/atomic\", \"Xchguintptr\", \"runtime/internal/atomic\", \"Xchg\", p4...)\n\talias(\"runtime/internal/atomic\", \"Xchguintptr\", \"runtime/internal/atomic\", \"Xchg64\", p8...)\n\talias(\"runtime/internal/atomic\", \"Xadduintptr\", \"runtime/internal/atomic\", \"Xadd\", p4...)\n\talias(\"runtime/internal/atomic\", \"Xadduintptr\", \"runtime/internal/atomic\", \"Xadd64\", p8...)\n\talias(\"runtime/internal/atomic\", \"Casuintptr\", \"runtime/internal/atomic\", \"Cas\", p4...)\n\talias(\"runtime/internal/atomic\", \"Casuintptr\", \"runtime/internal/atomic\", \"Cas64\", p8...)\n\talias(\"runtime/internal/atomic\", \"Casp1\", \"runtime/internal/atomic\", \"Cas\", p4...)\n\talias(\"runtime/internal/atomic\", \"Casp1\", \"runtime/internal/atomic\", \"Cas64\", p8...)\n\talias(\"runtime/internal/atomic\", \"CasRel\", \"runtime/internal/atomic\", \"Cas\", lwatomics...)\n\n\t/******** math ********/\n\taddF(\"math\", \"Sqrt\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpSqrt, types.Types[TFLOAT64], args[0])\n\t\t},\n\t\tsys.I386, sys.AMD64, sys.ARM, sys.ARM64, sys.MIPS, sys.MIPS64, sys.PPC64, sys.RISCV64, sys.S390X, sys.Wasm)\n\taddF(\"math\", \"Trunc\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpTrunc, types.Types[TFLOAT64], args[0])\n\t\t},\n\t\tsys.ARM64, sys.PPC64, sys.S390X, sys.Wasm)\n\taddF(\"math\", \"Ceil\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpCeil, types.Types[TFLOAT64], args[0])\n\t\t},\n\t\tsys.ARM64, sys.PPC64, sys.S390X, sys.Wasm)\n\taddF(\"math\", \"Floor\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpFloor, types.Types[TFLOAT64], args[0])\n\t\t},\n\t\tsys.ARM64, sys.PPC64, sys.S390X, sys.Wasm)\n\taddF(\"math\", \"Round\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpRound, types.Types[TFLOAT64], args[0])\n\t\t},\n\t\tsys.ARM64, sys.PPC64, sys.S390X)\n\taddF(\"math\", \"RoundToEven\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpRoundToEven, types.Types[TFLOAT64], args[0])\n\t\t},\n\t\tsys.ARM64, sys.S390X, sys.Wasm)\n\taddF(\"math\", \"Abs\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpAbs, types.Types[TFLOAT64], args[0])\n\t\t},\n\t\tsys.ARM64, sys.ARM, sys.PPC64, sys.Wasm)\n\taddF(\"math\", \"Copysign\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue2(ssa.OpCopysign, types.Types[TFLOAT64], args[0], args[1])\n\t\t},\n\t\tsys.PPC64, sys.Wasm)\n\taddF(\"math\", \"FMA\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue3(ssa.OpFMA, types.Types[TFLOAT64], args[0], args[1], args[2])\n\t\t},\n\t\tsys.ARM64, sys.PPC64, sys.S390X)\n\taddF(\"math\", \"FMA\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tif !s.config.UseFMA {\n\t\t\t\ta := s.call(n, callNormal)\n\t\t\t\ts.vars[n] = s.load(types.Types[TFLOAT64], a)\n\t\t\t\treturn s.variable(n, types.Types[TFLOAT64])\n\t\t\t}\n\t\t\tv := s.entryNewValue0A(ssa.OpHasCPUFeature, types.Types[TBOOL], x86HasFMA)\n\t\t\tb := s.endBlock()\n\t\t\tb.Kind = ssa.BlockIf\n\t\t\tb.SetControl(v)\n\t\t\tbTrue := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbFalse := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tb.AddEdgeTo(bTrue)\n\t\t\tb.AddEdgeTo(bFalse)\n\t\t\tb.Likely = ssa.BranchLikely // >= haswell cpus are common\n\n\t\t\t// We have the intrinsic - use it directly.\n\t\t\ts.startBlock(bTrue)\n\t\t\ts.vars[n] = s.newValue3(ssa.OpFMA, types.Types[TFLOAT64], args[0], args[1], args[2])\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Call the pure Go version.\n\t\t\ts.startBlock(bFalse)\n\t\t\ta := s.call(n, callNormal)\n\t\t\ts.vars[n] = s.load(types.Types[TFLOAT64], a)\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Merge results.\n\t\t\ts.startBlock(bEnd)\n\t\t\treturn s.variable(n, types.Types[TFLOAT64])\n\t\t},\n\t\tsys.AMD64)\n\taddF(\"math\", \"FMA\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tif !s.config.UseFMA {\n\t\t\t\ta := s.call(n, callNormal)\n\t\t\t\ts.vars[n] = s.load(types.Types[TFLOAT64], a)\n\t\t\t\treturn s.variable(n, types.Types[TFLOAT64])\n\t\t\t}\n\t\t\taddr := s.entryNewValue1A(ssa.OpAddr, types.Types[TBOOL].PtrTo(), armHasVFPv4, s.sb)\n\t\t\tv := s.load(types.Types[TBOOL], addr)\n\t\t\tb := s.endBlock()\n\t\t\tb.Kind = ssa.BlockIf\n\t\t\tb.SetControl(v)\n\t\t\tbTrue := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbFalse := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tb.AddEdgeTo(bTrue)\n\t\t\tb.AddEdgeTo(bFalse)\n\t\t\tb.Likely = ssa.BranchLikely\n\n\t\t\t// We have the intrinsic - use it directly.\n\t\t\ts.startBlock(bTrue)\n\t\t\ts.vars[n] = s.newValue3(ssa.OpFMA, types.Types[TFLOAT64], args[0], args[1], args[2])\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Call the pure Go version.\n\t\t\ts.startBlock(bFalse)\n\t\t\ta := s.call(n, callNormal)\n\t\t\ts.vars[n] = s.load(types.Types[TFLOAT64], a)\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Merge results.\n\t\t\ts.startBlock(bEnd)\n\t\t\treturn s.variable(n, types.Types[TFLOAT64])\n\t\t},\n\t\tsys.ARM)\n\n\tmakeRoundAMD64 := func(op ssa.Op) func(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\treturn func(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.entryNewValue0A(ssa.OpHasCPUFeature, types.Types[TBOOL], x86HasSSE41)\n\t\t\tb := s.endBlock()\n\t\t\tb.Kind = ssa.BlockIf\n\t\t\tb.SetControl(v)\n\t\t\tbTrue := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbFalse := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tb.AddEdgeTo(bTrue)\n\t\t\tb.AddEdgeTo(bFalse)\n\t\t\tb.Likely = ssa.BranchLikely // most machines have sse4.1 nowadays\n\n\t\t\t// We have the intrinsic - use it directly.\n\t\t\ts.startBlock(bTrue)\n\t\t\ts.vars[n] = s.newValue1(op, types.Types[TFLOAT64], args[0])\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Call the pure Go version.\n\t\t\ts.startBlock(bFalse)\n\t\t\ta := s.call(n, callNormal)\n\t\t\ts.vars[n] = s.load(types.Types[TFLOAT64], a)\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Merge results.\n\t\t\ts.startBlock(bEnd)\n\t\t\treturn s.variable(n, types.Types[TFLOAT64])\n\t\t}\n\t}\n\taddF(\"math\", \"RoundToEven\",\n\t\tmakeRoundAMD64(ssa.OpRoundToEven),\n\t\tsys.AMD64)\n\taddF(\"math\", \"Floor\",\n\t\tmakeRoundAMD64(ssa.OpFloor),\n\t\tsys.AMD64)\n\taddF(\"math\", \"Ceil\",\n\t\tmakeRoundAMD64(ssa.OpCeil),\n\t\tsys.AMD64)\n\taddF(\"math\", \"Trunc\",\n\t\tmakeRoundAMD64(ssa.OpTrunc),\n\t\tsys.AMD64)\n\n\t/******** math/bits ********/\n\taddF(\"math/bits\", \"TrailingZeros64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpCtz64, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"TrailingZeros32\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpCtz32, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"TrailingZeros16\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tx := s.newValue1(ssa.OpZeroExt16to32, types.Types[TUINT32], args[0])\n\t\t\tc := s.constInt32(types.Types[TUINT32], 1<<16)\n\t\t\ty := s.newValue2(ssa.OpOr32, types.Types[TUINT32], x, c)\n\t\t\treturn s.newValue1(ssa.OpCtz32, types.Types[TINT], y)\n\t\t},\n\t\tsys.MIPS)\n\taddF(\"math/bits\", \"TrailingZeros16\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpCtz16, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.I386, sys.ARM, sys.ARM64, sys.Wasm)\n\taddF(\"math/bits\", \"TrailingZeros16\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tx := s.newValue1(ssa.OpZeroExt16to64, types.Types[TUINT64], args[0])\n\t\t\tc := s.constInt64(types.Types[TUINT64], 1<<16)\n\t\t\ty := s.newValue2(ssa.OpOr64, types.Types[TUINT64], x, c)\n\t\t\treturn s.newValue1(ssa.OpCtz64, types.Types[TINT], y)\n\t\t},\n\t\tsys.S390X, sys.PPC64)\n\taddF(\"math/bits\", \"TrailingZeros8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tx := s.newValue1(ssa.OpZeroExt8to32, types.Types[TUINT32], args[0])\n\t\t\tc := s.constInt32(types.Types[TUINT32], 1<<8)\n\t\t\ty := s.newValue2(ssa.OpOr32, types.Types[TUINT32], x, c)\n\t\t\treturn s.newValue1(ssa.OpCtz32, types.Types[TINT], y)\n\t\t},\n\t\tsys.MIPS)\n\taddF(\"math/bits\", \"TrailingZeros8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpCtz8, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM, sys.ARM64, sys.Wasm)\n\taddF(\"math/bits\", \"TrailingZeros8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tx := s.newValue1(ssa.OpZeroExt8to64, types.Types[TUINT64], args[0])\n\t\t\tc := s.constInt64(types.Types[TUINT64], 1<<8)\n\t\t\ty := s.newValue2(ssa.OpOr64, types.Types[TUINT64], x, c)\n\t\t\treturn s.newValue1(ssa.OpCtz64, types.Types[TINT], y)\n\t\t},\n\t\tsys.S390X)\n\talias(\"math/bits\", \"ReverseBytes64\", \"runtime/internal/sys\", \"Bswap64\", all...)\n\talias(\"math/bits\", \"ReverseBytes32\", \"runtime/internal/sys\", \"Bswap32\", all...)\n\t// ReverseBytes inlines correctly, no need to intrinsify it.\n\t// ReverseBytes16 lowers to a rotate, no need for anything special here.\n\taddF(\"math/bits\", \"Len64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBitLen64, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"Len32\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBitLen32, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64)\n\taddF(\"math/bits\", \"Len32\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tif s.config.PtrSize == 4 {\n\t\t\t\treturn s.newValue1(ssa.OpBitLen32, types.Types[TINT], args[0])\n\t\t\t}\n\t\t\tx := s.newValue1(ssa.OpZeroExt32to64, types.Types[TUINT64], args[0])\n\t\t\treturn s.newValue1(ssa.OpBitLen64, types.Types[TINT], x)\n\t\t},\n\t\tsys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"Len16\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tif s.config.PtrSize == 4 {\n\t\t\t\tx := s.newValue1(ssa.OpZeroExt16to32, types.Types[TUINT32], args[0])\n\t\t\t\treturn s.newValue1(ssa.OpBitLen32, types.Types[TINT], x)\n\t\t\t}\n\t\t\tx := s.newValue1(ssa.OpZeroExt16to64, types.Types[TUINT64], args[0])\n\t\t\treturn s.newValue1(ssa.OpBitLen64, types.Types[TINT], x)\n\t\t},\n\t\tsys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"Len16\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBitLen16, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64)\n\taddF(\"math/bits\", \"Len8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tif s.config.PtrSize == 4 {\n\t\t\t\tx := s.newValue1(ssa.OpZeroExt8to32, types.Types[TUINT32], args[0])\n\t\t\t\treturn s.newValue1(ssa.OpBitLen32, types.Types[TINT], x)\n\t\t\t}\n\t\t\tx := s.newValue1(ssa.OpZeroExt8to64, types.Types[TUINT64], args[0])\n\t\t\treturn s.newValue1(ssa.OpBitLen64, types.Types[TINT], x)\n\t\t},\n\t\tsys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"Len8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBitLen8, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64)\n\taddF(\"math/bits\", \"Len\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tif s.config.PtrSize == 4 {\n\t\t\t\treturn s.newValue1(ssa.OpBitLen32, types.Types[TINT], args[0])\n\t\t\t}\n\t\t\treturn s.newValue1(ssa.OpBitLen64, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)\n\t// LeadingZeros is handled because it trivially calls Len.\n\taddF(\"math/bits\", \"Reverse64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBitRev64, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.ARM64)\n\taddF(\"math/bits\", \"Reverse32\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBitRev32, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.ARM64)\n\taddF(\"math/bits\", \"Reverse16\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBitRev16, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.ARM64)\n\taddF(\"math/bits\", \"Reverse8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpBitRev8, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.ARM64)\n\taddF(\"math/bits\", \"Reverse\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tif s.config.PtrSize == 4 {\n\t\t\t\treturn s.newValue1(ssa.OpBitRev32, types.Types[TINT], args[0])\n\t\t\t}\n\t\t\treturn s.newValue1(ssa.OpBitRev64, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.ARM64)\n\taddF(\"math/bits\", \"RotateLeft8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue2(ssa.OpRotateLeft8, types.Types[TUINT8], args[0], args[1])\n\t\t},\n\t\tsys.AMD64)\n\taddF(\"math/bits\", \"RotateLeft16\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue2(ssa.OpRotateLeft16, types.Types[TUINT16], args[0], args[1])\n\t\t},\n\t\tsys.AMD64)\n\taddF(\"math/bits\", \"RotateLeft32\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue2(ssa.OpRotateLeft32, types.Types[TUINT32], args[0], args[1])\n\t\t},\n\t\tsys.AMD64, sys.ARM, sys.ARM64, sys.S390X, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"RotateLeft64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue2(ssa.OpRotateLeft64, types.Types[TUINT64], args[0], args[1])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.S390X, sys.PPC64, sys.Wasm)\n\talias(\"math/bits\", \"RotateLeft\", \"math/bits\", \"RotateLeft64\", p8...)\n\n\tmakeOnesCountAMD64 := func(op64 ssa.Op, op32 ssa.Op) func(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\treturn func(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\tv := s.entryNewValue0A(ssa.OpHasCPUFeature, types.Types[TBOOL], x86HasPOPCNT)\n\t\t\tb := s.endBlock()\n\t\t\tb.Kind = ssa.BlockIf\n\t\t\tb.SetControl(v)\n\t\t\tbTrue := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbFalse := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tb.AddEdgeTo(bTrue)\n\t\t\tb.AddEdgeTo(bFalse)\n\t\t\tb.Likely = ssa.BranchLikely // most machines have popcnt nowadays\n\n\t\t\t// We have the intrinsic - use it directly.\n\t\t\ts.startBlock(bTrue)\n\t\t\top := op64\n\t\t\tif s.config.PtrSize == 4 {\n\t\t\t\top = op32\n\t\t\t}\n\t\t\ts.vars[n] = s.newValue1(op, types.Types[TINT], args[0])\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Call the pure Go version.\n\t\t\ts.startBlock(bFalse)\n\t\t\ta := s.call(n, callNormal)\n\t\t\ts.vars[n] = s.load(types.Types[TINT], a)\n\t\t\ts.endBlock().AddEdgeTo(bEnd)\n\n\t\t\t// Merge results.\n\t\t\ts.startBlock(bEnd)\n\t\t\treturn s.variable(n, types.Types[TINT])\n\t\t}\n\t}\n\taddF(\"math/bits\", \"OnesCount64\",\n\t\tmakeOnesCountAMD64(ssa.OpPopCount64, ssa.OpPopCount64),\n\t\tsys.AMD64)\n\taddF(\"math/bits\", \"OnesCount64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpPopCount64, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.PPC64, sys.ARM64, sys.S390X, sys.Wasm)\n\taddF(\"math/bits\", \"OnesCount32\",\n\t\tmakeOnesCountAMD64(ssa.OpPopCount32, ssa.OpPopCount32),\n\t\tsys.AMD64)\n\taddF(\"math/bits\", \"OnesCount32\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpPopCount32, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.PPC64, sys.ARM64, sys.S390X, sys.Wasm)\n\taddF(\"math/bits\", \"OnesCount16\",\n\t\tmakeOnesCountAMD64(ssa.OpPopCount16, ssa.OpPopCount16),\n\t\tsys.AMD64)\n\taddF(\"math/bits\", \"OnesCount16\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpPopCount16, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.ARM64, sys.S390X, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"OnesCount8\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue1(ssa.OpPopCount8, types.Types[TINT], args[0])\n\t\t},\n\t\tsys.S390X, sys.PPC64, sys.Wasm)\n\taddF(\"math/bits\", \"OnesCount\",\n\t\tmakeOnesCountAMD64(ssa.OpPopCount64, ssa.OpPopCount32),\n\t\tsys.AMD64)\n\taddF(\"math/bits\", \"Mul64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue2(ssa.OpMul64uhilo, types.NewTuple(types.Types[TUINT64], types.Types[TUINT64]), args[0], args[1])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.PPC64, sys.S390X, sys.MIPS64)\n\talias(\"math/bits\", \"Mul\", \"math/bits\", \"Mul64\", sys.ArchAMD64, sys.ArchARM64, sys.ArchPPC64, sys.ArchS390X, sys.ArchMIPS64, sys.ArchMIPS64LE)\n\taddF(\"math/bits\", \"Add64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue3(ssa.OpAdd64carry, types.NewTuple(types.Types[TUINT64], types.Types[TUINT64]), args[0], args[1], args[2])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.PPC64, sys.S390X)\n\talias(\"math/bits\", \"Add\", \"math/bits\", \"Add64\", sys.ArchAMD64, sys.ArchARM64, sys.ArchPPC64, sys.ArchS390X)\n\taddF(\"math/bits\", \"Sub64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue3(ssa.OpSub64borrow, types.NewTuple(types.Types[TUINT64], types.Types[TUINT64]), args[0], args[1], args[2])\n\t\t},\n\t\tsys.AMD64, sys.ARM64, sys.S390X)\n\talias(\"math/bits\", \"Sub\", \"math/bits\", \"Sub64\", sys.ArchAMD64, sys.ArchARM64, sys.ArchS390X)\n\taddF(\"math/bits\", \"Div64\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\t// check for divide-by-zero/overflow and panic with appropriate message\n\t\t\tcmpZero := s.newValue2(s.ssaOp(ONE, types.Types[TUINT64]), types.Types[TBOOL], args[2], s.zeroVal(types.Types[TUINT64]))\n\t\t\ts.check(cmpZero, panicdivide)\n\t\t\tcmpOverflow := s.newValue2(s.ssaOp(OLT, types.Types[TUINT64]), types.Types[TBOOL], args[0], args[2])\n\t\t\ts.check(cmpOverflow, panicoverflow)\n\t\t\treturn s.newValue3(ssa.OpDiv128u, types.NewTuple(types.Types[TUINT64], types.Types[TUINT64]), args[0], args[1], args[2])\n\t\t},\n\t\tsys.AMD64)\n\talias(\"math/bits\", \"Div\", \"math/bits\", \"Div64\", sys.ArchAMD64)\n\n\talias(\"runtime/internal/sys\", \"Ctz8\", \"math/bits\", \"TrailingZeros8\", all...)\n\talias(\"runtime/internal/sys\", \"TrailingZeros8\", \"math/bits\", \"TrailingZeros8\", all...)\n\talias(\"runtime/internal/sys\", \"TrailingZeros64\", \"math/bits\", \"TrailingZeros64\", all...)\n\talias(\"runtime/internal/sys\", \"Len8\", \"math/bits\", \"Len8\", all...)\n\talias(\"runtime/internal/sys\", \"Len64\", \"math/bits\", \"Len64\", all...)\n\talias(\"runtime/internal/sys\", \"OnesCount64\", \"math/bits\", \"OnesCount64\", all...)\n\n\t/******** sync/atomic ********/\n\n\t// Note: these are disabled by flag_race in findIntrinsic below.\n\talias(\"sync/atomic\", \"LoadInt32\", \"runtime/internal/atomic\", \"Load\", all...)\n\talias(\"sync/atomic\", \"LoadInt64\", \"runtime/internal/atomic\", \"Load64\", all...)\n\talias(\"sync/atomic\", \"LoadPointer\", \"runtime/internal/atomic\", \"Loadp\", all...)\n\talias(\"sync/atomic\", \"LoadUint32\", \"runtime/internal/atomic\", \"Load\", all...)\n\talias(\"sync/atomic\", \"LoadUint64\", \"runtime/internal/atomic\", \"Load64\", all...)\n\talias(\"sync/atomic\", \"LoadUintptr\", \"runtime/internal/atomic\", \"Load\", p4...)\n\talias(\"sync/atomic\", \"LoadUintptr\", \"runtime/internal/atomic\", \"Load64\", p8...)\n\n\talias(\"sync/atomic\", \"StoreInt32\", \"runtime/internal/atomic\", \"Store\", all...)\n\talias(\"sync/atomic\", \"StoreInt64\", \"runtime/internal/atomic\", \"Store64\", all...)\n\t// Note: not StorePointer, that needs a write barrier.  Same below for {CompareAnd}Swap.\n\talias(\"sync/atomic\", \"StoreUint32\", \"runtime/internal/atomic\", \"Store\", all...)\n\talias(\"sync/atomic\", \"StoreUint64\", \"runtime/internal/atomic\", \"Store64\", all...)\n\talias(\"sync/atomic\", \"StoreUintptr\", \"runtime/internal/atomic\", \"Store\", p4...)\n\talias(\"sync/atomic\", \"StoreUintptr\", \"runtime/internal/atomic\", \"Store64\", p8...)\n\n\talias(\"sync/atomic\", \"SwapInt32\", \"runtime/internal/atomic\", \"Xchg\", all...)\n\talias(\"sync/atomic\", \"SwapInt64\", \"runtime/internal/atomic\", \"Xchg64\", all...)\n\talias(\"sync/atomic\", \"SwapUint32\", \"runtime/internal/atomic\", \"Xchg\", all...)\n\talias(\"sync/atomic\", \"SwapUint64\", \"runtime/internal/atomic\", \"Xchg64\", all...)\n\talias(\"sync/atomic\", \"SwapUintptr\", \"runtime/internal/atomic\", \"Xchg\", p4...)\n\talias(\"sync/atomic\", \"SwapUintptr\", \"runtime/internal/atomic\", \"Xchg64\", p8...)\n\n\talias(\"sync/atomic\", \"CompareAndSwapInt32\", \"runtime/internal/atomic\", \"Cas\", all...)\n\talias(\"sync/atomic\", \"CompareAndSwapInt64\", \"runtime/internal/atomic\", \"Cas64\", all...)\n\talias(\"sync/atomic\", \"CompareAndSwapUint32\", \"runtime/internal/atomic\", \"Cas\", all...)\n\talias(\"sync/atomic\", \"CompareAndSwapUint64\", \"runtime/internal/atomic\", \"Cas64\", all...)\n\talias(\"sync/atomic\", \"CompareAndSwapUintptr\", \"runtime/internal/atomic\", \"Cas\", p4...)\n\talias(\"sync/atomic\", \"CompareAndSwapUintptr\", \"runtime/internal/atomic\", \"Cas64\", p8...)\n\n\talias(\"sync/atomic\", \"AddInt32\", \"runtime/internal/atomic\", \"Xadd\", all...)\n\talias(\"sync/atomic\", \"AddInt64\", \"runtime/internal/atomic\", \"Xadd64\", all...)\n\talias(\"sync/atomic\", \"AddUint32\", \"runtime/internal/atomic\", \"Xadd\", all...)\n\talias(\"sync/atomic\", \"AddUint64\", \"runtime/internal/atomic\", \"Xadd64\", all...)\n\talias(\"sync/atomic\", \"AddUintptr\", \"runtime/internal/atomic\", \"Xadd\", p4...)\n\talias(\"sync/atomic\", \"AddUintptr\", \"runtime/internal/atomic\", \"Xadd64\", p8...)\n\n\t/******** math/big ********/\n\tadd(\"math/big\", \"mulWW\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue2(ssa.OpMul64uhilo, types.NewTuple(types.Types[TUINT64], types.Types[TUINT64]), args[0], args[1])\n\t\t},\n\t\tsys.ArchAMD64, sys.ArchARM64, sys.ArchPPC64LE, sys.ArchPPC64, sys.ArchS390X)\n\tadd(\"math/big\", \"divWW\",\n\t\tfunc(s *state, n *Node, args []*ssa.Value) *ssa.Value {\n\t\t\treturn s.newValue3(ssa.OpDiv128u, types.NewTuple(types.Types[TUINT64], types.Types[TUINT64]), args[0], args[1], args[2])\n\t\t},\n\t\tsys.ArchAMD64)\n}\n\n// findIntrinsic returns a function which builds the SSA equivalent of the\n// function identified by the symbol sym.  If sym is not an intrinsic call, returns nil.\nfunc findIntrinsic(sym *types.Sym) intrinsicBuilder {\n\tif sym == nil || sym.Pkg == nil {\n\t\treturn nil\n\t}\n\tpkg := sym.Pkg.Path // string literal used in import statement, e.g. \"runtime/internal/sys\"\n\tif sym.Pkg == localpkg {\n\t\tpkg = myimportpath\n\t}\n\tif flag_race && pkg == \"sync/atomic\" {\n\t\t// The race detector needs to be able to intercept these calls.\n\t\t// We can't intrinsify them.\n\t\treturn nil\n\t}\n\t// Skip intrinsifying math functions (which may contain hard-float\n\t// instructions) when soft-float\n\tif thearch.SoftFloat && pkg == \"math\" {\n\t\treturn nil\n\t}\n\n\tfn := sym.Name // 符号的字面量\n\tif ssa.IntrinsicsDisable {\n\t\tif pkg == \"runtime\" && (fn == \"getcallerpc\" || fn == \"getcallersp\" || fn == \"getclosureptr\") {\n\t\t\t// These runtime functions don't have definitions, must be intrinsics.\n\t\t} else {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn intrinsics[intrinsicKey{thearch.LinkArch.Arch, pkg, fn}]\n}\n\nfunc isIntrinsicCall(n *Node) bool {\n\tif n == nil || n.Left == nil {\n\t\treturn false\n\t}\n\treturn findIntrinsic(n.Left.Sym) != nil\n}\n\n// intrinsicCall converts a call to a recognized intrinsic function into the intrinsic SSA operation.\nfunc (s *state) intrinsicCall(n *Node) *ssa.Value {\n\tv := findIntrinsic(n.Left.Sym)(s, n, s.intrinsicArgs(n))\n\tif ssa.IntrinsicsDebug > 0 {\n\t\tx := v\n\t\tif x == nil {\n\t\t\tx = s.mem()\n\t\t}\n\t\tif x.Op == ssa.OpSelect0 || x.Op == ssa.OpSelect1 {\n\t\t\tx = x.Args[0]\n\t\t}\n\t\tWarnl(n.Pos, \"intrinsic substitution for %v with %s\", n.Left.Sym.Name, x.LongString())\n\t}\n\treturn v\n}\n\n// intrinsicArgs extracts args from n, evaluates them to SSA values, and returns them.\nfunc (s *state) intrinsicArgs(n *Node) []*ssa.Value {\n\t// Construct map of temps; see comments in s.call about the structure of n.\n\ttemps := map[*Node]*ssa.Value{}    // 存储函数的所有参数\n\tfor _, a := range n.List.Slice() { // 遍历函数的参数列表\n\t\tif a.Op != OAS {\n\t\t\ts.Fatalf(\"non-assignment as a temp function argument %v\", a.Op)\n\t\t}\n\t\tl, r := a.Left, a.Right\n\t\tif l.Op != ONAME {\n\t\t\ts.Fatalf(\"non-ONAME temp function argument %v\", a.Op)\n\t\t}\n\t\t// Evaluate and store to \"temporary\".\n\t\t// Walk ensures these temporaries are dead outside of n.\n\t\ttemps[l] = s.expr(r)\n\t}\n\targs := make([]*ssa.Value, n.Rlist.Len())\n\tfor i, n := range n.Rlist.Slice() {\n\t\t// Store a value to an argument slot.\n\t\tif x, ok := temps[n]; ok {\n\t\t\t// This is a previously computed temporary.\n\t\t\targs[i] = x\n\t\t\tcontinue\n\t\t}\n\t\t// This is an explicit value; evaluate it.\n\t\targs[i] = s.expr(n)\n\t}\n\treturn args\n}\n\n// openDeferRecord adds code to evaluate and store the args for an open-code defer\n// call, and records info about the defer, so we can generate proper code on the\n// exit paths. n is the sub-node of the defer node that is the actual function\n// call. We will also record funcdata information on where the args are stored\n// (as well as the deferBits variable), and this will enable us to run the proper\n// defer calls during panics.\nfunc (s *state) openDeferRecord(n *Node) {\n\t// Do any needed expression evaluation for the args (including the\n\t// receiver, if any). This may be evaluating something like 'autotmp_3 =\n\t// once.mutex'. Such a statement will create a mapping in s.vars[] from\n\t// the autotmp name to the evaluated SSA arg value, but won't do any\n\t// stores to the stack.\n\ts.stmtList(n.List)\n\n\tvar args []*ssa.Value\n\tvar argNodes []*Node\n\n\topendefer := &openDeferInfo{\n\t\tn: n,\n\t}\n\tfn := n.Left // 获取函数节点\n\tif n.Op == OCALLFUNC {\n\t\t// We must always store the function value in a stack slot for the\n\t\t// runtime panic code to use. But in the defer exit code, we will\n\t\t// call the function directly if it is a static function.\n\t\tclosureVal := s.expr(fn)\n\t\tclosure := s.openDeferSave(nil, fn.Type, closureVal)\n\t\topendefer.closureNode = closure.Aux.(*Node)\n\t\tif !(fn.Op == ONAME && fn.Class() == PFUNC) {\n\t\t\topendefer.closure = closure\n\t\t}\n\t} else if n.Op == OCALLMETH {\n\t\tif fn.Op != ODOTMETH {\n\t\t\tFatalf(\"OCALLMETH: n.Left not an ODOTMETH: %v\", fn)\n\t\t}\n\t\tclosureVal := s.getMethodClosure(fn)\n\t\t// We must always store the function value in a stack slot for the\n\t\t// runtime panic code to use. But in the defer exit code, we will\n\t\t// call the method directly.\n\t\tclosure := s.openDeferSave(nil, fn.Type, closureVal)\n\t\topendefer.closureNode = closure.Aux.(*Node)\n\t} else {\n\t\tif fn.Op != ODOTINTER {\n\t\t\tFatalf(\"OCALLINTER: n.Left not an ODOTINTER: %v\", fn.Op)\n\t\t}\n\t\tclosure, rcvr := s.getClosureAndRcvr(fn)\n\t\topendefer.closure = s.openDeferSave(nil, closure.Type, closure)\n\t\t// Important to get the receiver type correct, so it is recognized\n\t\t// as a pointer for GC purposes.\n\t\topendefer.rcvr = s.openDeferSave(nil, fn.Type.Recv().Type, rcvr)\n\t\topendefer.closureNode = opendefer.closure.Aux.(*Node)\n\t\topendefer.rcvrNode = opendefer.rcvr.Aux.(*Node)\n\t}\n\tfor _, argn := range n.Rlist.Slice() {\n\t\tvar v *ssa.Value\n\t\tif canSSAType(argn.Type) {\n\t\t\tv = s.openDeferSave(nil, argn.Type, s.expr(argn))\n\t\t} else {\n\t\t\tv = s.openDeferSave(argn, argn.Type, nil)\n\t\t}\n\t\targs = append(args, v)\n\t\targNodes = append(argNodes, v.Aux.(*Node))\n\t}\n\topendefer.argVals = args\n\topendefer.argNodes = argNodes\n\tindex := len(s.openDefers)\n\ts.openDefers = append(s.openDefers, opendefer)\n\n\t// Update deferBits only after evaluation and storage to stack of\n\t// args/receiver/interface is successful.\n\tbitvalue := s.constInt8(types.Types[TUINT8], 1<<uint(index))\n\tnewDeferBits := s.newValue2(ssa.OpOr8, types.Types[TUINT8], s.variable(&deferBitsVar, types.Types[TUINT8]), bitvalue)\n\ts.vars[&deferBitsVar] = newDeferBits\n\ts.store(types.Types[TUINT8], s.deferBitsAddr, newDeferBits)\n}\n\n// openDeferSave generates SSA nodes to store a value (with type t) for an\n// open-coded defer at an explicit autotmp location on the stack, so it can be\n// reloaded and used for the appropriate call on exit. If type t is SSAable, then\n// val must be non-nil (and n should be nil) and val is the value to be stored. If\n// type t is non-SSAable, then n must be non-nil (and val should be nil) and n is\n// evaluated (via s.addr() below) to get the value that is to be stored. The\n// function returns an SSA value representing a pointer to the autotmp location.\nfunc (s *state) openDeferSave(n *Node, t *types.Type, val *ssa.Value) *ssa.Value {\n\tcanSSA := canSSAType(t)\n\tvar pos src.XPos\n\tif canSSA {\n\t\tpos = val.Pos\n\t} else {\n\t\tpos = n.Pos\n\t}\n\targTemp := tempAt(pos.WithNotStmt(), s.curfn, t)\n\targTemp.Name.SetOpenDeferSlot(true)\n\tvar addrArgTemp *ssa.Value\n\t// Use OpVarLive to make sure stack slots for the args, etc. are not\n\t// removed by dead-store elimination\n\tif s.curBlock.ID != s.f.Entry.ID {\n\t\t// Force the argtmp storing this defer function/receiver/arg to be\n\t\t// declared in the entry block, so that it will be live for the\n\t\t// defer exit code (which will actually access it only if the\n\t\t// associated defer call has been activated).\n\t\ts.defvars[s.f.Entry.ID][&memVar] = s.entryNewValue1A(ssa.OpVarDef, types.TypeMem, argTemp, s.defvars[s.f.Entry.ID][&memVar])\n\t\ts.defvars[s.f.Entry.ID][&memVar] = s.entryNewValue1A(ssa.OpVarLive, types.TypeMem, argTemp, s.defvars[s.f.Entry.ID][&memVar])\n\t\taddrArgTemp = s.entryNewValue2A(ssa.OpLocalAddr, types.NewPtr(argTemp.Type), argTemp, s.sp, s.defvars[s.f.Entry.ID][&memVar])\n\t} else {\n\t\t// Special case if we're still in the entry block. We can't use\n\t\t// the above code, since s.defvars[s.f.Entry.ID] isn't defined\n\t\t// until we end the entry block with s.endBlock().\n\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarDef, types.TypeMem, argTemp, s.mem(), false)\n\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarLive, types.TypeMem, argTemp, s.mem(), false)\n\t\taddrArgTemp = s.newValue2Apos(ssa.OpLocalAddr, types.NewPtr(argTemp.Type), argTemp, s.sp, s.mem(), false)\n\t}\n\tif t.HasPointers() {\n\t\t// Since we may use this argTemp during exit depending on the\n\t\t// deferBits, we must define it unconditionally on entry.\n\t\t// Therefore, we must make sure it is zeroed out in the entry\n\t\t// block if it contains pointers, else GC may wrongly follow an\n\t\t// uninitialized pointer value.\n\t\targTemp.Name.SetNeedzero(true)\n\t}\n\tif !canSSA {\n\t\ta := s.addr(n)\n\t\ts.move(t, addrArgTemp, a)\n\t\treturn addrArgTemp\n\t}\n\t// We are storing to the stack, hence we can avoid the full checks in\n\t// storeType() (no write barrier) and do a simple store().\n\ts.store(t, addrArgTemp, val)\n\treturn addrArgTemp\n}\n\n// openDeferExit generates SSA for processing all the open coded defers at exit.\n// The code involves loading deferBits, and checking each of the bits to see if\n// the corresponding defer statement was executed. For each bit that is turned\n// on, the associated defer call is made.\nfunc (s *state) openDeferExit() {\n\tdeferExit := s.f.NewBlock(ssa.BlockPlain)\n\ts.endBlock().AddEdgeTo(deferExit)\n\ts.startBlock(deferExit)\n\ts.lastDeferExit = deferExit\n\ts.lastDeferCount = len(s.openDefers)\n\tzeroval := s.constInt8(types.Types[TUINT8], 0)\n\t// Test for and run defers in reverse order\n\tfor i := len(s.openDefers) - 1; i >= 0; i-- {\n\t\tr := s.openDefers[i]\n\t\tbCond := s.f.NewBlock(ssa.BlockPlain)\n\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\n\t\tdeferBits := s.variable(&deferBitsVar, types.Types[TUINT8])\n\t\t// Generate code to check if the bit associated with the current\n\t\t// defer is set.\n\t\tbitval := s.constInt8(types.Types[TUINT8], 1<<uint(i))\n\t\tandval := s.newValue2(ssa.OpAnd8, types.Types[TUINT8], deferBits, bitval)\n\t\teqVal := s.newValue2(ssa.OpEq8, types.Types[TBOOL], andval, zeroval)\n\t\tb := s.endBlock()\n\t\tb.Kind = ssa.BlockIf\n\t\tb.SetControl(eqVal)\n\t\tb.AddEdgeTo(bEnd)\n\t\tb.AddEdgeTo(bCond)\n\t\tbCond.AddEdgeTo(bEnd)\n\t\ts.startBlock(bCond)\n\n\t\t// Clear this bit in deferBits and force store back to stack, so\n\t\t// we will not try to re-run this defer call if this defer call panics.\n\t\tnbitval := s.newValue1(ssa.OpCom8, types.Types[TUINT8], bitval)\n\t\tmaskedval := s.newValue2(ssa.OpAnd8, types.Types[TUINT8], deferBits, nbitval)\n\t\ts.store(types.Types[TUINT8], s.deferBitsAddr, maskedval)\n\t\t// Use this value for following tests, so we keep previous\n\t\t// bits cleared.\n\t\ts.vars[&deferBitsVar] = maskedval\n\n\t\t// Generate code to call the function call of the defer, using the\n\t\t// closure/receiver/args that were stored in argtmps at the point\n\t\t// of the defer statement.\n\t\targStart := Ctxt.FixedFrameSize()\n\t\tfn := r.n.Left\n\t\tstksize := fn.Type.ArgWidth()\n\t\tif r.rcvr != nil {\n\t\t\t// rcvr in case of OCALLINTER\n\t\t\tv := s.load(r.rcvr.Type.Elem(), r.rcvr)\n\t\t\taddr := s.constOffPtrSP(s.f.Config.Types.UintptrPtr, argStart)\n\t\t\ts.store(types.Types[TUINTPTR], addr, v)\n\t\t}\n\t\tfor j, argAddrVal := range r.argVals {\n\t\t\tf := getParam(r.n, j)\n\t\t\tpt := types.NewPtr(f.Type)\n\t\t\taddr := s.constOffPtrSP(pt, argStart+f.Offset)\n\t\t\tif !canSSAType(f.Type) {\n\t\t\t\ts.move(f.Type, addr, argAddrVal)\n\t\t\t} else {\n\t\t\t\targVal := s.load(f.Type, argAddrVal)\n\t\t\t\ts.storeType(f.Type, addr, argVal, 0, false)\n\t\t\t}\n\t\t}\n\t\tvar call *ssa.Value\n\t\tif r.closure != nil {\n\t\t\tv := s.load(r.closure.Type.Elem(), r.closure)\n\t\t\ts.maybeNilCheckClosure(v, callDefer)\n\t\t\tcodeptr := s.rawLoad(types.Types[TUINTPTR], v)\n\t\t\tcall = s.newValue3(ssa.OpClosureCall, types.TypeMem, codeptr, v, s.mem())\n\t\t} else {\n\t\t\t// Do a static call if the original call was a static function or method\n\t\t\tcall = s.newValue1A(ssa.OpStaticCall, types.TypeMem, fn.Sym.Linksym(), s.mem())\n\t\t}\n\t\tcall.AuxInt = stksize\n\t\ts.vars[&memVar] = call\n\t\t// Make sure that the stack slots with pointers are kept live\n\t\t// through the call (which is a pre-emption point). Also, we will\n\t\t// use the first call of the last defer exit to compute liveness\n\t\t// for the deferreturn, so we want all stack slots to be live.\n\t\tif r.closureNode != nil {\n\t\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarLive, types.TypeMem, r.closureNode, s.mem(), false)\n\t\t}\n\t\tif r.rcvrNode != nil {\n\t\t\tif r.rcvrNode.Type.HasPointers() {\n\t\t\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarLive, types.TypeMem, r.rcvrNode, s.mem(), false)\n\t\t\t}\n\t\t}\n\t\tfor _, argNode := range r.argNodes {\n\t\t\tif argNode.Type.HasPointers() {\n\t\t\t\ts.vars[&memVar] = s.newValue1Apos(ssa.OpVarLive, types.TypeMem, argNode, s.mem(), false)\n\t\t\t}\n\t\t}\n\n\t\ts.endBlock()\n\t\ts.startBlock(bEnd)\n\t}\n}\n\n// Calls the function n using the specified call type.\n// Returns the address of the return value (or nil if none).\nfunc (s *state) call(n *Node, k callKind) *ssa.Value {\n\tvar sym *types.Sym     // target symbol (if static)\n\tvar closure *ssa.Value // ptr to closure to run (if dynamic)\n\tvar codeptr *ssa.Value // ptr to target code (if dynamic)\n\tvar rcvr *ssa.Value    // receiver to set\t\t保存调用interface的函数时的rcvr\n\tfn := n.Left           // 获取左边的函数节点\n\tswitch n.Op {\n\tcase OCALLFUNC: // Left(List/Rlist) (function call f(args))\n\t\tif k == callNormal && fn.Op == ONAME && fn.Class() == PFUNC { // 全局函数的OCALLMETH, OCALLINTER两种调用方式\n\t\t\tsym = fn.Sym // 函数的方法符号\n\t\t\tbreak\n\t\t}\n\t\tclosure = s.expr(fn) // 闭包函数的调用\n\t\tif k != callDefer && k != callDeferStack {\n\t\t\t// Deferred nil function needs to panic when the function is invoked,\n\t\t\t// not the point of defer statement.\n\t\t\ts.maybeNilCheckClosure(closure, k)\n\t\t}\n\tcase OCALLMETH: // Left(List/Rlist) (direct method call x.Method(args))\n\t\tif fn.Op != ODOTMETH { // Left.Sym (Left is non-interface, Right is method name)\n\t\t\ts.Fatalf(\"OCALLMETH: n.Left not an ODOTMETH: %v\", fn)\n\t\t}\n\t\tif k == callNormal {\n\t\t\tsym = fn.Sym\n\t\t\tbreak\n\t\t}\n\t\tclosure = s.getMethodClosure(fn)\n\t\t// Note: receiver is already present in n.Rlist, so we don't\n\t\t// want to set it here.\n\tcase OCALLINTER: // Left(List/Rlist) (interface method call x.Method(args))\n\t\tif fn.Op != ODOTINTER { // Left.Sym (Left is interface, Right is method name)\n\t\t\ts.Fatalf(\"OCALLINTER: n.Left not an ODOTINTER: %v\", fn.Op)\n\t\t}\n\t\tvar iclosure *ssa.Value\n\t\ticlosure, rcvr = s.getClosureAndRcvr(fn)\n\t\tif k == callNormal {\n\t\t\tcodeptr = s.load(types.Types[TUINTPTR], iclosure)\n\t\t} else {\n\t\t\tclosure = iclosure\n\t\t}\n\t}\n\tdowidth(fn.Type)\n\tstksize := fn.Type.ArgWidth() // includes receiver, args, and results\tstksize记录函数需要开辟的总空间\n\n\t// Run all assignments of temps.\n\t// The temps are introduced to avoid overwriting argument\n\t// slots when arguments themselves require function calls.\n\ts.stmtList(n.List) // 实参赋值到内存\n\n\tvar call *ssa.Value\n\tif k == callDeferStack { // defer函数没有逃逸\n\t\t// Make a defer struct d on the stack.\n\t\tt := deferstruct(stksize)      // 创建一个deferstruct\n\t\td := tempAt(n.Pos, s.curfn, t) // 依据deferstruct类型创建一个位于s.curfn函数中的临时变量\n\n\t\ts.vars[&memVar] = s.newValue1A(ssa.OpVarDef, types.TypeMem, d, s.mem()) // 声明_defer结构体变量\n\t\taddr := s.addr(d)\n\n\t\t// Must match reflect.go:deferstruct and src/runtime/runtime2.go:_defer.\n\t\t// 0: siz\n\t\ts.store(types.Types[TUINT32],\n\t\t\ts.newValue1I(ssa.OpOffPtr, types.Types[TUINT32].PtrTo(), t.FieldOff(0), addr),\n\t\t\ts.constInt32(types.Types[TUINT32], int32(stksize)))\n\t\t// 1: started, set in deferprocStack\n\t\t// 2: heap, set in deferprocStack\n\t\t// 3: openDefer\n\t\t// 4: sp, set in deferprocStack\n\t\t// 5: pc, set in deferprocStack\n\t\t// 6: fn\n\t\ts.store(closure.Type,\n\t\t\ts.newValue1I(ssa.OpOffPtr, closure.Type.PtrTo(), t.FieldOff(6), addr),\n\t\t\tclosure)\n\t\t// 7: panic, set in deferprocStack\n\t\t// 8: link, set in deferprocStack\n\t\t// 9: framepc\n\t\t// 10: varp\n\t\t// 11: fd\n\n\t\t// Then, store all the arguments of the defer call.\n\t\tft := fn.Type // 函数类型\n\t\toff := t.FieldOff(12)\n\t\targs := n.Rlist.Slice() // 函数的出参列表, 先保存返回地址\n\n\t\t// Set receiver (for interface calls). Always a pointer.\n\t\tif rcvr != nil {\n\t\t\tp := s.newValue1I(ssa.OpOffPtr, ft.Recv().Type.PtrTo(), off, addr) // 获取defer结构体的off偏移处的地址\n\t\t\ts.store(types.Types[TUINTPTR], p, rcvr)                            // 将rcvr保存到p处\n\t\t}\n\t\t// Set receiver (for method calls).\n\t\tif n.Op == OCALLMETH {\n\t\t\tf := ft.Recv() // 获取函数的receiver\n\t\t\ts.storeArgWithBase(args[0], f.Type, addr, off+f.Offset)\n\t\t\targs = args[1:]\n\t\t}\n\t\t// Set other args.\n\t\tfor _, f := range ft.Params().Fields().Slice() {\n\t\t\ts.storeArgWithBase(args[0], f.Type, addr, off+f.Offset)\n\t\t\targs = args[1:]\n\t\t}\n\n\t\t// Call runtime.deferprocStack with pointer to _defer record.\n\t\targ0 := s.constOffPtrSP(types.Types[TUINTPTR], Ctxt.FixedFrameSize())\n\t\ts.store(types.Types[TUINTPTR], arg0, addr)                                    // 将defer保存到栈上\n\t\tcall = s.newValue1A(ssa.OpStaticCall, types.TypeMem, deferprocStack, s.mem()) // 调用deferprocStack函数\n\t\tif stksize < int64(Widthptr) {\n\t\t\t// We need room for both the call to deferprocStack and the call to\n\t\t\t// the deferred function.\n\t\t\tstksize = int64(Widthptr)\n\t\t}\n\t\tcall.AuxInt = stksize\n\t} else {\n\t\t// Store arguments to stack, including defer/go arguments and receiver for method calls.\n\t\t// These are written in SP-offset order.\n\t\targStart := Ctxt.FixedFrameSize()\n\t\t// Defer/go args.\n\t\tif k != callNormal {\n\t\t\t// Write argsize and closure (args to newproc/deferproc).\n\t\t\targsize := s.constInt32(types.Types[TUINT32], int32(stksize))\n\t\t\taddr := s.constOffPtrSP(s.f.Config.Types.UInt32Ptr, argStart)                 // 获取参数入栈的栈指针起始位置\n\t\t\ts.store(types.Types[TUINT32], addr, argsize)                                  // 函数的参数占据空间size保存在栈上\n\t\t\taddr = s.constOffPtrSP(s.f.Config.Types.UintptrPtr, argStart+int64(Widthptr)) // 栈偏移一个指针的长度\n\t\t\ts.store(types.Types[TUINTPTR], addr, closure)                                 // argsize之后将函数保存到栈上\n\t\t\tstksize += 2 * int64(Widthptr)                                                // 栈上存储了参数的字节数以及闭包函数的地址,所以总的栈空间加上两个指针长度\n\t\t\targStart += 2 * int64(Widthptr)                                               // 同上,实际存储参数的起始地址也加两个指针长度\n\t\t}\n\n\t\t// Set receiver (for interface calls).\n\t\tif rcvr != nil {\n\t\t\taddr := s.constOffPtrSP(s.f.Config.Types.UintptrPtr, argStart)\n\t\t\ts.store(types.Types[TUINTPTR], addr, rcvr) // 将receiver保存到栈上的第一个参数的位置\n\t\t}\n\n\t\t// Write args.\n\t\tt := n.Left.Type        // 函数节点类型\n\t\targs := n.Rlist.Slice() // 参数列表\n\t\tif n.Op == OCALLMETH {  // Left(List/Rlist) (direct method call x.Method(args))\n\t\t\tf := t.Recv()\n\t\t\ts.storeArg(args[0], f.Type, argStart+f.Offset) // 第一个参数是receiver,将其放在\n\t\t\targs = args[1:]\n\t\t}\n\t\tfor i, n := range args {\n\t\t\tf := t.Params().Field(i) // 获取第i个索引的实参\n\t\t\ts.storeArg(n, f.Type, argStart+f.Offset)\n\t\t}\n\n\t\t// call target\n\t\tswitch {\n\t\tcase k == callDefer:\n\t\t\tcall = s.newValue1A(ssa.OpStaticCall, types.TypeMem, deferproc, s.mem())\n\t\tcase k == callGo:\n\t\t\tcall = s.newValue1A(ssa.OpStaticCall, types.TypeMem, newproc, s.mem())\n\t\tcase closure != nil:\n\t\t\t// rawLoad because loading the code pointer from a\n\t\t\t// closure is always safe, but IsSanitizerSafeAddr\n\t\t\t// can't always figure that out currently, and it's\n\t\t\t// critical that we not clobber any arguments already\n\t\t\t// stored onto the stack.\n\t\t\tcodeptr = s.rawLoad(types.Types[TUINTPTR], closure)\n\t\t\tcall = s.newValue3(ssa.OpClosureCall, types.TypeMem, codeptr, closure, s.mem())\n\t\tcase codeptr != nil:\n\t\t\tcall = s.newValue2(ssa.OpInterCall, types.TypeMem, codeptr, s.mem())\n\t\tcase sym != nil:\n\t\t\tcall = s.newValue1A(ssa.OpStaticCall, types.TypeMem, sym.Linksym(), s.mem())\n\t\tdefault:\n\t\t\ts.Fatalf(\"bad call type %v %v\", n.Op, n)\n\t\t}\n\t\tcall.AuxInt = stksize // Call operations carry the argsize of the callee along with them\n\t}\n\ts.vars[&memVar] = call\n\n\t// Finish block for defers\n\tif k == callDefer || k == callDeferStack {\n\t\tb := s.endBlock()\n\t\tb.Kind = ssa.BlockDefer\n\t\tb.SetControl(call)\n\t\tbNext := s.f.NewBlock(ssa.BlockPlain)\n\t\tb.AddEdgeTo(bNext)\n\t\t// Add recover edge to exit code.\n\t\tr := s.f.NewBlock(ssa.BlockPlain)\n\t\ts.startBlock(r)\n\t\ts.exit()\n\t\tb.AddEdgeTo(r)\n\t\tb.Likely = ssa.BranchLikely\n\t\ts.startBlock(bNext)\n\t}\n\n\tres := n.Left.Type.Results()                 // 获取函数的返回值列表,是一个结构体\n\tif res.NumFields() == 0 || k != callNormal { // 无返回值或者不是一般调用\n\t\t// call has no return value. Continue with the next statement.\n\t\treturn nil\n\t}\n\tfp := res.Field(0) // 第一个出参\n\treturn s.constOffPtrSP(types.NewPtr(fp.Type), fp.Offset+Ctxt.FixedFrameSize())\n}\n\n// maybeNilCheckClosure checks if a nil check of a closure is needed in some\n// architecture-dependent situations and, if so, emits the nil check.\nfunc (s *state) maybeNilCheckClosure(closure *ssa.Value, k callKind) {\n\tif thearch.LinkArch.Family == sys.Wasm || objabi.GOOS == \"aix\" && k != callGo {\n\t\t// On AIX, the closure needs to be verified as fn can be nil, except if it's a call go. This needs to be handled by the runtime to have the \"go of nil func value\" error.\n\t\t// TODO(neelance): On other architectures this should be eliminated by the optimization steps\n\t\ts.nilCheck(closure)\n\t}\n}\n\n// getMethodClosure returns a value representing the closure for a method call\nfunc (s *state) getMethodClosure(fn *Node) *ssa.Value {\n\t// Make a name n2 for the function.\n\t// fn.Sym might be sync.(*Mutex).Unlock.\n\t// Make a PFUNC node out of that, then evaluate it.\n\t// We get back an SSA value representing &sync.(*Mutex).Unlock·f.\n\t// We can then pass that to defer or go.\n\tn2 := newnamel(fn.Pos, fn.Sym) // 依据传入的符号创新创建一个ONAME节点\n\tn2.Name.Curfn = s.curfn\n\tn2.SetClass(PFUNC)\n\t// n2.Sym already existed, so it's already marked as a function.\n\tn2.Pos = fn.Pos\n\tn2.Type = types.Types[TUINT8] // dummy type for a static closure. Could use runtime.funcval if we had it.\n\treturn s.expr(n2)\n}\n\n// getClosureAndRcvr returns values for the appropriate closure and receiver of an\n// interface call\nfunc (s *state) getClosureAndRcvr(fn *Node) (*ssa.Value, *ssa.Value) {\n\ti := s.expr(fn.Left)                                      // 接口\n\titab := s.newValue1(ssa.OpITab, types.Types[TUINTPTR], i) // 依据接口类型获取itab\n\ts.nilCheck(itab)                                          // 添加对itab的空指针检查\n\titabidx := fn.Xoffset + 2*int64(Widthptr) + 8             // offset of fun field in runtime.itab\n\tclosure := s.newValue1I(ssa.OpOffPtr, s.f.Config.Types.UintptrPtr, itabidx, itab)\n\trcvr := s.newValue1(ssa.OpIData, types.Types[TUINTPTR], i)\n\treturn closure, rcvr\n}\n\n// etypesign returns the signed-ness of e, for integer/pointer etypes.\n// -1 means signed, +1 means unsigned, 0 means non-integer/non-pointer.\nfunc etypesign(e types.EType) int8 {\n\tswitch e {\n\tcase TINT8, TINT16, TINT32, TINT64, TINT:\n\t\treturn -1\n\tcase TUINT8, TUINT16, TUINT32, TUINT64, TUINT, TUINTPTR, TUNSAFEPTR:\n\t\treturn +1\n\t}\n\treturn 0\n}\n\n// addr converts the address of the expression n to SSA, adds it to s and returns the SSA result.\n// The value that the returned Value represents is guaranteed to be non-nil.\nfunc (s *state) addr(n *Node) *ssa.Value {\n\tif n.Op != ONAME { // 不保存变量声明时的调试信息\n\t\ts.pushLine(n.Pos)\n\t\tdefer s.popLine()\n\t}\n\n\tt := types.NewPtr(n.Type) // n.Type的指针类型\n\tswitch n.Op {\n\tcase ONAME:\n\t\tswitch n.Class() {\n\t\tcase PEXTERN: // global variable\n\t\t\t// global variable\n\t\t\tv := s.entryNewValue1A(ssa.OpAddr, t, n.Sym.Linksym(), s.sb) // 取全局变量的地址(通过一个链接符号),返回t类型\n\t\t\t// TODO: Make OpAddr use AuxInt as well as Aux.\n\t\t\tif n.Xoffset != 0 { // 取一个地址的偏移地址\n\t\t\t\tv = s.entryNewValue1I(ssa.OpOffPtr, v.Type, n.Xoffset, v)\n\t\t\t}\n\t\t\treturn v\n\t\tcase PPARAM: // input arguments\n\t\t\t// parameter slot\n\t\t\tv := s.decladdrs[n]\n\t\t\tif v != nil {\n\t\t\t\treturn v\n\t\t\t}\n\t\t\tif n == nodfp {\n\t\t\t\t// Special arg that points to the frame pointer (Used by ORECOVER).\n\t\t\t\treturn s.entryNewValue2A(ssa.OpLocalAddr, t, n, s.sp, s.startmem)\n\t\t\t}\n\t\t\ts.Fatalf(\"addr of undeclared ONAME %v. declared: %v\", n, s.decladdrs)\n\t\t\treturn nil\n\t\tcase PAUTO: // local variables\n\t\t\treturn s.newValue2Apos(ssa.OpLocalAddr, t, n, s.sp, s.mem(), !n.IsAutoTmp())\n\n\t\tcase PPARAMOUT: // Same as PAUTO -- cannot generate LEA early.\n\t\t\t// ensure that we reuse symbols for out parameters so\n\t\t\t// that cse works on their addresses\n\t\t\treturn s.newValue2Apos(ssa.OpLocalAddr, t, n, s.sp, s.mem(), true)\n\t\tdefault:\n\t\t\ts.Fatalf(\"variable address class %v not implemented\", n.Class())\n\t\t\treturn nil\n\t\t}\n\tcase ORESULT:\n\t\t// load return from callee\n\t\treturn s.constOffPtrSP(t, n.Xoffset)\n\tcase OINDEX: // Left[Right] (index of array or slice)\n\t\tif n.Left.Type.IsSlice() {\n\t\t\ta := s.expr(n.Left)\n\t\t\ti := s.expr(n.Right)\n\t\t\tlen := s.newValue1(ssa.OpSliceLen, types.Types[TINT], a)\n\t\t\taddOp := s.ssaOp(OADD, types.Types[TINT])\n\t\t\tif !i.IsGenericIntConst() {\n\t\t\t\ti = s.nagetiveAddLen(i, len, addOp)\n\t\t\t} else if i.AuxInt < 0 {\n\t\t\t\ti = s.newValue2(addOp, types.Types[TINT], i, len)\n\t\t\t}\n\t\t\ti = s.boundsCheck(i, len, ssa.BoundsIndex, n.Bounded())\n\t\t\tp := s.newValue1(ssa.OpSlicePtr, t, a)\n\t\t\treturn s.newValue2(ssa.OpPtrIndex, t, p, i)\n\t\t} else { // array\n\t\t\ta := s.addr(n.Left)\n\t\t\ti := s.expr(n.Right)\n\t\t\tlen := s.constInt(types.Types[TINT], n.Left.Type.NumElem())\n\t\t\t/*addOp := s.ssaOp(OADD, types.Types[TINT])\n\t\t\tif !i.IsGenericIntConst() {\n\t\t\t\ti = s.nagetiveAddLen(i, len, addOp)\n\t\t\t} else if i.AuxInt < 0 {\n\t\t\t\ti = s.newValue2(addOp, types.Types[TINT], i, len)\n\t\t\t}*/\n\t\t\ti = s.boundsCheck(i, len, ssa.BoundsIndex, n.Bounded())\n\t\t\treturn s.newValue2(ssa.OpPtrIndex, types.NewPtr(n.Left.Type.Elem()), a, i)\n\t\t}\n\tcase ODEREF: // *Left\n\t\treturn s.exprPtr(n.Left, n.Bounded(), n.Pos)\n\tcase ODOT: // Left.Sym (Left is of struct type)\n\t\tp := s.addr(n.Left)\n\t\treturn s.newValue1I(ssa.OpOffPtr, t, n.Xoffset, p)\n\tcase ODOTPTR: // Left.Sym (Left is of pointer to struct type)\n\t\tp := s.exprPtr(n.Left, n.Bounded(), n.Pos)\n\t\treturn s.newValue1I(ssa.OpOffPtr, t, n.Xoffset, p)\n\tcase OCLOSUREVAR: // 在闭包函数开始时引用的变量\n\t\treturn s.newValue1I(ssa.OpOffPtr, t, n.Xoffset,\n\t\t\ts.entryNewValue0(ssa.OpGetClosurePtr, s.f.Config.Types.BytePtr))\n\tcase OCONVNOP: // Type(Left) (type conversion, no effect)\n\t\taddr := s.addr(n.Left)\n\t\treturn s.newValue1(ssa.OpCopy, t, addr) // ensure that addr has the right type\n\tcase OCALLFUNC, OCALLINTER, OCALLMETH: // Left(List/Rlist) (function call f(args)), Left(List/Rlist) (interface method call x.Method(args)), Left(List/Rlist) (direct method call x.Method(args))\n\t\treturn s.call(n, callNormal)\n\tcase ODOTTYPE: // Left.Right or Left.Type (.Right during parsing, .Type once resolved); after walk, .Right contains address of interface type descriptor and .Right contains address of concrete type descriptor\n\t\tv, _ := s.dottype(n, false)\n\t\tif v.Op != ssa.OpLoad {\n\t\t\ts.Fatalf(\"dottype of non-load\")\n\t\t}\n\t\tif v.Args[1] != s.mem() {\n\t\t\ts.Fatalf(\"memory no longer live from dottype load\")\n\t\t}\n\t\treturn v.Args[0]\n\tdefault:\n\t\ts.Fatalf(\"unhandled addr %v\", n.Op)\n\t\treturn nil\n\t}\n}\n\n// canSSA reports whether n is SSA-able.\n// n must be an ONAME (or an ODOT sequence with an ONAME base).\nfunc (s *state) canSSA(n *Node) bool {\n\tif Debug['N'] != 0 {\n\t\treturn false\n\t}\n\tfor n.Op == ODOT || (n.Op == OINDEX && n.Left.Type.IsArray()) {\n\t\tn = n.Left\n\t}\n\tif n.Op != ONAME {\n\t\treturn false\n\t}\n\tif n.Name.Addrtaken() { // 变量是一个地址返回false\n\t\treturn false\n\t}\n\tif n.isParamHeapCopy() {\n\t\treturn false\n\t}\n\tif n.Class() == PAUTOHEAP {\n\t\ts.Fatalf(\"canSSA of PAUTOHEAP %v\", n)\n\t}\n\tswitch n.Class() {\n\tcase PEXTERN:\n\t\treturn false\n\tcase PPARAMOUT:\n\t\tif s.hasdefer {\n\t\t\t// TODO: handle this case? Named return values must be\n\t\t\t// in memory so that the deferred function can see them.\n\t\t\t// Maybe do: if !strings.HasPrefix(n.String(), \"~\") { return false }\n\t\t\t// Or maybe not, see issue 18860.  Even unnamed return values\n\t\t\t// must be written back so if a defer recovers, the caller can see them.\n\t\t\treturn false\n\t\t}\n\t\tif s.cgoUnsafeArgs {\n\t\t\t// Cgo effectively takes the address of all result args,\n\t\t\t// but the compiler can't see that.\n\t\t\treturn false\n\t\t}\n\t}\n\tif n.Class() == PPARAM && n.Sym != nil && n.Sym.Name == \".this\" {\n\t\t// wrappers generated by genwrapper need to update\n\t\t// the .this pointer in place.\n\t\t// TODO: treat as a PPARMOUT?\n\t\treturn false\n\t}\n\treturn canSSAType(n.Type)\n\t// TODO: try to make more variables SSAable?\n}\n\n// canSSA reports whether variables of type t are SSA-able.\nfunc canSSAType(t *types.Type) bool {\n\tdowidth(t)\n\tif t.Width > int64(4*Widthptr) {\n\t\t// 4*Widthptr is an arbitrary constant. We want it\n\t\t// to be at least 3*Widthptr so slices can be registerized.\n\t\t// Too big and we'll introduce too much register pressure.\n\t\treturn false\n\t}\n\tswitch t.Etype {\n\tcase TARRAY:\n\t\t// We can't do larger arrays because dynamic indexing is\n\t\t// not supported on SSA variables.\n\t\t// TODO: allow if all indexes are constant.\n\t\tif t.NumElem() <= 1 {\n\t\t\treturn canSSAType(t.Elem())\n\t\t}\n\t\treturn false\n\tcase TSTRUCT:\n\t\tif t.NumFields() > ssa.MaxStruct {\n\t\t\treturn false\n\t\t}\n\t\tfor _, t1 := range t.Fields().Slice() {\n\t\t\tif !canSSAType(t1.Type) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tdefault:\n\t\treturn true\n\t}\n}\n\n// exprPtr evaluates n to a pointer and nil-checks it.\nfunc (s *state) exprPtr(n *Node, bounded bool, lineno src.XPos) *ssa.Value {\n\tp := s.expr(n)\n\tif bounded || n.NonNil() { // 无需边界检查或n不为nil\n\t\tif s.f.Frontend().Debug_checknil() && lineno.Line() > 1 {\n\t\t\ts.f.Warnl(lineno, \"removed nil check\")\n\t\t}\n\t\treturn p\n\t}\n\ts.nilCheck(p)\n\treturn p\n}\n\n// nilCheck generates nil pointer checking code.\n// Used only for automatically inserted nil checks,\n// not for user code like 'x != nil'.\nfunc (s *state) nilCheck(ptr *ssa.Value) {\n\tif disable_checknil != 0 || s.curfn.Func.NilCheckDisabled() {\n\t\treturn\n\t}\n\ts.newValue2(ssa.OpNilCheck, types.TypeVoid, ptr, s.mem())\n}\n\n// boundsCheck generates bounds checking code. Checks if 0 <= idx <[=] len, branches to exit if not.\n// Starts a new block on return.\n// On input, len must be converted to full int width and be nonnegative.\n// Returns idx converted to full int width.\n// If bounded is true then caller guarantees the index is not out of bounds\n// (but boundsCheck will still extend the index to full int width).\nfunc (s *state) boundsCheck(idx, len *ssa.Value, kind ssa.BoundsKind, bounded bool) *ssa.Value {\n\tidx = s.extendIndex(idx, len, kind, bounded)\n\n\tif bounded || Debug['B'] != 0 {\n\t\t// If bounded or bounds checking is flag-disabled, then no check necessary,\n\t\t// just return the extended index.\n\t\t//\n\t\t// Here, bounded == true if the compiler generated the index itself,\n\t\t// such as in the expansion of a slice initializer. These indexes are\n\t\t// compiler-generated, not Go program variables, so they cannot be\n\t\t// attacker-controlled, so we can omit Spectre masking as well.\n\t\t//\n\t\t// Note that we do not want to omit Spectre masking in code like:\n\t\t//\n\t\t//\tif 0 <= i && i < len(x) {\n\t\t//\t\tuse(x[i])\n\t\t//\t}\n\t\t//\n\t\t// Lucky for us, bounded==false for that code.\n\t\t// In that case (handled below), we emit a bound check (and Spectre mask)\n\t\t// and then the prove pass will remove the bounds check.\n\t\t// In theory the prove pass could potentially remove certain\n\t\t// Spectre masks, but it's very delicate and probably better\n\t\t// to be conservative and leave them all in.\n\t\treturn idx\n\t}\n\n\tbNext := s.f.NewBlock(ssa.BlockPlain)\n\tbPanic := s.f.NewBlock(ssa.BlockExit)\n\n\tif !idx.Type.IsSigned() {\n\t\tswitch kind {\n\t\tcase ssa.BoundsIndex:\n\t\t\tkind = ssa.BoundsIndexU\n\t\tcase ssa.BoundsSliceAlen:\n\t\t\tkind = ssa.BoundsSliceAlenU\n\t\tcase ssa.BoundsSliceAcap:\n\t\t\tkind = ssa.BoundsSliceAcapU\n\t\tcase ssa.BoundsSliceB:\n\t\t\tkind = ssa.BoundsSliceBU\n\t\tcase ssa.BoundsSlice3Alen:\n\t\t\tkind = ssa.BoundsSlice3AlenU\n\t\tcase ssa.BoundsSlice3Acap:\n\t\t\tkind = ssa.BoundsSlice3AcapU\n\t\tcase ssa.BoundsSlice3B:\n\t\t\tkind = ssa.BoundsSlice3BU\n\t\tcase ssa.BoundsSlice3C:\n\t\t\tkind = ssa.BoundsSlice3CU\n\t\t}\n\t}\n\n\tvar cmp *ssa.Value\n\tif kind == ssa.BoundsIndex || kind == ssa.BoundsIndexU {\n\t\tcmp = s.newValue2(ssa.OpIsInBounds, types.Types[TBOOL], idx, len)\n\t} else {\n\t\tcmp = s.newValue2(ssa.OpIsSliceInBounds, types.Types[TBOOL], idx, len)\n\t}\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf // 标志b是一个if块\n\tb.SetControl(cmp)    // 通过cmp进行控制流判断\n\tb.Likely = ssa.BranchLikely\n\tb.AddEdgeTo(bNext)\n\tb.AddEdgeTo(bPanic)\n\n\ts.startBlock(bPanic)\n\tif thearch.LinkArch.Family == sys.Wasm {\n\t\t// TODO(khr): figure out how to do \"register\" based calling convention for bounds checks.\n\t\t// Should be similar to gcWriteBarrier, but I can't make it work.\n\t\ts.rtcall(BoundsCheckFunc[kind], false, nil, idx, len)\n\t} else {\n\t\tmem := s.newValue3I(ssa.OpPanicBounds, types.TypeMem, int64(kind), idx, len, s.mem())\n\t\ts.endBlock().SetControl(mem)\n\t}\n\ts.startBlock(bNext)\n\n\t// In Spectre index mode, apply an appropriate mask to avoid speculative out-of-bounds accesses.\n\tif spectreIndex {\n\t\top := ssa.OpSpectreIndex\n\t\tif kind != ssa.BoundsIndex && kind != ssa.BoundsIndexU {\n\t\t\top = ssa.OpSpectreSliceIndex\n\t\t}\n\t\tidx = s.newValue2(op, types.Types[TINT], idx, len)\n\t}\n\n\treturn idx\n}\n\n// If cmp (a bool) is false, panic using the given function.\nfunc (s *state) check(cmp *ssa.Value, fn *obj.LSym) {\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf\n\tb.SetControl(cmp)\n\tb.Likely = ssa.BranchLikely\n\tbNext := s.f.NewBlock(ssa.BlockPlain)\n\tline := s.peekPos()\n\tpos := Ctxt.PosTable.Pos(line)\n\tfl := funcLine{f: fn, base: pos.Base(), line: pos.Line()}\n\tbPanic := s.panics[fl]\n\tif bPanic == nil {\n\t\tbPanic = s.f.NewBlock(ssa.BlockPlain)\n\t\ts.panics[fl] = bPanic\n\t\ts.startBlock(bPanic)\n\t\t// The panic call takes/returns memory to ensure that the right\n\t\t// memory state is observed if the panic happens.\n\t\ts.rtcall(fn, false, nil)\n\t}\n\tb.AddEdgeTo(bNext)\n\tb.AddEdgeTo(bPanic)\n\ts.startBlock(bNext)\n}\n\nfunc (s *state) intDivide(n *Node, a, b *ssa.Value) *ssa.Value {\n\tneedcheck := true\n\tswitch b.Op { // 判断被除数表达式的操作码\n\tcase ssa.OpConst8, ssa.OpConst16, ssa.OpConst32, ssa.OpConst64:\n\t\tif b.AuxInt != 0 { // 被除数不为0\n\t\t\tneedcheck = false\n\t\t}\n\t}\n\tif needcheck {\n\t\t// do a size-appropriate check for zero\n\t\tcmp := s.newValue2(s.ssaOp(ONE, n.Type), types.Types[TBOOL], b, s.zeroVal(n.Type))\n\t\ts.check(cmp, panicdivide)\n\t}\n\treturn s.newValue2(s.ssaOp(n.Op, n.Type), a.Type, a, b)\n}\n\n// rtcall issues a call to the given runtime function fn with the listed args.\n// Returns a slice of results of the given result types.\n// The call is added to the end of the current block.\n// If returns is false, the block is marked as an exit block.\nfunc (s *state) rtcall(fn *obj.LSym, returns bool, results []*types.Type, args ...*ssa.Value) []*ssa.Value {\n\t// Write args to the stack\n\toff := Ctxt.FixedFrameSize() // 获取从硬件堆栈指针到堆栈上的局部变量的最小可能偏移量\n\tfor _, arg := range args {\n\t\tt := arg.Type                 // 参数类型\n\t\toff = Rnd(off, t.Alignment()) // 将off依据参数的类型进行对齐\n\t\tptr := s.constOffPtrSP(t.PtrTo(), off)\n\t\tsize := t.Size()     // 获取参数类型的宽度\n\t\ts.store(t, ptr, arg) // 将t类型的arg参数存储到ptr指针\n\t\toff += size          // 在off + size处继续存储下一个参数\n\t}\n\toff = Rnd(off, int64(Widthreg)) // 与指针宽度对齐\n\n\t// Issue call\n\tcall := s.newValue1A(ssa.OpStaticCall, types.TypeMem, fn, s.mem())\n\ts.vars[&memVar] = call\n\n\tif !returns { // 函数没有返回值\n\t\t// Finish block\n\t\tb := s.endBlock()\n\t\tb.Kind = ssa.BlockExit // 退出块\n\t\tb.SetControl(call)\n\t\tcall.AuxInt = off - Ctxt.FixedFrameSize() // 计算出所有的入参共占用了多少栈空间\n\t\tif len(results) > 0 {                     // 设置了出参的类型\n\t\t\ts.Fatalf(\"panic call can't have results\")\n\t\t}\n\t\treturn nil\n\t}\n\n\t// Load results\n\tres := make([]*ssa.Value, len(results))\n\tfor i, t := range results { // 遍历所有定义的results类型\n\t\toff = Rnd(off, t.Alignment()) // 通过t类型进行地址对齐\n\t\tptr := s.constOffPtrSP(types.NewPtr(t), off)\n\t\tres[i] = s.load(t, ptr) // 推测为从ptr指针指向的内存中获取类型为t的指针保存大res[i]中\n\t\toff += t.Size()         // 偏移加上返回值的类型宽度\n\t}\n\toff = Rnd(off, int64(Widthptr)) // 与指针宽度对齐\n\n\t// Remember how much callee stack space we needed.\n\tcall.AuxInt = off\n\n\treturn res\n}\n\n// do *left = right for type t.\nfunc (s *state) storeType(t *types.Type, left, right *ssa.Value, skip skipMask, leftIsStmt bool) {\n\ts.instrument(t, left, true)\n\n\tif skip == 0 && (!t.HasPointers() || ssa.IsStackAddr(left)) {\n\t\t// Known to not have write barrier. Store the whole type.\n\t\ts.vars[&memVar] = s.newValue3Apos(ssa.OpStore, types.TypeMem, t, left, right, s.mem(), leftIsStmt)\n\t\treturn\n\t}\n\n\t// store scalar fields first, so write barrier stores for\n\t// pointer fields can be grouped together, and scalar values\n\t// don't need to be live across the write barrier call.\n\t// TODO: if the writebarrier pass knows how to reorder stores,\n\t// we can do a single store here as long as skip==0.\n\ts.storeTypeScalars(t, left, right, skip)\n\tif skip&skipPtr == 0 && t.HasPointers() { // 跳过指针且类型t包含指针\n\t\ts.storeTypePtrs(t, left, right)\n\t}\n}\n\n// do *left = right for all scalar (non-pointer) parts of t.\nfunc (s *state) storeTypeScalars(t *types.Type, left, right *ssa.Value, skip skipMask) {\n\tswitch {\n\tcase t.IsBoolean() || t.IsInteger() || t.IsFloat() || t.IsComplex():\n\t\ts.store(t, left, right)\n\tcase t.IsPtrShaped():\n\t\tif t.IsPtr() && t.Elem().NotInHeap() { // t是指针类型且没有指向堆区\n\t\t\ts.store(t, left, right) // see issue 42032\n\t\t}\n\t\t// otherwise, no scalar fields.\n\tcase t.IsString():\n\t\tif skip&skipLen != 0 {\n\t\t\treturn\n\t\t}\n\t\tlen := s.newValue1(ssa.OpStringLen, types.Types[TINT], right)\n\t\tlenAddr := s.newValue1I(ssa.OpOffPtr, s.f.Config.Types.IntPtr, s.config.PtrSize, left) // left+一个指针偏移处保存字符串的长度\n\t\ts.store(types.Types[TINT], lenAddr, len)\n\tcase t.IsSlice():\n\t\tif skip&skipLen == 0 {\n\t\t\tlen := s.newValue1(ssa.OpSliceLen, types.Types[TINT], right)\n\t\t\tlenAddr := s.newValue1I(ssa.OpOffPtr, s.f.Config.Types.IntPtr, s.config.PtrSize, left)\n\t\t\ts.store(types.Types[TINT], lenAddr, len)\n\t\t}\n\t\tif skip&skipCap == 0 {\n\t\t\tcap := s.newValue1(ssa.OpSliceCap, types.Types[TINT], right)\n\t\t\tcapAddr := s.newValue1I(ssa.OpOffPtr, s.f.Config.Types.IntPtr, 2*s.config.PtrSize, left)\n\t\t\ts.store(types.Types[TINT], capAddr, cap)\n\t\t}\n\tcase t.IsInterface():\n\t\t// itab field doesn't need a write barrier (even though it is a pointer).\n\t\titab := s.newValue1(ssa.OpITab, s.f.Config.Types.BytePtr, right)\n\t\ts.store(types.Types[TUINTPTR], left, itab)\n\tcase t.IsStruct():\n\t\tn := t.NumFields()\n\t\tfor i := 0; i < n; i++ {\n\t\t\tft := t.FieldType(i)                                                // 获取第i个字段的类型\n\t\t\taddr := s.newValue1I(ssa.OpOffPtr, ft.PtrTo(), t.FieldOff(i), left) // 获取left第i个字段的偏移所在地址\n\t\t\tval := s.newValue1I(ssa.OpStructSelect, ft, int64(i), right)\n\t\t\ts.storeTypeScalars(ft, addr, val, 0)\n\t\t}\n\tcase t.IsArray() && t.NumElem() == 0:\n\t\t// nothing\n\tcase t.IsArray() && t.NumElem() == 1:\n\t\ts.storeTypeScalars(t.Elem(), left, s.newValue1I(ssa.OpArraySelect, t.Elem(), 0, right), 0)\n\tdefault:\n\t\ts.Fatalf(\"bad write barrier type %v\", t)\n\t}\n}\n\n// do *left = right for all pointer parts of t.\nfunc (s *state) storeTypePtrs(t *types.Type, left, right *ssa.Value) {\n\tswitch {\n\tcase t.IsPtrShaped():\n\t\tif t.IsPtr() && t.Elem().NotInHeap() {\n\t\t\tbreak // see issue 42032\n\t\t}\n\t\ts.store(t, left, right)\n\tcase t.IsString(): // 字符串指针\n\t\tptr := s.newValue1(ssa.OpStringPtr, s.f.Config.Types.BytePtr, right)\n\t\ts.store(s.f.Config.Types.BytePtr, left, ptr) // 将指针保存到left中\n\tcase t.IsSlice():\n\t\telType := types.NewPtr(t.Elem()) // 创建切片元素的指针类型\n\t\tptr := s.newValue1(ssa.OpSlicePtr, elType, right)\n\t\ts.store(elType, left, ptr)\n\tcase t.IsInterface():\n\t\t// itab field is treated as a scalar.\n\t\tidata := s.newValue1(ssa.OpIData, s.f.Config.Types.BytePtr, right) // 获取右边的idata\n\t\tidataAddr := s.newValue1I(ssa.OpOffPtr, s.f.Config.Types.BytePtrPtr, s.config.PtrSize, left)\n\t\ts.store(s.f.Config.Types.BytePtr, idataAddr, idata)\n\tcase t.IsStruct():\n\t\tn := t.NumFields()\n\t\tfor i := 0; i < n; i++ {\n\t\t\tft := t.FieldType(i)\n\t\t\tif !ft.HasPointers() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\taddr := s.newValue1I(ssa.OpOffPtr, ft.PtrTo(), t.FieldOff(i), left)\n\t\t\tval := s.newValue1I(ssa.OpStructSelect, ft, int64(i), right)\n\t\t\ts.storeTypePtrs(ft, addr, val)\n\t\t}\n\tcase t.IsArray() && t.NumElem() == 0:\n\t\t// nothing\n\tcase t.IsArray() && t.NumElem() == 1:\n\t\ts.storeTypePtrs(t.Elem(), left, s.newValue1I(ssa.OpArraySelect, t.Elem(), 0, right))\n\tdefault:\n\t\ts.Fatalf(\"bad write barrier type %v\", t)\n\t}\n}\n\nfunc (s *state) storeArg(n *Node, t *types.Type, off int64) {\n\ts.storeArgWithBase(n, t, s.sp, off)\n}\n\nfunc (s *state) storeArgWithBase(n *Node, t *types.Type, base *ssa.Value, off int64) {\n\tpt := types.NewPtr(t) // 为t创建一个指针类型\n\tvar addr *ssa.Value\n\tif base == s.sp { // 表示当前这个参数是存储在栈上的\n\t\t// Use special routine that avoids allocation on duplicate offsets.\n\t\taddr = s.constOffPtrSP(pt, off)\n\t} else {\n\t\taddr = s.newValue1I(ssa.OpOffPtr, pt, off, base)\n\t}\n\n\tif !canSSAType(t) {\n\t\ta := s.addr(n)\n\t\ts.move(t, addr, a)\n\t\treturn\n\t}\n\n\ta := s.expr(n)\n\ts.storeType(t, addr, a, 0, false)\n}\n\nfunc (s *state) nagetiveAddLen(i, len *ssa.Value, addOp ssa.Op) *ssa.Value {\n\t// Allocate new blocks\n\tyes := s.f.NewBlock(ssa.BlockPlain)\n\tno := s.f.NewBlock(ssa.BlockPlain)\n\t// 在if块中定义变量\n\ts.vars[&minVar] = i\n\t// 非常量,添加判断并返回\n\tcmp := s.newValue2(s.ssaOp(OLT, types.Types[TINT]), types.Types[TBOOL], i, s.constInt(types.Types[TINT], 0)) // if i < 0\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf\n\tb.SetControl(cmp)\n\tb.AddEdgeTo(yes)\n\tb.AddEdgeTo(no)\n\n\ts.startBlock(yes)\n\t// 在yes块中定义变量,这样进入yes块时会将相加的结果赋值回i\n\ts.vars[&minVar] = s.newValue2(addOp, types.Types[TINT], i, len)\n\tb = s.endBlock()\n\tb.AddEdgeTo(no)\n\ts.startBlock(no)\n\t// 返回了i\n\treturn s.variable(&minVar, types.Types[TINT])\n}\n\n// slice computes the slice v[i:j:k] and returns ptr, len, and cap of result.\n// i,j,k may be nil, in which case they are set to their default value.\n// v may be a slice, string or pointer to an array.\nfunc (s *state) slice(v, i, j, k *ssa.Value, bounded bool) (p, l, c *ssa.Value) {\n\tt := v.Type\n\tvar ptr, len, cap *ssa.Value // 切片操作中被操作切片的指针,len与cap\n\tswitch {\n\tcase t.IsSlice():\n\t\tptr = s.newValue1(ssa.OpSlicePtr, types.NewPtr(t.Elem()), v)\n\t\tlen = s.newValue1(ssa.OpSliceLen, types.Types[TINT], v)\n\t\tcap = s.newValue1(ssa.OpSliceCap, types.Types[TINT], v)\n\tcase t.IsString():\n\t\tptr = s.newValue1(ssa.OpStringPtr, types.NewPtr(types.Types[TUINT8]), v)\n\t\tlen = s.newValue1(ssa.OpStringLen, types.Types[TINT], v)\n\t\tcap = len\n\tcase t.IsPtr():\n\t\tif !t.Elem().IsArray() {\n\t\t\ts.Fatalf(\"bad ptr to array in slice %v\\n\", t)\n\t\t}\n\t\ts.nilCheck(v) // 判断v不为nil\n\t\tptr = s.newValue1(ssa.OpCopy, types.NewPtr(t.Elem().Elem()), v)\n\t\tlen = s.constInt(types.Types[TINT], t.Elem().NumElem())\n\t\tcap = len\n\tdefault:\n\t\ts.Fatalf(\"bad type in slice %v\\n\", t)\n\t}\n\n\taddOp := s.ssaOp(OADD, types.Types[TINT])\n\t// Set default values\n\tif i == nil {\n\t\ti = s.constInt(types.Types[TINT], 0)\n\t} else if !i.IsGenericIntConst() {\n\t\ti = s.nagetiveAddLen(i, len, addOp)\n\t} else if i.AuxInt < 0 {\n\t\ti = s.newValue2(addOp, types.Types[TINT], i, len)\n\t}\n\n\tif j == nil {\n\t\tj = len\n\t} else if !j.IsGenericIntConst() {\n\t\tj = s.nagetiveAddLen(j, len, addOp)\n\t} else if j.IsGenericIntConst() && j.AuxInt < 0 {\n\t\tj = s.newValue2(addOp, types.Types[TINT], j, len)\n\t}\n\n\tif k == nil {\n\t\tif v.Extra == nil {\n\t\t\tk = cap\n\t\t} else {\n\t\t\t// v.Extra不为nil,那么必定是true,表示这个k是步进值,默认是1\n\t\t\tk = s.constInt(types.Types[TINT], 1)\n\t\t}\n\t}\n\n\t// Panic if slice indices are not in bounds.\n\t// Make sure we check these in reverse order so that we're always\n\t// comparing against a value known to be nonnegative. See issue 28797.\n\n\t// 确保i <= j\n\ti = s.boundsCheck(i, j, ssa.BoundsSliceB, bounded)\n\tif v.Extra == nil {\n\t\t// 确保j <= k\n\t\tj = s.boundsCheck(j, k, ssa.BoundsSliceB, bounded)\n\t} else {\n\t\t// 确保j <= cap\n\t\tj = s.boundsCheck(j, cap, ssa.BoundsSliceB, bounded)\n\t}\n\n\t// Word-sized integer operations.\n\tsubOp := s.ssaOp(OSUB, types.Types[TINT])\n\tmulOp := s.ssaOp(OMUL, types.Types[TINT])\n\tandOp := s.ssaOp(OAND, types.Types[TINT])\n\n\t// Calculate the length (rlen) and capacity (rcap) of the new slice.\n\t// For strings the capacity of the result is unimportant. However,\n\t// we use rcap to test if we've generated a zero-length slice.\n\t// Use length of strings for that.\n\trlen := s.newValue2(subOp, types.Types[TINT], j, i) // 计算新的长度\n\trcap := rlen\n\n\tif (i.Op == ssa.OpConst64 || i.Op == ssa.OpConst32) && i.AuxInt == 0 && v.Extra == nil {\n\t\t// No pointer arithmetic necessary.\n\t\treturn ptr, rlen, rcap\n\t}\n\n\t// Calculate the base pointer (rptr) for the new slice.\n\t//\n\t// Generate the following code assuming that indexes are in bounds.\n\t// The masking is to make sure that we don't generate a slice\n\t// that points to the next object in memory. We cannot just set\n\t// the pointer to nil because then we would create a nil slice or\n\t// string.\n\t//\n\t//     rcap = k - i\n\t//     rlen = j - i\n\t//     rptr = ptr + (mask(rcap) & (i * stride))\n\t//\n\t// Where mask(x) is 0 if x==0 and -1 if x>0 and stride is the width\n\t// of the element type.\n\tstride := s.constInt(types.Types[TINT], ptr.Type.Elem().Width) // 元素类型的宽度\n\n\t// The delta is the number of bytes to offset ptr by.\n\tdelta := s.newValue2(mulOp, types.Types[TINT], i, stride)\n\n\t// If we're slicing to the point where the capacity is zero,\n\t// zero out the delta.\n\tmask := s.newValue1(ssa.OpSlicemask, types.Types[TINT], rcap)\n\tdelta = s.newValue2(andOp, types.Types[TINT], delta, mask)\n\n\t// Compute rptr = ptr + delta.\n\trptr := s.newValue2(ssa.OpAddPtr, ptr.Type, ptr, delta)\n\tif v.Extra == nil || t.IsString() {\n\t\treturn rptr, rlen, rcap\n\t}\n\n\tet := t.Elem()         // 获取元素的类型\n\tpt := types.NewPtr(et) // 元素的指针类型\n\ttypenode := typename(et)\n\ttaddr := s.expr(typenode)\n\t// ptr偏移i个位置\n\tr := s.rtcall(cutslice, true, []*types.Type{pt, types.Types[TINT], types.Types[TINT]}, taddr, rptr, len, cap, i, j, k)\n\treturn r[0], r[1], r[2]\n}\n\ntype u642fcvtTab struct {\n\tleq, cvt2F, and, rsh, or, add ssa.Op\n\tone                           func(*state, *types.Type, int64) *ssa.Value\n}\n\nvar u64_f64 = u642fcvtTab{\n\tleq:   ssa.OpLeq64,\n\tcvt2F: ssa.OpCvt64to64F,\n\tand:   ssa.OpAnd64,\n\trsh:   ssa.OpRsh64Ux64,\n\tor:    ssa.OpOr64,\n\tadd:   ssa.OpAdd64F,\n\tone:   (*state).constInt64,\n}\n\nvar u64_f32 = u642fcvtTab{\n\tleq:   ssa.OpLeq64,\n\tcvt2F: ssa.OpCvt64to32F,\n\tand:   ssa.OpAnd64,\n\trsh:   ssa.OpRsh64Ux64,\n\tor:    ssa.OpOr64,\n\tadd:   ssa.OpAdd32F,\n\tone:   (*state).constInt64,\n}\n\nfunc (s *state) uint64Tofloat64(n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\treturn s.uint64Tofloat(&u64_f64, n, x, ft, tt)\n}\n\nfunc (s *state) uint64Tofloat32(n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\treturn s.uint64Tofloat(&u64_f32, n, x, ft, tt)\n}\n\nfunc (s *state) uint64Tofloat(cvttab *u642fcvtTab, n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\t// if x >= 0 {\n\t//    result = (floatY) x\n\t// } else {\n\t// \t  y = uintX(x) ; y = x & 1\n\t// \t  z = uintX(x) ; z = z >> 1\n\t// \t  z = z >> 1\n\t// \t  z = z | y\n\t// \t  result = floatY(z)\n\t// \t  result = result + result\n\t// }\n\t//\n\t// Code borrowed from old code generator.\n\t// What's going on: large 64-bit \"unsigned\" looks like\n\t// negative number to hardware's integer-to-float\n\t// conversion. However, because the mantissa is only\n\t// 63 bits, we don't need the LSB, so instead we do an\n\t// unsigned right shift (divide by two), convert, and\n\t// double. However, before we do that, we need to be\n\t// sure that we do not lose a \"1\" if that made the\n\t// difference in the resulting rounding. Therefore, we\n\t// preserve it, and OR (not ADD) it back in. The case\n\t// that matters is when the eleven discarded bits are\n\t// equal to 10000000001; that rounds up, and the 1 cannot\n\t// be lost else it would round down if the LSB of the\n\t// candidate mantissa is 0.\n\tcmp := s.newValue2(cvttab.leq, types.Types[TBOOL], s.zeroVal(ft), x) // if x >= 0\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf\n\tb.SetControl(cmp)\n\tb.Likely = ssa.BranchLikely\n\n\tbThen := s.f.NewBlock(ssa.BlockPlain)\n\tbElse := s.f.NewBlock(ssa.BlockPlain)\n\tbAfter := s.f.NewBlock(ssa.BlockPlain)\n\n\tb.AddEdgeTo(bThen)\n\ts.startBlock(bThen)\n\ta0 := s.newValue1(cvttab.cvt2F, tt, x) //    result = (floatY) x\n\ts.vars[n] = a0\n\ts.endBlock()\n\tbThen.AddEdgeTo(bAfter)\n\n\tb.AddEdgeTo(bElse)\n\ts.startBlock(bElse)\n\tone := cvttab.one(s, ft, 1)\n\ty := s.newValue2(cvttab.and, ft, x, one) // \t y = x & 1\n\tz := s.newValue2(cvttab.rsh, ft, x, one) // \t  z = z >> 1\n\tz = s.newValue2(cvttab.or, ft, z, y)     // \t  z = z | y\n\ta := s.newValue1(cvttab.cvt2F, tt, z)    // \t  result = floatY(z)\n\ta1 := s.newValue2(cvttab.add, tt, a, a)  // \t  result = result + result\n\ts.vars[n] = a1\n\ts.endBlock()\n\tbElse.AddEdgeTo(bAfter)\n\n\ts.startBlock(bAfter)\n\treturn s.variable(n, n.Type)\n}\n\ntype u322fcvtTab struct {\n\tcvtI2F, cvtF2F ssa.Op\n}\n\nvar u32_f64 = u322fcvtTab{\n\tcvtI2F: ssa.OpCvt32to64F,\n\tcvtF2F: ssa.OpCopy,\n}\n\nvar u32_f32 = u322fcvtTab{\n\tcvtI2F: ssa.OpCvt32to32F,\n\tcvtF2F: ssa.OpCvt64Fto32F,\n}\n\n// ft的类型是uint32,tt的类型是float64\nfunc (s *state) uint32Tofloat64(n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\treturn s.uint32Tofloat(&u32_f64, n, x, ft, tt)\n}\n\n// ft的类型是uint32,tt的类型是float32\nfunc (s *state) uint32Tofloat32(n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\treturn s.uint32Tofloat(&u32_f32, n, x, ft, tt)\n}\n\n// ft的类型是uint32,tt的类型是float32,x是被强转的值\nfunc (s *state) uint32Tofloat(cvttab *u322fcvtTab, n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\t// if x >= 0 {\n\t// \tresult = floatY(x)\n\t// } else {\n\t// \tresult = floatY(float64(x) + (1<<32))\n\t// }\n\tcmp := s.newValue2(ssa.OpLeq32, types.Types[TBOOL], s.zeroVal(ft), x) // 比较x与ft类型的0值\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf // 设置上一个块为if块\n\tb.SetControl(cmp)\n\tb.Likely = ssa.BranchLikely\n\n\tbThen := s.f.NewBlock(ssa.BlockPlain)  // if为true之后的块\n\tbElse := s.f.NewBlock(ssa.BlockPlain)  // if判断为false之后的块\n\tbAfter := s.f.NewBlock(ssa.BlockPlain) // if-else之后运行的代码块\n\n\tb.AddEdgeTo(bThen)\n\ts.startBlock(bThen)\n\ta0 := s.newValue1(cvttab.cvtI2F, tt, x)\n\ts.vars[n] = a0 // 记录被赋值的变量\n\ts.endBlock()\n\tbThen.AddEdgeTo(bAfter)\n\n\tb.AddEdgeTo(bElse)\n\ts.startBlock(bElse)\n\ta1 := s.newValue1(ssa.OpCvt32to64F, types.Types[TFLOAT64], x)\n\ttwoToThe32 := s.constFloat64(types.Types[TFLOAT64], float64(1<<32))\n\ta2 := s.newValue2(ssa.OpAdd64F, types.Types[TFLOAT64], a1, twoToThe32) // a1 + (1<<32)\n\ta3 := s.newValue1(cvttab.cvtF2F, tt, a2)\n\n\ts.vars[n] = a3 // 记录被赋值的变量\n\ts.endBlock()\n\tbElse.AddEdgeTo(bAfter)\n\n\ts.startBlock(bAfter)\n\treturn s.variable(n, n.Type)\n}\n\n// referenceTypeBuiltin generates code for the len/cap builtins for maps and channels.\nfunc (s *state) referenceTypeBuiltin(n *Node, x *ssa.Value) *ssa.Value {\n\tif !n.Left.Type.IsMap() && !n.Left.Type.IsChan() {\n\t\ts.Fatalf(\"node must be a map or a channel\")\n\t}\n\t// if n == nil {\n\t//   return 0\n\t// } else {\n\t//   // len\n\t//   return *((*int)n)\n\t//   // cap\n\t//   return *(((*int)n)+1)\n\t// }\n\tlenType := n.Type\n\tnilValue := s.constNil(types.Types[TUINTPTR])\n\tcmp := s.newValue2(ssa.OpEqPtr, types.Types[TBOOL], x, nilValue) // if n == nil\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf\n\tb.SetControl(cmp)\n\tb.Likely = ssa.BranchUnlikely\n\n\tbThen := s.f.NewBlock(ssa.BlockPlain)\n\tbElse := s.f.NewBlock(ssa.BlockPlain)\n\tbAfter := s.f.NewBlock(ssa.BlockPlain)\n\n\t// length/capacity of a nil map/chan is zero\n\tb.AddEdgeTo(bThen)\n\ts.startBlock(bThen)\n\ts.vars[n] = s.zeroVal(lenType) //   return 0\n\ts.endBlock()\n\tbThen.AddEdgeTo(bAfter)\n\n\tb.AddEdgeTo(bElse)\n\ts.startBlock(bElse)\n\tswitch n.Op {\n\tcase OLEN:\n\t\t// length is stored in the first word for map/chan\n\t\ts.vars[n] = s.load(lenType, x)\n\tcase OCAP:\n\t\t// capacity is stored in the second word for chan\n\t\tsw := s.newValue1I(ssa.OpOffPtr, lenType.PtrTo(), lenType.Width, x)\n\t\ts.vars[n] = s.load(lenType, sw)\n\tdefault:\n\t\ts.Fatalf(\"op must be OLEN or OCAP\")\n\t}\n\ts.endBlock()\n\tbElse.AddEdgeTo(bAfter)\n\n\ts.startBlock(bAfter)\n\treturn s.variable(n, lenType)\n}\n\ntype f2uCvtTab struct {\n\tltf, cvt2U, subf, or ssa.Op\n\tfloatValue           func(*state, *types.Type, float64) *ssa.Value\n\tintValue             func(*state, *types.Type, int64) *ssa.Value\n\tcutoff               uint64\n}\n\nvar f32_u64 = f2uCvtTab{\n\tltf:        ssa.OpLess32F,\n\tcvt2U:      ssa.OpCvt32Fto64,\n\tsubf:       ssa.OpSub32F,\n\tor:         ssa.OpOr64,\n\tfloatValue: (*state).constFloat32,\n\tintValue:   (*state).constInt64,\n\tcutoff:     1 << 63,\n}\n\nvar f64_u64 = f2uCvtTab{\n\tltf:        ssa.OpLess64F,\n\tcvt2U:      ssa.OpCvt64Fto64,\n\tsubf:       ssa.OpSub64F,\n\tor:         ssa.OpOr64,\n\tfloatValue: (*state).constFloat64,\n\tintValue:   (*state).constInt64,\n\tcutoff:     1 << 63,\n}\n\nvar f32_u32 = f2uCvtTab{\n\tltf:        ssa.OpLess32F,\n\tcvt2U:      ssa.OpCvt32Fto32,\n\tsubf:       ssa.OpSub32F,\n\tor:         ssa.OpOr32,\n\tfloatValue: (*state).constFloat32,\n\tintValue:   func(s *state, t *types.Type, v int64) *ssa.Value { return s.constInt32(t, int32(v)) },\n\tcutoff:     1 << 31,\n}\n\nvar f64_u32 = f2uCvtTab{\n\tltf:        ssa.OpLess64F,\n\tcvt2U:      ssa.OpCvt64Fto32,\n\tsubf:       ssa.OpSub64F,\n\tor:         ssa.OpOr32,\n\tfloatValue: (*state).constFloat64,\n\tintValue:   func(s *state, t *types.Type, v int64) *ssa.Value { return s.constInt32(t, int32(v)) },\n\tcutoff:     1 << 31,\n}\n\nfunc (s *state) float32ToUint64(n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\treturn s.floatToUint(&f32_u64, n, x, ft, tt)\n}\nfunc (s *state) float64ToUint64(n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\treturn s.floatToUint(&f64_u64, n, x, ft, tt)\n}\n\n// ft is float32 or float64, and tt is unsigned integer\nfunc (s *state) float32ToUint32(n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\treturn s.floatToUint(&f32_u32, n, x, ft, tt)\n}\n\nfunc (s *state) float64ToUint32(n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\treturn s.floatToUint(&f64_u32, n, x, ft, tt)\n}\n\n// ft is float32 or float64, and tt is unsigned integer\nfunc (s *state) floatToUint(cvttab *f2uCvtTab, n *Node, x *ssa.Value, ft, tt *types.Type) *ssa.Value {\n\t// cutoff:=1<<(intY_Size-1)\n\t// if x < floatX(cutoff) {\n\t// \tresult = uintY(x)\n\t// } else {\n\t// \ty = x - floatX(cutoff)\n\t// \tz = uintY(y)\n\t// \tresult = z | -(cutoff)\n\t// }\n\tcutoff := cvttab.floatValue(s, ft, float64(cvttab.cutoff))\n\tcmp := s.newValue2(cvttab.ltf, types.Types[TBOOL], x, cutoff) // if x < floatX(cutoff)\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf\n\tb.SetControl(cmp)\n\tb.Likely = ssa.BranchLikely\n\n\tbThen := s.f.NewBlock(ssa.BlockPlain)\n\tbElse := s.f.NewBlock(ssa.BlockPlain)\n\tbAfter := s.f.NewBlock(ssa.BlockPlain)\n\n\tb.AddEdgeTo(bThen)\n\ts.startBlock(bThen)\n\ta0 := s.newValue1(cvttab.cvt2U, tt, x) // result = uintY(x)\n\ts.vars[n] = a0\n\ts.endBlock()\n\tbThen.AddEdgeTo(bAfter)\n\n\tb.AddEdgeTo(bElse)\n\ts.startBlock(bElse)\n\ty := s.newValue2(cvttab.subf, ft, x, cutoff) // \ty = x - floatX(cutoff)\n\ty = s.newValue1(cvttab.cvt2U, tt, y)\n\tz := cvttab.intValue(s, tt, int64(-cvttab.cutoff))\n\ta1 := s.newValue2(cvttab.or, tt, y, z)\n\ts.vars[n] = a1\n\ts.endBlock()\n\tbElse.AddEdgeTo(bAfter)\n\n\ts.startBlock(bAfter)\n\treturn s.variable(n, n.Type)\n}\n\n// dottype generates SSA for a type assertion node.\n// commaok indicates whether to panic or return a bool.\n// If commaok is false, resok will be nil.\nfunc (s *state) dottype(n *Node, commaok bool) (res, resok *ssa.Value) {\n\tiface := s.expr(n.Left)   // input interface\n\ttarget := s.expr(n.Right) // target type\n\tbyteptr := s.f.Config.Types.BytePtr\n\n\tif n.Type.IsInterface() { // 说明n.Right的类型也是interface\n\t\tif n.Type.IsEmptyInterface() { // n.Right的类型是空接口\n\t\t\t// Converting to an empty interface.\n\t\t\t// Input could be an empty or nonempty interface.\n\t\t\tif Debug_typeassert > 0 {\n\t\t\t\tWarnl(n.Pos, \"type assertion inlined\")\n\t\t\t}\n\n\t\t\t// Get itab/type field from input.\n\t\t\titab := s.newValue1(ssa.OpITab, byteptr, iface)\n\t\t\t// Conversion succeeds if that field is not nil.\n\t\t\tcond := s.newValue2(ssa.OpNeqPtr, types.Types[TBOOL], itab, s.constNil(byteptr)) // 判断itab不为nil\n\n\t\t\tif n.Left.Type.IsEmptyInterface() && commaok { // 空接口强转为空接口只需要检查下待强转的接口是否为nil即可\n\t\t\t\t// Converting empty interface to empty interface with ,ok is just a nil check.\n\t\t\t\treturn iface, cond\n\t\t\t}\n\t\t\t// 非空接口强转为空接口\n\t\t\t// Branch on nilness.\n\t\t\tb := s.endBlock()\n\t\t\tb.Kind = ssa.BlockIf\n\t\t\tb.SetControl(cond) // 判断非空接口不为nil\n\t\t\tb.Likely = ssa.BranchLikely\n\t\t\tbOk := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbFail := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tb.AddEdgeTo(bOk)\n\t\t\tb.AddEdgeTo(bFail)\n\n\t\t\tif !commaok { // 接收的变量中没有, ok\n\t\t\t\t// On failure, panic by calling panicnildottype.\n\t\t\t\ts.startBlock(bFail)\n\t\t\t\ts.rtcall(panicnildottype, false, nil, target)\n\n\t\t\t\t// On success, return (perhaps modified) input interface.\n\t\t\t\ts.startBlock(bOk)\n\t\t\t\tif n.Left.Type.IsEmptyInterface() { // 空接口对空接口的类型断言\n\t\t\t\t\tres = iface // Use input interface unchanged.\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\t// Load type out of itab, build interface with existing idata.\n\t\t\t\toff := s.newValue1I(ssa.OpOffPtr, byteptr, int64(Widthptr), itab) // 获取n.Left的itab,一个指针的长度\n\t\t\t\ttyp := s.load(byteptr, off)                                       // 获取itab的第一个成员,也就是typ\n\t\t\t\tidata := s.newValue1(ssa.OpIData, n.Type, iface)                  // 从接口中获取idata\n\t\t\t\tres = s.newValue2(ssa.OpIMake, n.Type, typ, idata)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\ts.startBlock(bOk)\n\t\t\t// nonempty -> empty\n\t\t\t// Need to load type from itab\n\t\t\toff := s.newValue1I(ssa.OpOffPtr, byteptr, int64(Widthptr), itab) // 获取n.Left的itab\n\t\t\ts.vars[&typVar] = s.load(byteptr, off)                            // 根据itab获取type成员\n\t\t\ts.endBlock()\n\n\t\t\t// itab is nil, might as well use that as the nil result.\n\t\t\ts.startBlock(bFail)\n\t\t\ts.vars[&typVar] = itab\n\t\t\ts.endBlock()\n\n\t\t\t// Merge point.\n\t\t\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\t\t\tbOk.AddEdgeTo(bEnd)\n\t\t\tbFail.AddEdgeTo(bEnd)\n\t\t\ts.startBlock(bEnd)\n\t\t\tidata := s.newValue1(ssa.OpIData, n.Type, iface)                            // 从n.Left这个接口中获取idata\n\t\t\tres = s.newValue2(ssa.OpIMake, n.Type, s.variable(&typVar, byteptr), idata) // 将空接口类型与从n.Left这个接口中获取的idata组合\n\t\t\tresok = cond                                                                // 如果n.Left不为nil就是true,否则为false\n\t\t\tdelete(s.vars, &typVar)\n\t\t\treturn\n\t\t}\n\t\t// converting to a nonempty interface needs a runtime call.\n\t\tif Debug_typeassert > 0 {\n\t\t\tWarnl(n.Pos, \"type assertion not inlined\")\n\t\t}\n\t\tif n.Left.Type.IsEmptyInterface() { // 空接口转为非空接口\n\t\t\tif commaok {\n\t\t\t\tcall := s.rtcall(assertE2I2, true, []*types.Type{n.Type, types.Types[TBOOL]}, target, iface)\n\t\t\t\treturn call[0], call[1]\n\t\t\t}\n\t\t\treturn s.rtcall(assertE2I, true, []*types.Type{n.Type}, target, iface)[0], nil\n\t\t}\n\t\tif commaok { // 非空接口转为非空接口且接受的变量存在ok\n\t\t\tcall := s.rtcall(assertI2I2, true, []*types.Type{n.Type, types.Types[TBOOL]}, target, iface)\n\t\t\treturn call[0], call[1]\n\t\t}\n\t\treturn s.rtcall(assertI2I, true, []*types.Type{n.Type}, target, iface)[0], nil\n\t}\n\t// n.Right的类型不是接口\n\tif Debug_typeassert > 0 {\n\t\tWarnl(n.Pos, \"type assertion inlined\")\n\t}\n\n\t// Converting to a concrete type.\n\tdirect := isdirectiface(n.Type)                 // 转换后的类型可以直接存储到idata?\n\titab := s.newValue1(ssa.OpITab, byteptr, iface) // type word of interface\n\tif Debug_typeassert > 0 {\n\t\tWarnl(n.Pos, \"type assertion inlined\")\n\t}\n\tvar targetITab *ssa.Value\n\tif n.Left.Type.IsEmptyInterface() { // 空接口转化为确定的类型\n\t\t// Looking for pointer to target type.\n\t\ttargetITab = target\n\t} else { // 非空接口转化为确定的类型\n\t\t// Looking for pointer to itab for target type and source interface.\n\t\ttargetITab = s.expr(n.List.First())\n\t}\n\n\tvar tmp *Node       // temporary for use with large types\n\tvar addr *ssa.Value // address of tmp\n\tif commaok && !canSSAType(n.Type) {\n\t\t// unSSAable type, use temporary.\n\t\t// TODO: get rid of some of these temporaries.\n\t\ttmp = tempAt(n.Pos, s.curfn, n.Type)\n\t\ts.vars[&memVar] = s.newValue1A(ssa.OpVarDef, types.TypeMem, tmp, s.mem())\n\t\taddr = s.addr(tmp)\n\t}\n\n\tcond := s.newValue2(ssa.OpEqPtr, types.Types[TBOOL], itab, targetITab) // 比较\n\tb := s.endBlock()\n\tb.Kind = ssa.BlockIf\n\tb.SetControl(cond)\n\tb.Likely = ssa.BranchLikely\n\n\tbOk := s.f.NewBlock(ssa.BlockPlain)\n\tbFail := s.f.NewBlock(ssa.BlockPlain)\n\tb.AddEdgeTo(bOk)\n\tb.AddEdgeTo(bFail)\n\n\tif !commaok {\n\t\t// on failure, panic by calling panicdottype\n\t\ts.startBlock(bFail)\n\t\ttaddr := s.expr(n.Right.Right)\n\t\tif n.Left.Type.IsEmptyInterface() {\n\t\t\ts.rtcall(panicdottypeE, false, nil, itab, target, taddr)\n\t\t} else {\n\t\t\ts.rtcall(panicdottypeI, false, nil, itab, target, taddr)\n\t\t}\n\n\t\t// on success, return data from interface\n\t\ts.startBlock(bOk)\n\t\tif direct {\n\t\t\treturn s.newValue1(ssa.OpIData, n.Type, iface), nil\n\t\t}\n\t\tp := s.newValue1(ssa.OpIData, types.NewPtr(n.Type), iface)\n\t\treturn s.load(n.Type, p), nil // 获取idata指向的内容\n\t}\n\n\t// commaok is the more complicated case because we have\n\t// a control flow merge point.\n\tbEnd := s.f.NewBlock(ssa.BlockPlain)\n\t// Note that we need a new valVar each time (unlike okVar where we can\n\t// reuse the variable) because it might have a different type every time.\n\tvalVar := &Node{Op: ONAME, Sym: &types.Sym{Name: \"val\"}}\n\n\t// type assertion succeeded\n\ts.startBlock(bOk)\n\tif tmp == nil {\n\t\tif direct {\n\t\t\ts.vars[valVar] = s.newValue1(ssa.OpIData, n.Type, iface) // 直接获取idata\n\t\t} else {\n\t\t\tp := s.newValue1(ssa.OpIData, types.NewPtr(n.Type), iface) // idata其实是保存了初始类型的地址\n\t\t\ts.vars[valVar] = s.load(n.Type, p)                         // 根据地址获取变量\n\t\t}\n\t} else {\n\t\tp := s.newValue1(ssa.OpIData, types.NewPtr(n.Type), iface)\n\t\ts.move(n.Type, addr, p)\n\t}\n\ts.vars[&okVar] = s.constBool(true)\n\ts.endBlock()\n\tbOk.AddEdgeTo(bEnd)\n\n\t// type assertion failed\n\ts.startBlock(bFail)\n\tif tmp == nil {\n\t\ts.vars[valVar] = s.zeroVal(n.Type)\n\t} else {\n\t\ts.zero(n.Type, addr)\n\t}\n\ts.vars[&okVar] = s.constBool(false) // false变量\n\ts.endBlock()\n\tbFail.AddEdgeTo(bEnd)\n\n\t// merge point\n\ts.startBlock(bEnd)\n\tif tmp == nil {\n\t\tres = s.variable(valVar, n.Type)\n\t\tdelete(s.vars, valVar)\n\t} else {\n\t\tres = s.load(n.Type, addr)\n\t\ts.vars[&memVar] = s.newValue1A(ssa.OpVarKill, types.TypeMem, tmp, s.mem())\n\t}\n\tresok = s.variable(&okVar, types.Types[TBOOL])\n\tdelete(s.vars, &okVar)\n\treturn res, resok\n}\n\n// variable returns the value of a variable at the current location.\nfunc (s *state) variable(name *Node, t *types.Type) *ssa.Value {\n\tv := s.vars[name] // 从vars中根据name找到ssa变量\n\tif v != nil {     // 存在在当前块中被赋值的变量就返回该变量\n\t\treturn v\n\t}\n\tv = s.fwdVars[name] // 从fwdVars中根据name找到ssa变量\n\tif v != nil {       // 存在就返回该变量\n\t\treturn v\n\t}\n\n\tif s.curBlock == s.f.Entry {\n\t\t// No variable should be live at entry.\n\t\ts.Fatalf(\"Value live at entry. It shouldn't be. func %s, node %v, value %v\", s.f.Name, name, v)\n\t}\n\t// Make a FwdRef, which records a value that's live on block input.\n\t// We'll find the matching definition as part of insertPhis.\n\tv = s.newValue0A(ssa.OpFwdRef, t, name)\n\ts.fwdVars[name] = v //  没有在本块中定义的变量\n\ts.addNamedValue(name, v)\n\treturn v\n}\n\nfunc (s *state) mem() *ssa.Value {\n\treturn s.variable(&memVar, types.TypeMem)\n}\n\nfunc (s *state) addNamedValue(n *Node, v *ssa.Value) {\n\tif n.Class() == Pxxx { // n记录了一个伪变量\n\t\t// Don't track our dummy nodes (&memVar etc.).\n\t\treturn\n\t}\n\tif n.IsAutoTmp() { // 判断n是否为临时变量\n\t\t// Don't track temporary variables.\n\t\treturn\n\t}\n\tif n.Class() == PPARAMOUT { // 判断n是否为出参\n\t\t// Don't track named output values.  This prevents return values\n\t\t// from being assigned too early. See #14591 and #14762. TODO: allow this.\n\t\treturn\n\t}\n\tif n.Class() == PAUTO && n.Xoffset != 0 {\n\t\ts.Fatalf(\"AUTO var with offset %v %d\", n, n.Xoffset)\n\t}\n\tloc := ssa.LocalSlot{N: n, Type: n.Type, Off: 0} // 为n节点创建一个栈槽\n\tvalues, ok := s.f.NamedValues[loc]\n\tif !ok {\n\t\ts.f.Names = append(s.f.Names, loc) // Names中不重复存储Local槽\n\t}\n\ts.f.NamedValues[loc] = append(values, v) // ssa变量v加入到NamedValues[loc]中,表示当前的栈槽存储的values\n}\n\n// Generate a disconnected call to a runtime routine and a return.\nfunc gencallret(pp *Progs, sym *obj.LSym) *obj.Prog {\n\tp := pp.Prog(obj.ACALL)\n\tp.To.Type = obj.TYPE_MEM\n\tp.To.Name = obj.NAME_EXTERN\n\tp.To.Sym = sym\n\tp = pp.Prog(obj.ARET)\n\treturn p\n}\n\n// Branch is an unresolved branch.\ntype Branch struct {\n\tP *obj.Prog  // branch instruction\n\tB *ssa.Block // target\n}\n\n// SSAGenState contains state needed during Prog generation.\ntype SSAGenState struct {\n\tpp *Progs\n\n\t// Branches remembers all the branch instructions we've seen\n\t// and where they would like to go.\n\tBranches []Branch\n\n\t// bstart remembers where each block starts (indexed by block ID)\n\tbstart []*obj.Prog\n\n\t// 387 port: maps from SSE registers (REG_X?) to 387 registers (REG_F?)\n\tSSEto387 map[int16]int16\n\t// Some architectures require a 64-bit temporary for FP-related register shuffling. Examples include x86-387, PPC, and Sparc V8.\n\tScratchFpMem *Node\n\n\tmaxarg int64 // largest frame size for arguments to calls made by the function\n\n\t// Map from GC safe points to liveness index, generated by\n\t// liveness analysis.\n\tlivenessMap LivenessMap\n\n\t// lineRunStart records the beginning of the current run of instructions\n\t// within a single block sharing the same line number\n\t// Used to move statement marks to the beginning of such runs.\n\tlineRunStart *obj.Prog\n\n\t// wasm: The number of values on the WebAssembly stack. This is only used as a safeguard.\n\tOnWasmStackSkipped int\n}\n\n// Prog appends a new Prog.\nfunc (s *SSAGenState) Prog(as obj.As) *obj.Prog {\n\tp := s.pp.Prog(as)\n\tif ssa.LosesStmtMark(as) {\n\t\treturn p\n\t}\n\t// Float a statement start to the beginning of any same-line run.\n\t// lineRunStart is reset at block boundaries, which appears to work well.\n\tif s.lineRunStart == nil || s.lineRunStart.Pos.Line() != p.Pos.Line() {\n\t\ts.lineRunStart = p\n\t} else if p.Pos.IsStmt() == src.PosIsStmt {\n\t\ts.lineRunStart.Pos = s.lineRunStart.Pos.WithIsStmt()\n\t\tp.Pos = p.Pos.WithNotStmt()\n\t}\n\treturn p\n}\n\n// Pc returns the current Prog.\nfunc (s *SSAGenState) Pc() *obj.Prog {\n\treturn s.pp.next\n}\n\n// SetPos sets the current source position.\nfunc (s *SSAGenState) SetPos(pos src.XPos) {\n\ts.pp.pos = pos\n}\n\n// Br emits a single branch instruction and returns the instruction.\n// Not all architectures need the returned instruction, but otherwise\n// the boilerplate is common to all.\nfunc (s *SSAGenState) Br(op obj.As, target *ssa.Block) *obj.Prog {\n\tp := s.Prog(op)\n\tp.To.Type = obj.TYPE_BRANCH\n\ts.Branches = append(s.Branches, Branch{P: p, B: target})\n\treturn p\n}\n\n// DebugFriendlySetPosFrom adjusts Pos.IsStmt subject to heuristics\n// that reduce \"jumpy\" line number churn when debugging.\n// Spill/fill/copy instructions from the register allocator,\n// phi functions, and instructions with a no-pos position\n// are examples of instructions that can cause churn.\nfunc (s *SSAGenState) DebugFriendlySetPosFrom(v *ssa.Value) {\n\tswitch v.Op {\n\tcase ssa.OpPhi, ssa.OpCopy, ssa.OpLoadReg, ssa.OpStoreReg:\n\t\t// These are not statements\n\t\ts.SetPos(v.Pos.WithNotStmt())\n\tdefault:\n\t\tp := v.Pos\n\t\tif p != src.NoXPos {\n\t\t\t// If the position is defined, update the position.\n\t\t\t// Also convert default IsStmt to NotStmt; only\n\t\t\t// explicit statement boundaries should appear\n\t\t\t// in the generated code.\n\t\t\tif p.IsStmt() != src.PosIsStmt {\n\t\t\t\tp = p.WithNotStmt()\n\t\t\t\t// Calls use the pos attached to v, but copy the statement mark from SSAGenState\n\t\t\t}\n\t\t\ts.SetPos(p)\n\t\t} else {\n\t\t\ts.SetPos(s.pp.pos.WithNotStmt())\n\t\t}\n\t}\n}\n\n// byXoffset implements sort.Interface for []*Node using Xoffset as the ordering.\ntype byXoffset []*Node\n\nfunc (s byXoffset) Len() int           { return len(s) }\nfunc (s byXoffset) Less(i, j int) bool { return s[i].Xoffset < s[j].Xoffset }\nfunc (s byXoffset) Swap(i, j int)      { s[i], s[j] = s[j], s[i] }\n\nfunc emitStackObjects(e *ssafn, pp *Progs) {\n\tvar vars []*Node\n\tfor _, n := range e.curfn.Func.Dcl {\n\t\tif livenessShouldTrack(n) && n.Name.Addrtaken() {\n\t\t\tvars = append(vars, n)\n\t\t}\n\t}\n\tif len(vars) == 0 {\n\t\treturn\n\t}\n\n\t// Sort variables from lowest to highest address.\n\tsort.Sort(byXoffset(vars))\n\n\t// Populate the stack object data.\n\t// Format must match runtime/stack.go:stackObjectRecord.\n\tx := e.curfn.Func.lsym.Func.StackObjects\n\toff := 0\n\toff = duintptr(x, off, uint64(len(vars)))\n\tfor _, v := range vars {\n\t\t// Note: arguments and return values have non-negative Xoffset,\n\t\t// in which case the offset is relative to argp.\n\t\t// Locals have a negative Xoffset, in which case the offset is relative to varp.\n\t\toff = duintptr(x, off, uint64(v.Xoffset))\n\t\tif !typesym(v.Type).Siggen() {\n\t\t\te.Fatalf(v.Pos, \"stack object's type symbol not generated for type %s\", v.Type)\n\t\t}\n\t\toff = dsymptr(x, off, dtypesym(v.Type), 0)\n\t}\n\n\t// Emit a funcdata pointing at the stack object data.\n\tp := pp.Prog(obj.AFUNCDATA)\n\tAddrconst(&p.From, objabi.FUNCDATA_StackObjects)\n\tp.To.Type = obj.TYPE_MEM\n\tp.To.Name = obj.NAME_EXTERN\n\tp.To.Sym = x\n\n\tif debuglive != 0 {\n\t\tfor _, v := range vars {\n\t\t\tWarnl(v.Pos, \"stack object %v %s\", v, v.Type.String())\n\t\t}\n\t}\n}\n\n// genssa appends entries to pp for each instruction in f.\nfunc genssa(f *ssa.Func, pp *Progs) {\n\tvar s SSAGenState\n\n\te := f.Frontend().(*ssafn)\n\n\ts.livenessMap = liveness(e, f, pp)\n\temitStackObjects(e, pp)\n\n\topenDeferInfo := e.curfn.Func.lsym.Func.OpenCodedDeferInfo\n\tif openDeferInfo != nil {\n\t\t// This function uses open-coded defers -- write out the funcdata\n\t\t// info that we computed at the end of genssa.\n\t\tp := pp.Prog(obj.AFUNCDATA)\n\t\tAddrconst(&p.From, objabi.FUNCDATA_OpenCodedDeferInfo)\n\t\tp.To.Type = obj.TYPE_MEM\n\t\tp.To.Name = obj.NAME_EXTERN\n\t\tp.To.Sym = openDeferInfo\n\t}\n\n\t// Remember where each block starts.\n\ts.bstart = make([]*obj.Prog, f.NumBlocks())\n\ts.pp = pp\n\tvar progToValue map[*obj.Prog]*ssa.Value\n\tvar progToBlock map[*obj.Prog]*ssa.Block\n\tvar valueToProgAfter []*obj.Prog // The first Prog following computation of a value v; v is visible at this point.\n\tif f.PrintOrHtmlSSA {\n\t\tprogToValue = make(map[*obj.Prog]*ssa.Value, f.NumValues())\n\t\tprogToBlock = make(map[*obj.Prog]*ssa.Block, f.NumBlocks())\n\t\tf.Logf(\"genssa %s\\n\", f.Name)\n\t\tprogToBlock[s.pp.next] = f.Blocks[0]\n\t}\n\n\tif thearch.Use387 {\n\t\ts.SSEto387 = map[int16]int16{}\n\t}\n\n\ts.ScratchFpMem = e.scratchFpMem\n\n\tif Ctxt.Flag_locationlists {\n\t\tif cap(f.Cache.ValueToProgAfter) < f.NumValues() {\n\t\t\tf.Cache.ValueToProgAfter = make([]*obj.Prog, f.NumValues())\n\t\t}\n\t\tvalueToProgAfter = f.Cache.ValueToProgAfter[:f.NumValues()]\n\t\tfor i := range valueToProgAfter {\n\t\t\tvalueToProgAfter[i] = nil\n\t\t}\n\t}\n\n\t// If the very first instruction is not tagged as a statement,\n\t// debuggers may attribute it to previous function in program.\n\tfirstPos := src.NoXPos\n\tfor _, v := range f.Entry.Values { // 从entry块中找到一个statement并将position赋给firstPos\n\t\tif v.Pos.IsStmt() == src.PosIsStmt {\n\t\t\tfirstPos = v.Pos\n\t\t\tv.Pos = firstPos.WithDefaultStmt()\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// inlMarks has an entry for each Prog that implements an inline mark.\n\t// It maps from that Prog to the global inlining id of the inlined body\n\t// which should unwind to this Prog's location.\n\tvar inlMarks map[*obj.Prog]int32\n\tvar inlMarkList []*obj.Prog\n\n\t// inlMarksByPos maps from a (column 1) source position to the set of\n\t// Progs that are in the set above and have that source position.\n\tvar inlMarksByPos map[src.XPos][]*obj.Prog\n\n\t// Emit basic blocks\n\tfor i, b := range f.Blocks {\n\t\ts.bstart[b.ID] = s.pp.next // 记录b块的开始Prog\n\t\ts.lineRunStart = nil\n\n\t\t// Attach a \"default\" liveness info. Normally this will be\n\t\t// overwritten in the Values loop below for each Value. But\n\t\t// for an empty block this will be used for its control\n\t\t// instruction. We won't use the actual liveness map on a\n\t\t// control instruction. Just mark it something that is\n\t\t// preemptible, unless this function is \"all unsafe\".\n\t\ts.pp.nextLive = LivenessIndex{-1, -1, allUnsafe(f)}\n\n\t\t// Emit values in block\n\t\tthearch.SSAMarkMoves(&s, b)\n\t\tfor _, v := range b.Values {\n\t\t\tx := s.pp.next\n\t\t\ts.DebugFriendlySetPosFrom(v)\n\n\t\t\tswitch v.Op {\n\t\t\tcase ssa.OpInitMem:\n\t\t\t\t// memory arg needs no code\n\t\t\tcase ssa.OpArg:\n\t\t\t\t// input args need no code\n\t\t\tcase ssa.OpSP, ssa.OpSB:\n\t\t\t\t// nothing to do\n\t\t\tcase ssa.OpSelect0, ssa.OpSelect1:\n\t\t\t\t// nothing to do\n\t\t\tcase ssa.OpGetG:\n\t\t\t\t// nothing to do when there's a g register,\n\t\t\t\t// and checkLower complains if there's not\n\t\t\tcase ssa.OpVarDef, ssa.OpVarLive, ssa.OpKeepAlive, ssa.OpVarKill:\n\t\t\t\t// nothing to do; already used by liveness\n\t\t\tcase ssa.OpPhi:\n\t\t\t\tCheckLoweredPhi(v)\n\t\t\tcase ssa.OpConvert:\n\t\t\t\t// nothing to do; no-op conversion for liveness\n\t\t\t\tif v.Args[0].Reg() != v.Reg() {\n\t\t\t\t\tv.Fatalf(\"OpConvert should be a no-op: %s; %s\", v.Args[0].LongString(), v.LongString())\n\t\t\t\t}\n\t\t\tcase ssa.OpInlMark:\n\t\t\t\tp := thearch.Ginsnop(s.pp)\n\t\t\t\tif inlMarks == nil {\n\t\t\t\t\tinlMarks = map[*obj.Prog]int32{}\n\t\t\t\t\tinlMarksByPos = map[src.XPos][]*obj.Prog{}\n\t\t\t\t}\n\t\t\t\tinlMarks[p] = v.AuxInt32()\n\t\t\t\tinlMarkList = append(inlMarkList, p)\n\t\t\t\tpos := v.Pos.AtColumn1()\n\t\t\t\tinlMarksByPos[pos] = append(inlMarksByPos[pos], p)\n\n\t\t\tdefault:\n\t\t\t\t// Attach this safe point to the next\n\t\t\t\t// instruction.\n\t\t\t\ts.pp.nextLive = s.livenessMap.Get(v)\n\n\t\t\t\t// Special case for first line in function; move it to the start.\n\t\t\t\tif firstPos != src.NoXPos {\n\t\t\t\t\ts.SetPos(firstPos)\n\t\t\t\t\tfirstPos = src.NoXPos\n\t\t\t\t}\n\t\t\t\t// let the backend handle it\n\t\t\t\tthearch.SSAGenValue(&s, v)\n\t\t\t}\n\n\t\t\tif Ctxt.Flag_locationlists {\n\t\t\t\tvalueToProgAfter[v.ID] = s.pp.next\n\t\t\t}\n\n\t\t\tif f.PrintOrHtmlSSA {\n\t\t\t\tfor ; x != s.pp.next; x = x.Link {\n\t\t\t\t\tprogToValue[x] = v\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// If this is an empty infinite loop, stick a hardware NOP in there so that debuggers are less confused.\n\t\tif s.bstart[b.ID] == s.pp.next && len(b.Succs) == 1 && b.Succs[0].Block() == b {\n\t\t\tp := thearch.Ginsnop(s.pp)\n\t\t\tp.Pos = p.Pos.WithIsStmt()\n\t\t\tif b.Pos == src.NoXPos {\n\t\t\t\tb.Pos = p.Pos // It needs a file, otherwise a no-file non-zero line causes confusion.  See #35652.\n\t\t\t\tif b.Pos == src.NoXPos {\n\t\t\t\t\tb.Pos = pp.Text.Pos // Sometimes p.Pos is empty.  See #35695.\n\t\t\t\t}\n\t\t\t}\n\t\t\tb.Pos = b.Pos.WithBogusLine() // Debuggers are not good about infinite loops, force a change in line number\n\t\t}\n\t\t// Emit control flow instructions for block\n\t\tvar next *ssa.Block\n\t\tif i < len(f.Blocks)-1 && Debug['N'] == 0 {\n\t\t\t// If -N, leave next==nil so every block with successors\n\t\t\t// ends in a JMP (except call blocks - plive doesn't like\n\t\t\t// select{send,recv} followed by a JMP call).  Helps keep\n\t\t\t// line numbers for otherwise empty blocks.\n\t\t\tnext = f.Blocks[i+1]\n\t\t}\n\t\tx := s.pp.next\n\t\ts.SetPos(b.Pos)\n\t\tthearch.SSAGenBlock(&s, b, next)\n\t\tif f.PrintOrHtmlSSA {\n\t\t\tfor ; x != s.pp.next; x = x.Link {\n\t\t\t\tprogToBlock[x] = b\n\t\t\t}\n\t\t}\n\t}\n\tif f.Blocks[len(f.Blocks)-1].Kind == ssa.BlockExit {\n\t\t// We need the return address of a panic call to\n\t\t// still be inside the function in question. So if\n\t\t// it ends in a call which doesn't return, add a\n\t\t// nop (which will never execute) after the call.\n\t\tthearch.Ginsnop(pp)\n\t}\n\tif openDeferInfo != nil {\n\t\t// When doing open-coded defers, generate a disconnected call to\n\t\t// deferreturn and a return. This will be used to during panic\n\t\t// recovery to unwind the stack and return back to the runtime.\n\t\ts.pp.nextLive = s.livenessMap.deferreturn\n\t\tgencallret(pp, Deferreturn)\n\t}\n\n\tif inlMarks != nil {\n\t\t// We have some inline marks. Try to find other instructions we're\n\t\t// going to emit anyway, and use those instructions instead of the\n\t\t// inline marks.\n\t\tfor p := pp.Text; p != nil; p = p.Link {\n\t\t\tif p.As == obj.ANOP || p.As == obj.AFUNCDATA || p.As == obj.APCDATA || p.As == obj.ATEXT || p.As == obj.APCALIGN || thearch.LinkArch.Family == sys.Wasm {\n\t\t\t\t// Don't use 0-sized instructions as inline marks, because we need\n\t\t\t\t// to identify inline mark instructions by pc offset.\n\t\t\t\t// (Some of these instructions are sometimes zero-sized, sometimes not.\n\t\t\t\t// We must not use anything that even might be zero-sized.)\n\t\t\t\t// TODO: are there others?\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif _, ok := inlMarks[p]; ok {\n\t\t\t\t// Don't use inline marks themselves. We don't know\n\t\t\t\t// whether they will be zero-sized or not yet.\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tpos := p.Pos.AtColumn1()\n\t\t\ts := inlMarksByPos[pos]\n\t\t\tif len(s) == 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, m := range s {\n\t\t\t\t// We found an instruction with the same source position as\n\t\t\t\t// some of the inline marks.\n\t\t\t\t// Use this instruction instead.\n\t\t\t\tp.Pos = p.Pos.WithIsStmt() // promote position to a statement\n\t\t\t\tpp.curfn.Func.lsym.Func.AddInlMark(p, inlMarks[m])\n\t\t\t\t// Make the inline mark a real nop, so it doesn't generate any code.\n\t\t\t\tm.As = obj.ANOP\n\t\t\t\tm.Pos = src.NoXPos\n\t\t\t\tm.From = obj.Addr{}\n\t\t\t\tm.To = obj.Addr{}\n\t\t\t}\n\t\t\tdelete(inlMarksByPos, pos)\n\t\t}\n\t\t// Any unmatched inline marks now need to be added to the inlining tree (and will generate a nop instruction).\n\t\tfor _, p := range inlMarkList {\n\t\t\tif p.As != obj.ANOP {\n\t\t\t\tpp.curfn.Func.lsym.Func.AddInlMark(p, inlMarks[p])\n\t\t\t}\n\t\t}\n\t}\n\n\tif Ctxt.Flag_locationlists {\n\t\te.curfn.Func.DebugInfo = ssa.BuildFuncDebug(Ctxt, f, Debug_locationlist > 1, stackOffset)\n\t\tbstart := s.bstart\n\t\t// Note that at this moment, Prog.Pc is a sequence number; it's\n\t\t// not a real PC until after assembly, so this mapping has to\n\t\t// be done later.\n\t\te.curfn.Func.DebugInfo.GetPC = func(b, v ssa.ID) int64 {\n\t\t\tswitch v {\n\t\t\tcase ssa.BlockStart.ID:\n\t\t\t\tif b == f.Entry.ID {\n\t\t\t\t\treturn 0 // Start at the very beginning, at the assembler-generated prologue.\n\t\t\t\t\t// this should only happen for function args (ssa.OpArg)\n\t\t\t\t}\n\t\t\t\treturn bstart[b].Pc\n\t\t\tcase ssa.BlockEnd.ID:\n\t\t\t\treturn e.curfn.Func.lsym.Size\n\t\t\tdefault:\n\t\t\t\treturn valueToProgAfter[v].Pc\n\t\t\t}\n\t\t}\n\t}\n\n\t// Resolve branches, and relax DefaultStmt into NotStmt\n\tfor _, br := range s.Branches {\n\t\tbr.P.To.Val = s.bstart[br.B.ID]\n\t\tif br.P.Pos.IsStmt() != src.PosIsStmt {\n\t\t\tbr.P.Pos = br.P.Pos.WithNotStmt()\n\t\t} else if v0 := br.B.FirstPossibleStmtValue(); v0 != nil && v0.Pos.Line() == br.P.Pos.Line() && v0.Pos.IsStmt() == src.PosIsStmt {\n\t\t\tbr.P.Pos = br.P.Pos.WithNotStmt()\n\t\t}\n\n\t}\n\n\tif e.log { // spew to stdout\n\t\tfilename := \"\"\n\t\tfor p := pp.Text; p != nil; p = p.Link {\n\t\t\tif p.Pos.IsKnown() && p.InnermostFilename() != filename {\n\t\t\t\tfilename = p.InnermostFilename()\n\t\t\t\tf.Logf(\"# %s\\n\", filename)\n\t\t\t}\n\n\t\t\tvar s string\n\t\t\tif v, ok := progToValue[p]; ok {\n\t\t\t\ts = v.String()\n\t\t\t} else if b, ok := progToBlock[p]; ok {\n\t\t\t\ts = b.String()\n\t\t\t} else {\n\t\t\t\ts = \"   \" // most value and branch strings are 2-3 characters long\n\t\t\t}\n\t\t\tf.Logf(\" %-6s\\t%.5d (%s)\\t%s\\n\", s, p.Pc, p.InnermostLineNumber(), p.InstructionString())\n\t\t}\n\t}\n\tif f.HTMLWriter != nil { // spew to ssa.html\n\t\tvar buf bytes.Buffer\n\t\tbuf.WriteString(\"<code>\")\n\t\tbuf.WriteString(\"<dl class=\\\"ssa-gen\\\">\")\n\t\tfilename := \"\"\n\t\tfor p := pp.Text; p != nil; p = p.Link {\n\t\t\t// Don't spam every line with the file name, which is often huge.\n\t\t\t// Only print changes, and \"unknown\" is not a change.\n\t\t\tif p.Pos.IsKnown() && p.InnermostFilename() != filename {\n\t\t\t\tfilename = p.InnermostFilename()\n\t\t\t\tbuf.WriteString(\"<dt class=\\\"ssa-prog-src\\\"></dt><dd class=\\\"ssa-prog\\\">\")\n\t\t\t\tbuf.WriteString(html.EscapeString(\"# \" + filename))\n\t\t\t\tbuf.WriteString(\"</dd>\")\n\t\t\t}\n\n\t\t\tbuf.WriteString(\"<dt class=\\\"ssa-prog-src\\\">\")\n\t\t\tif v, ok := progToValue[p]; ok {\n\t\t\t\tbuf.WriteString(v.HTML())\n\t\t\t} else if b, ok := progToBlock[p]; ok {\n\t\t\t\tbuf.WriteString(\"<b>\" + b.HTML() + \"</b>\")\n\t\t\t}\n\t\t\tbuf.WriteString(\"</dt>\")\n\t\t\tbuf.WriteString(\"<dd class=\\\"ssa-prog\\\">\")\n\t\t\tbuf.WriteString(fmt.Sprintf(\"%.5d <span class=\\\"l%v line-number\\\">(%s)</span> %s\", p.Pc, p.InnermostLineNumber(), p.InnermostLineNumberHTML(), html.EscapeString(p.InstructionString())))\n\t\t\tbuf.WriteString(\"</dd>\")\n\t\t}\n\t\tbuf.WriteString(\"</dl>\")\n\t\tbuf.WriteString(\"</code>\")\n\t\tf.HTMLWriter.WriteColumn(\"genssa\", \"genssa\", \"ssa-prog\", buf.String())\n\t}\n\n\tdefframe(&s, e)\n\n\tf.HTMLWriter.Close()\n\tf.HTMLWriter = nil\n}\n\nfunc defframe(s *SSAGenState, e *ssafn) {\n\tpp := s.pp\n\n\tframe := Rnd(s.maxarg+e.stksize, int64(Widthreg))\n\tif thearch.PadFrame != nil {\n\t\tframe = thearch.PadFrame(frame)\n\t}\n\n\t// Fill in argument and frame size.\n\tpp.Text.To.Type = obj.TYPE_TEXTSIZE\n\tpp.Text.To.Val = int32(Rnd(e.curfn.Type.ArgWidth(), int64(Widthreg)))\n\tpp.Text.To.Offset = frame\n\n\t// Insert code to zero ambiguously live variables so that the\n\t// garbage collector only sees initialized values when it\n\t// looks for pointers.\n\tp := pp.Text\n\tvar lo, hi int64\n\n\t// Opaque state for backend to use. Current backends use it to\n\t// keep track of which helper registers have been zeroed.\n\tvar state uint32\n\n\t// Iterate through declarations. They are sorted in decreasing Xoffset order.\n\tfor _, n := range e.curfn.Func.Dcl {\n\t\tif !n.Name.Needzero() {\n\t\t\tcontinue\n\t\t}\n\t\tif n.Class() != PAUTO {\n\t\t\te.Fatalf(n.Pos, \"needzero class %d\", n.Class())\n\t\t}\n\t\tif n.Type.Size()%int64(Widthptr) != 0 || n.Xoffset%int64(Widthptr) != 0 || n.Type.Size() == 0 {\n\t\t\te.Fatalf(n.Pos, \"var %L has size %d offset %d\", n, n.Type.Size(), n.Xoffset)\n\t\t}\n\n\t\tif lo != hi && n.Xoffset+n.Type.Size() >= lo-int64(2*Widthreg) {\n\t\t\t// Merge with range we already have.\n\t\t\tlo = n.Xoffset\n\t\t\tcontinue\n\t\t}\n\n\t\t// Zero old range\n\t\tp = thearch.ZeroRange(pp, p, frame+lo, hi-lo, &state)\n\n\t\t// Set new range.\n\t\tlo = n.Xoffset\n\t\thi = lo + n.Type.Size()\n\t}\n\n\t// Zero final range.\n\tthearch.ZeroRange(pp, p, frame+lo, hi-lo, &state)\n}\n\n// For generating consecutive jump instructions to model a specific branching\ntype IndexJump struct {\n\tJump  obj.As\n\tIndex int\n}\n\nfunc (s *SSAGenState) oneJump(b *ssa.Block, jump *IndexJump) {\n\tp := s.Br(jump.Jump, b.Succs[jump.Index].Block())\n\tp.Pos = b.Pos\n}\n\n// CombJump generates combinational instructions (2 at present) for a block jump,\n// thereby the behaviour of non-standard condition codes could be simulated\nfunc (s *SSAGenState) CombJump(b, next *ssa.Block, jumps *[2][2]IndexJump) {\n\tswitch next {\n\tcase b.Succs[0].Block():\n\t\ts.oneJump(b, &jumps[0][0])\n\t\ts.oneJump(b, &jumps[0][1])\n\tcase b.Succs[1].Block():\n\t\ts.oneJump(b, &jumps[1][0])\n\t\ts.oneJump(b, &jumps[1][1])\n\tdefault:\n\t\tvar q *obj.Prog\n\t\tif b.Likely != ssa.BranchUnlikely {\n\t\t\ts.oneJump(b, &jumps[1][0])\n\t\t\ts.oneJump(b, &jumps[1][1])\n\t\t\tq = s.Br(obj.AJMP, b.Succs[1].Block())\n\t\t} else {\n\t\t\ts.oneJump(b, &jumps[0][0])\n\t\t\ts.oneJump(b, &jumps[0][1])\n\t\t\tq = s.Br(obj.AJMP, b.Succs[0].Block())\n\t\t}\n\t\tq.Pos = b.Pos\n\t}\n}\n\n// AddAux adds the offset in the aux fields (AuxInt and Aux) of v to a.\nfunc AddAux(a *obj.Addr, v *ssa.Value) {\n\tAddAux2(a, v, v.AuxInt)\n}\nfunc AddAux2(a *obj.Addr, v *ssa.Value, offset int64) {\n\tif a.Type != obj.TYPE_MEM && a.Type != obj.TYPE_ADDR {\n\t\tv.Fatalf(\"bad AddAux addr %v\", a)\n\t}\n\t// add integer offset\n\ta.Offset += offset\n\n\t// If no additional symbol offset, we're done.\n\tif v.Aux == nil {\n\t\treturn\n\t}\n\t// Add symbol's offset from its base register.\n\tswitch n := v.Aux.(type) {\n\tcase *obj.LSym:\n\t\ta.Name = obj.NAME_EXTERN\n\t\ta.Sym = n\n\tcase *Node:\n\t\tif n.Class() == PPARAM || n.Class() == PPARAMOUT {\n\t\t\ta.Name = obj.NAME_PARAM\n\t\t\ta.Sym = n.Orig.Sym.Linksym()\n\t\t\ta.Offset += n.Xoffset\n\t\t\tbreak\n\t\t}\n\t\ta.Name = obj.NAME_AUTO\n\t\ta.Sym = n.Sym.Linksym()\n\t\ta.Offset += n.Xoffset\n\tdefault:\n\t\tv.Fatalf(\"aux in %s not implemented %#v\", v, v.Aux)\n\t}\n}\n\n// extendIndex extends v to a full int width.\n// panic with the given kind if v does not fit in an int (only on 32-bit archs).\nfunc (s *state) extendIndex(idx, len *ssa.Value, kind ssa.BoundsKind, bounded bool) *ssa.Value {\n\tsize := idx.Type.Size()\n\tif size == s.config.PtrSize {\n\t\treturn idx\n\t}\n\tif size > s.config.PtrSize { // 索引类型大于int的字节长度,此时当前程序只能为32位\n\t\t// truncate 64-bit indexes on 32-bit pointer archs. Test the\n\t\t// high word and branch to out-of-bounds failure if it is not 0.\n\t\tvar lo *ssa.Value\n\t\tif idx.Type.IsSigned() { // 判断idx是否为有符号数\n\t\t\tlo = s.newValue1(ssa.OpInt64Lo, types.Types[TINT], idx)\n\t\t} else {\n\t\t\tlo = s.newValue1(ssa.OpInt64Lo, types.Types[TUINT], idx)\n\t\t}\n\t\tif bounded || Debug['B'] != 0 { // 不做数组越界检查的情况\n\t\t\treturn lo\n\t\t}\n\t\tbNext := s.f.NewBlock(ssa.BlockPlain)\n\t\tbPanic := s.f.NewBlock(ssa.BlockExit)\n\t\thi := s.newValue1(ssa.OpInt64Hi, types.Types[TUINT32], idx)\n\t\tcmp := s.newValue2(ssa.OpEq32, types.Types[TBOOL], hi, s.constInt32(types.Types[TUINT32], 0))\n\t\tif !idx.Type.IsSigned() {\n\t\t\tswitch kind {\n\t\t\tcase ssa.BoundsIndex:\n\t\t\t\tkind = ssa.BoundsIndexU\n\t\t\tcase ssa.BoundsSliceAlen:\n\t\t\t\tkind = ssa.BoundsSliceAlenU\n\t\t\tcase ssa.BoundsSliceAcap:\n\t\t\t\tkind = ssa.BoundsSliceAcapU\n\t\t\tcase ssa.BoundsSliceB:\n\t\t\t\tkind = ssa.BoundsSliceBU\n\t\t\tcase ssa.BoundsSlice3Alen:\n\t\t\t\tkind = ssa.BoundsSlice3AlenU\n\t\t\tcase ssa.BoundsSlice3Acap:\n\t\t\t\tkind = ssa.BoundsSlice3AcapU\n\t\t\tcase ssa.BoundsSlice3B:\n\t\t\t\tkind = ssa.BoundsSlice3BU\n\t\t\tcase ssa.BoundsSlice3C:\n\t\t\t\tkind = ssa.BoundsSlice3CU\n\t\t\t}\n\t\t}\n\t\tb := s.endBlock()\n\t\tb.Kind = ssa.BlockIf\n\t\tb.SetControl(cmp)\n\t\tb.Likely = ssa.BranchLikely\n\t\tb.AddEdgeTo(bNext)\n\t\tb.AddEdgeTo(bPanic)\n\n\t\ts.startBlock(bPanic)\n\t\tmem := s.newValue4I(ssa.OpPanicExtend, types.TypeMem, int64(kind), hi, lo, len, s.mem())\n\t\ts.endBlock().SetControl(mem)\n\t\ts.startBlock(bNext)\n\n\t\treturn lo\n\t}\n\n\t// Extend value to the required size\n\tvar op ssa.Op\n\tif idx.Type.IsSigned() {\n\t\tswitch 10*size + s.config.PtrSize {\n\t\tcase 14:\n\t\t\top = ssa.OpSignExt8to32\n\t\tcase 18:\n\t\t\top = ssa.OpSignExt8to64\n\t\tcase 24:\n\t\t\top = ssa.OpSignExt16to32\n\t\tcase 28:\n\t\t\top = ssa.OpSignExt16to64\n\t\tcase 48:\n\t\t\top = ssa.OpSignExt32to64\n\t\tdefault:\n\t\t\ts.Fatalf(\"bad signed index extension %s\", idx.Type)\n\t\t}\n\t} else {\n\t\tswitch 10*size + s.config.PtrSize {\n\t\tcase 14:\n\t\t\top = ssa.OpZeroExt8to32\n\t\tcase 18:\n\t\t\top = ssa.OpZeroExt8to64\n\t\tcase 24:\n\t\t\top = ssa.OpZeroExt16to32\n\t\tcase 28:\n\t\t\top = ssa.OpZeroExt16to64\n\t\tcase 48:\n\t\t\top = ssa.OpZeroExt32to64\n\t\tdefault:\n\t\t\ts.Fatalf(\"bad unsigned index extension %s\", idx.Type)\n\t\t}\n\t}\n\treturn s.newValue1(op, types.Types[TINT], idx)\n}\n\n// CheckLoweredPhi checks that regalloc and stackalloc correctly handled phi values.\n// Called during ssaGenValue.\nfunc CheckLoweredPhi(v *ssa.Value) {\n\tif v.Op != ssa.OpPhi {\n\t\tv.Fatalf(\"CheckLoweredPhi called with non-phi value: %v\", v.LongString())\n\t}\n\tif v.Type.IsMemory() {\n\t\treturn\n\t}\n\tf := v.Block.Func\n\tloc := f.RegAlloc[v.ID]\n\tfor _, a := range v.Args {\n\t\tif aloc := f.RegAlloc[a.ID]; aloc != loc { // TODO: .Equal() instead?\n\t\t\tv.Fatalf(\"phi arg at different location than phi: %v @ %s, but arg %v @ %s\\n%s\\n\", v, loc, a, aloc, v.Block.Func)\n\t\t}\n\t}\n}\n\n// CheckLoweredGetClosurePtr checks that v is the first instruction in the function's entry block.\n// The output of LoweredGetClosurePtr is generally hardwired to the correct register.\n// That register contains the closure pointer on closure entry.\nfunc CheckLoweredGetClosurePtr(v *ssa.Value) {\n\tentry := v.Block.Func.Entry\n\tif entry != v.Block || entry.Values[0] != v {\n\t\tFatalf(\"in %s, badly placed LoweredGetClosurePtr: %v %v\", v.Block.Func.Name, v.Block, v)\n\t}\n}\n\n// AutoVar returns a *Node and int64 representing the auto variable and offset within it\n// where v should be spilled.\nfunc AutoVar(v *ssa.Value) (*Node, int64) {\n\tloc := v.Block.Func.RegAlloc[v.ID].(ssa.LocalSlot)\n\tif v.Type.Size() > loc.Type.Size() {\n\t\tv.Fatalf(\"spill/restore type %s doesn't fit in slot type %s\", v.Type, loc.Type)\n\t}\n\treturn loc.N.(*Node), loc.Off\n}\n\nfunc AddrAuto(a *obj.Addr, v *ssa.Value) {\n\tn, off := AutoVar(v)\n\ta.Type = obj.TYPE_MEM\n\ta.Sym = n.Sym.Linksym()\n\ta.Reg = int16(thearch.REGSP)\n\ta.Offset = n.Xoffset + off\n\tif n.Class() == PPARAM || n.Class() == PPARAMOUT {\n\t\ta.Name = obj.NAME_PARAM\n\t} else {\n\t\ta.Name = obj.NAME_AUTO\n\t}\n}\n\nfunc (s *SSAGenState) AddrScratch(a *obj.Addr) {\n\tif s.ScratchFpMem == nil {\n\t\tpanic(\"no scratch memory available; forgot to declare usesScratch for Op?\")\n\t}\n\ta.Type = obj.TYPE_MEM\n\ta.Name = obj.NAME_AUTO\n\ta.Sym = s.ScratchFpMem.Sym.Linksym()\n\ta.Reg = int16(thearch.REGSP)\n\ta.Offset = s.ScratchFpMem.Xoffset\n}\n\n// Call returns a new CALL instruction for the SSA value v.\n// It uses PrepareCall to prepare the call.\nfunc (s *SSAGenState) Call(v *ssa.Value) *obj.Prog {\n\tpPosIsStmt := s.pp.pos.IsStmt() // The statement-ness fo the call comes from ssaGenState\n\ts.PrepareCall(v)\n\n\tp := s.Prog(obj.ACALL)\n\tif pPosIsStmt == src.PosIsStmt {\n\t\tp.Pos = v.Pos.WithIsStmt()\n\t} else {\n\t\tp.Pos = v.Pos.WithNotStmt()\n\t}\n\tif sym, ok := v.Aux.(*obj.LSym); ok {\n\t\tp.To.Type = obj.TYPE_MEM\n\t\tp.To.Name = obj.NAME_EXTERN\n\t\tp.To.Sym = sym\n\t} else {\n\t\t// TODO(mdempsky): Can these differences be eliminated?\n\t\tswitch thearch.LinkArch.Family {\n\t\tcase sys.AMD64, sys.I386, sys.PPC64, sys.RISCV64, sys.S390X, sys.Wasm:\n\t\t\tp.To.Type = obj.TYPE_REG\n\t\tcase sys.ARM, sys.ARM64, sys.MIPS, sys.MIPS64:\n\t\t\tp.To.Type = obj.TYPE_MEM\n\t\tdefault:\n\t\t\tFatalf(\"unknown indirect call family\")\n\t\t}\n\t\tp.To.Reg = v.Args[0].Reg()\n\t}\n\treturn p\n}\n\n// PrepareCall prepares to emit a CALL instruction for v and does call-related bookkeeping.\n// It must be called immediately before emitting the actual CALL instruction,\n// since it emits PCDATA for the stack map at the call (calls are safe points).\nfunc (s *SSAGenState) PrepareCall(v *ssa.Value) {\n\tidx := s.livenessMap.Get(v)\n\tif !idx.StackMapValid() {\n\t\t// See Liveness.hasStackMap.\n\t\tif sym, _ := v.Aux.(*obj.LSym); !(sym == typedmemclr || sym == typedmemmove) {\n\t\t\tFatalf(\"missing stack map index for %v\", v.LongString())\n\t\t}\n\t}\n\n\tif sym, _ := v.Aux.(*obj.LSym); sym == Deferreturn {\n\t\t// Deferred calls will appear to be returning to\n\t\t// the CALL deferreturn(SB) that we are about to emit.\n\t\t// However, the stack trace code will show the line\n\t\t// of the instruction byte before the return PC.\n\t\t// To avoid that being an unrelated instruction,\n\t\t// insert an actual hardware NOP that will have the right line number.\n\t\t// This is different from obj.ANOP, which is a virtual no-op\n\t\t// that doesn't make it into the instruction stream.\n\t\tthearch.Ginsnopdefer(s.pp)\n\t}\n\n\tif sym, ok := v.Aux.(*obj.LSym); ok {\n\t\t// Record call graph information for nowritebarrierrec\n\t\t// analysis.\n\t\tif nowritebarrierrecCheck != nil {\n\t\t\tnowritebarrierrecCheck.recordCall(s.pp.curfn, sym, v.Pos)\n\t\t}\n\t}\n\n\tif s.maxarg < v.AuxInt {\n\t\ts.maxarg = v.AuxInt\n\t}\n}\n\n// UseArgs records the fact that an instruction needs a certain amount of\n// callee args space for its use.\nfunc (s *SSAGenState) UseArgs(n int64) {\n\tif s.maxarg < n {\n\t\ts.maxarg = n\n\t}\n}\n\n// fieldIdx finds the index of the field referred to by the ODOT node n.\nfunc fieldIdx(n *Node) int {\n\tt := n.Left.Type // 结构体类型\n\tf := n.Sym       // 结构体字段名\n\tif !t.IsStruct() {\n\t\tpanic(\"ODOT's LHS is not a struct\")\n\t}\n\n\tvar i int\n\tfor _, t1 := range t.Fields().Slice() {\n\t\tif t1.Sym != f {\n\t\t\ti++\n\t\t\tcontinue\n\t\t}\n\t\tif t1.Offset != n.Xoffset {\n\t\t\tpanic(\"field offset doesn't match\")\n\t\t}\n\t\treturn i\n\t}\n\tpanic(fmt.Sprintf(\"can't find field in expr %v\\n\", n))\n\n\t// TODO: keep the result of this function somewhere in the ODOT Node\n\t// so we don't have to recompute it each time we need it.\n}\n\n// ssafn holds frontend information about a function that the backend is processing.\n// It also exports a bunch of compiler services for the ssa backend.\ntype ssafn struct {\n\tcurfn        *Node\n\tstrings      map[string]*obj.LSym // map from constant string to data symbols\n\tscratchFpMem *Node                // temp for floating point register / memory moves on some architectures\n\tstksize      int64                // stack size for current frame\n\tstkptrsize   int64                // prefix of stack containing pointers\n\tlog          bool                 // print ssa debug to the stdout\n}\n\n// StringData returns a symbol which\n// is the data component of a global string constant containing s.\nfunc (e *ssafn) StringData(s string) *obj.LSym {\n\tif aux, ok := e.strings[s]; ok {\n\t\treturn aux\n\t}\n\tif e.strings == nil {\n\t\te.strings = make(map[string]*obj.LSym)\n\t}\n\tdata := stringsym(e.curfn.Pos, s)\n\te.strings[s] = data\n\treturn data\n}\n\nfunc (e *ssafn) Auto(pos src.XPos, t *types.Type) ssa.GCNode {\n\tn := tempAt(pos, e.curfn, t) // Note: adds new auto to e.curfn.Func.Dcl list\n\treturn n\n}\n\nfunc (e *ssafn) SplitString(name ssa.LocalSlot) (ssa.LocalSlot, ssa.LocalSlot) {\n\tn := name.N.(*Node)\n\tptrType := types.NewPtr(types.Types[TUINT8])\n\tlenType := types.Types[TINT]\n\tif n.Class() == PAUTO && !n.Name.Addrtaken() {\n\t\t// Split this string up into two separate variables.\n\t\tp := e.splitSlot(&name, \".ptr\", 0, ptrType)\n\t\tl := e.splitSlot(&name, \".len\", ptrType.Size(), lenType)\n\t\treturn p, l\n\t}\n\t// Return the two parts of the larger variable.\n\treturn ssa.LocalSlot{N: n, Type: ptrType, Off: name.Off}, ssa.LocalSlot{N: n, Type: lenType, Off: name.Off + int64(Widthptr)}\n}\n\nfunc (e *ssafn) SplitInterface(name ssa.LocalSlot) (ssa.LocalSlot, ssa.LocalSlot) {\n\tn := name.N.(*Node)\n\tu := types.Types[TUINTPTR]\n\tt := types.NewPtr(types.Types[TUINT8])\n\tif n.Class() == PAUTO && !n.Name.Addrtaken() {\n\t\t// Split this interface up into two separate variables.\n\t\tf := \".itab\"\n\t\tif n.Type.IsEmptyInterface() {\n\t\t\tf = \".type\"\n\t\t}\n\t\tc := e.splitSlot(&name, f, 0, u) // see comment in plive.go:onebitwalktype1.\n\t\td := e.splitSlot(&name, \".data\", u.Size(), t)\n\t\treturn c, d\n\t}\n\t// Return the two parts of the larger variable.\n\treturn ssa.LocalSlot{N: n, Type: u, Off: name.Off}, ssa.LocalSlot{N: n, Type: t, Off: name.Off + int64(Widthptr)}\n}\n\nfunc (e *ssafn) SplitSlice(name ssa.LocalSlot) (ssa.LocalSlot, ssa.LocalSlot, ssa.LocalSlot) {\n\tn := name.N.(*Node)\n\tptrType := types.NewPtr(name.Type.Elem())\n\tlenType := types.Types[TINT]\n\tif n.Class() == PAUTO && !n.Name.Addrtaken() {\n\t\t// Split this slice up into three separate variables.\n\t\tp := e.splitSlot(&name, \".ptr\", 0, ptrType)\n\t\tl := e.splitSlot(&name, \".len\", ptrType.Size(), lenType)\n\t\tc := e.splitSlot(&name, \".cap\", ptrType.Size()+lenType.Size(), lenType)\n\t\treturn p, l, c\n\t}\n\t// Return the three parts of the larger variable.\n\treturn ssa.LocalSlot{N: n, Type: ptrType, Off: name.Off},\n\t\tssa.LocalSlot{N: n, Type: lenType, Off: name.Off + int64(Widthptr)},\n\t\tssa.LocalSlot{N: n, Type: lenType, Off: name.Off + int64(2*Widthptr)}\n}\n\nfunc (e *ssafn) SplitComplex(name ssa.LocalSlot) (ssa.LocalSlot, ssa.LocalSlot) {\n\tn := name.N.(*Node)\n\ts := name.Type.Size() / 2\n\tvar t *types.Type\n\tif s == 8 {\n\t\tt = types.Types[TFLOAT64]\n\t} else {\n\t\tt = types.Types[TFLOAT32]\n\t}\n\tif n.Class() == PAUTO && !n.Name.Addrtaken() {\n\t\t// Split this complex up into two separate variables.\n\t\tr := e.splitSlot(&name, \".real\", 0, t)\n\t\ti := e.splitSlot(&name, \".imag\", t.Size(), t)\n\t\treturn r, i\n\t}\n\t// Return the two parts of the larger variable.\n\treturn ssa.LocalSlot{N: n, Type: t, Off: name.Off}, ssa.LocalSlot{N: n, Type: t, Off: name.Off + s}\n}\n\nfunc (e *ssafn) SplitInt64(name ssa.LocalSlot) (ssa.LocalSlot, ssa.LocalSlot) {\n\tn := name.N.(*Node)\n\tvar t *types.Type\n\tif name.Type.IsSigned() {\n\t\tt = types.Types[TINT32]\n\t} else {\n\t\tt = types.Types[TUINT32]\n\t}\n\tif n.Class() == PAUTO && !n.Name.Addrtaken() {\n\t\t// Split this int64 up into two separate variables.\n\t\tif thearch.LinkArch.ByteOrder == binary.BigEndian {\n\t\t\treturn e.splitSlot(&name, \".hi\", 0, t), e.splitSlot(&name, \".lo\", t.Size(), types.Types[TUINT32])\n\t\t}\n\t\treturn e.splitSlot(&name, \".hi\", t.Size(), t), e.splitSlot(&name, \".lo\", 0, types.Types[TUINT32])\n\t}\n\t// Return the two parts of the larger variable.\n\tif thearch.LinkArch.ByteOrder == binary.BigEndian {\n\t\treturn ssa.LocalSlot{N: n, Type: t, Off: name.Off}, ssa.LocalSlot{N: n, Type: types.Types[TUINT32], Off: name.Off + 4}\n\t}\n\treturn ssa.LocalSlot{N: n, Type: t, Off: name.Off + 4}, ssa.LocalSlot{N: n, Type: types.Types[TUINT32], Off: name.Off}\n}\n\nfunc (e *ssafn) SplitStruct(name ssa.LocalSlot, i int) ssa.LocalSlot {\n\tn := name.N.(*Node)\n\tst := name.Type\n\tft := st.FieldType(i)\n\tvar offset int64\n\tfor f := 0; f < i; f++ {\n\t\toffset += st.FieldType(f).Size()\n\t}\n\tif n.Class() == PAUTO && !n.Name.Addrtaken() {\n\t\t// Note: the _ field may appear several times.  But\n\t\t// have no fear, identically-named but distinct Autos are\n\t\t// ok, albeit maybe confusing for a debugger.\n\t\treturn e.splitSlot(&name, \".\"+st.FieldName(i), offset, ft)\n\t}\n\treturn ssa.LocalSlot{N: n, Type: ft, Off: name.Off + st.FieldOff(i)}\n}\n\nfunc (e *ssafn) SplitArray(name ssa.LocalSlot) ssa.LocalSlot {\n\tn := name.N.(*Node)\n\tat := name.Type\n\tif at.NumElem() != 1 {\n\t\te.Fatalf(n.Pos, \"bad array size\")\n\t}\n\tet := at.Elem()\n\tif n.Class() == PAUTO && !n.Name.Addrtaken() {\n\t\treturn e.splitSlot(&name, \"[0]\", 0, et)\n\t}\n\treturn ssa.LocalSlot{N: n, Type: et, Off: name.Off}\n}\n\nfunc (e *ssafn) DerefItab(it *obj.LSym, offset int64) *obj.LSym {\n\treturn itabsym(it, offset)\n}\n\n// splitSlot returns a slot representing the data of parent starting at offset.\nfunc (e *ssafn) splitSlot(parent *ssa.LocalSlot, suffix string, offset int64, t *types.Type) ssa.LocalSlot {\n\ts := &types.Sym{Name: parent.N.(*Node).Sym.Name + suffix, Pkg: localpkg}\n\n\tn := &Node{\n\t\tName: new(Name),\n\t\tOp:   ONAME,\n\t\tPos:  parent.N.(*Node).Pos,\n\t}\n\tn.Orig = n\n\n\ts.Def = asTypesNode(n)\n\tasNode(s.Def).Name.SetUsed(true)\n\tn.Sym = s\n\tn.Type = t\n\tn.SetClass(PAUTO)\n\tn.Esc = EscNever\n\tn.Name.Curfn = e.curfn\n\te.curfn.Func.Dcl = append(e.curfn.Func.Dcl, n)\n\tdowidth(t)\n\treturn ssa.LocalSlot{N: n, Type: t, Off: 0, SplitOf: parent, SplitOffset: offset}\n}\n\nfunc (e *ssafn) CanSSA(t *types.Type) bool {\n\treturn canSSAType(t)\n}\n\nfunc (e *ssafn) Line(pos src.XPos) string {\n\treturn linestr(pos)\n}\n\n// Log logs a message from the compiler.\nfunc (e *ssafn) Logf(msg string, args ...interface{}) {\n\tif e.log {\n\t\tfmt.Printf(msg, args...)\n\t}\n}\n\nfunc (e *ssafn) Log() bool {\n\treturn e.log\n}\n\n// Fatal reports a compiler error and exits.\nfunc (e *ssafn) Fatalf(pos src.XPos, msg string, args ...interface{}) {\n\tlineno = pos\n\tnargs := append([]interface{}{e.curfn.funcname()}, args...)\n\tFatalf(\"'%s': \"+msg, nargs...)\n}\n\n// Warnl reports a \"warning\", which is usually flag-triggered\n// logging output for the benefit of tests.\nfunc (e *ssafn) Warnl(pos src.XPos, fmt_ string, args ...interface{}) {\n\tWarnl(pos, fmt_, args...)\n}\n\nfunc (e *ssafn) Debug_checknil() bool {\n\treturn Debug_checknil != 0\n}\n\nfunc (e *ssafn) UseWriteBarrier() bool {\n\treturn use_writebarrier\n}\n\nfunc (e *ssafn) Syslook(name string) *obj.LSym {\n\tswitch name {\n\tcase \"goschedguarded\":\n\t\treturn goschedguarded\n\tcase \"writeBarrier\":\n\t\treturn writeBarrier\n\tcase \"gcWriteBarrier\":\n\t\treturn gcWriteBarrier\n\tcase \"typedmemmove\":\n\t\treturn typedmemmove\n\tcase \"typedmemclr\":\n\t\treturn typedmemclr\n\t}\n\te.Fatalf(src.NoXPos, \"unknown Syslook func %v\", name)\n\treturn nil\n}\n\nfunc (e *ssafn) SetWBPos(pos src.XPos) {\n\te.curfn.Func.setWBPos(pos)\n}\n\nfunc (n *Node) Typ() *types.Type {\n\treturn n.Type\n}\nfunc (n *Node) StorageClass() ssa.StorageClass {\n\tswitch n.Class() {\n\tcase PPARAM:\n\t\treturn ssa.ClassParam\n\tcase PPARAMOUT:\n\t\treturn ssa.ClassParamOut\n\tcase PAUTO:\n\t\treturn ssa.ClassAuto\n\tdefault:\n\t\tFatalf(\"untranslatable storage class for %v: %s\", n, n.Class())\n\t\treturn 0\n\t}\n}\n\nfunc clobberBase(n *Node) *Node {\n\tif n.Op == ODOT && n.Left.Type.NumFields() == 1 {\n\t\treturn clobberBase(n.Left)\n\t}\n\tif n.Op == OINDEX && n.Left.Type.IsArray() && n.Left.Type.NumElem() == 1 {\n\t\treturn clobberBase(n.Left)\n\t}\n\treturn n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/cmd/compile/internal/gc/ssa.go b/cmd/compile/internal/gc/ssa.go
--- a/cmd/compile/internal/gc/ssa.go	
+++ b/cmd/compile/internal/gc/ssa.go	
@@ -5187,10 +5187,10 @@
 	// 确保i <= j
 	i = s.boundsCheck(i, j, ssa.BoundsSliceB, bounded)
 	if v.Extra == nil {
-		// 确保j <= k
+		// 这里的k是cap,确保j <= k
 		j = s.boundsCheck(j, k, ssa.BoundsSliceB, bounded)
 	} else {
-		// 确保j <= cap
+		// 这里的k是步进值,确保j <= cap
 		j = s.boundsCheck(j, cap, ssa.BoundsSliceB, bounded)
 	}
 
@@ -5205,6 +5205,9 @@
 	// Use length of strings for that.
 	rlen := s.newValue2(subOp, types.Types[TINT], j, i) // 计算新的长度
 	rcap := rlen
+	if j != k && !t.IsString() {
+		rcap = s.newValue2(subOp, types.Types[TINT], k, i) // 计算新的cap
+	}
 
 	if (i.Op == ssa.OpConst64 || i.Op == ssa.OpConst32) && i.AuxInt == 0 && v.Extra == nil {
 		// No pointer arithmetic necessary.
